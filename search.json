[{"title":"Hux主题添加搜索","url":"/2021/04/22/Modify/Hux主题添加搜索/","content":"\n>本文介绍下给hux主题添加搜索功能，主要是抄 [黄玄](https://huangxuan.me/) 的作业，可以去参考[huxpro](https://github.com/Huxpro/huxpro.github.io/)\n\n**使用插件**：hexo-generator-search\n\n```yaml\nnpm install hexo-generator-search --save\n```\n\n**配置 _config.yml**：\n\n```yaml\nsearch:\n  path: search.json\n  field: post\n  limit: 50\n  enable: true\n```\n\n**增加模板 search.ejs**:\n\n```javascript\n<div class=\"search-page\">\n    <div class=\"search-icon-close-container\">\n      <span class=\"search-icon-close\">\n        <i class=\"fa fa-chevron-down\"></i>\n      </span>\n    </div>\n    <div class=\"search-main container\">\n      <div class=\"row\">\n        <div class=\"col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1\">\n          <form></form>\n          <input type=\"text\" id=\"search-input\" placeholder=\"search: \">\n          \n          <div id=\"search-results\" class=\"mini-post-list\"></div>\n        </div>\n      </div>\n    </div>\n</div>\n\n<script>\n\n    $(document).ready(function () {\n        var $searchPage = $('.search-page');\n        var $searchOpen = $('.search-icon');\n        var $searchClose = $('.search-icon-close');\n        var $searchInput = $('#search-input');\n        var $body = $('body');\n\n        $searchOpen.on('click', function (e) {\n            e.preventDefault();\n            $searchPage.toggleClass('search-active');\n            var prevClasses = $body.attr('class') || '';\n            setTimeout(function () {\n                $body.addClass('no-scroll');\n            }, 400)\n\n            if ($searchPage.hasClass('search-active')) {\n                $searchClose.on('click', function (e) {\n                    e.preventDefault();\n                    $searchPage.removeClass('search-active');\n                    $body.attr('class', prevClasses);  // from closure \n                });\n                $searchInput.focus();\n            }\n            searchFunc('/search.json', 'search-input', 'search-results');\n        });\n    });\n</script>\n```\n\n把search.ejs导入到 layout.ejs中:\n\n```javascript\n    <!-- Search -->\n    <%- partial('_partial/search')%>\n```\n\n**新增search.js**:\n\n定义 searchFunc 函数\n\n```javascript\nvar searchFunc = function (path, search_id, content_id) {\n    console.log(\"test\");\n    $.ajax({\n        url: path,\n        dataType: \"json\",\n        success: function (datas) {\n            var $input = document.getElementById(search_id);\n            var $resultContent = document.getElementById(content_id);\n            $input.addEventListener('input', function () {\n                var keywords = this.value.trim().toLowerCase().split(/[\\s\\-]+/);\n                var str = \"\";\n                $resultContent.innerHTML = \"\";\n                if (this.value.trim().length <= 0) {\n                    return;\n                }\n                datas.forEach(function (data) {\n                    var isMatch = true;\n                    var content_index = [];\n                    var data_title = data.title.trim().toLowerCase();\n                    var data_content = data.content.trim().replace(/<[^>]+>/g, \"\").toLowerCase();\n                    var data_url = data.url;\n                    var index_title = -1;\n                    var index_content = -1;\n                    var first_occur = -1;\n                    // only match artiles with not empty titles and contents\n                    if (data_title != '' && data_content != '') {\n                        keywords.forEach(function (keyword, i) {\n                            index_title = data_title.indexOf(keyword);\n                            index_content = data_content.indexOf(keyword);\n                            if (index_title < 0 && index_content < 0) {\n                                isMatch = false;\n                            } else {\n                                if (index_content < 0) {\n                                    index_content = 0;\n                                }\n                                if (i == 0) {\n                                    first_occur = index_content;\n                                }\n                            }\n                        });\n                    }\n                    // show search results\n                    if (isMatch) {\n                        str += \"<div class='post-preview item'><a href='\" + data_url +\"'>\" +\"<h2 class='post-title'>\" + data_title +\"</h2>\" + \"</a>\";\n                        var content = data.content.trim().replace(/<[^>]+>/g, \"\");\n                        if (first_occur >= 0) {\n                            // cut out 40 characters\n                            var start = first_occur - 20;\n                            var end = first_occur + 20;\n                            if (start < 0) {\n                                start = 0;\n                            }\n                            if (start == 0) {\n                                end = 40;\n                            }\n                            if (end > content.length) {\n                                end = content.length;\n                            }\n                            var match_content = content.substring(start, end);\n                            // highlight all keywords\n                            keywords.forEach(function (keyword) {\n                                var regS = new RegExp(keyword, \"gi\");\n                                match_content = match_content.replace(regS, \"<em class=\\\"search-keyword\\\">\" + keyword + \"</em>\");\n                            });\n\n                            str += \"<p class=\\\"search-result\\\">\" + match_content + \"...</p><hr>\"\n                        }\n                        str+=\"</div>\"\n                    }\n                });\n                $resultContent.innerHTML = str;\n            });\n        }\n    });\n}\n```\n\n**增加样式**：\n\n抄huxpro的作业：[hux](https://huangxuan.me/)\n\n","tags":["Modify Theme"]},{"title":"Redis相关知识----对象机制","url":"/2021/04/21/Redis/Redis相关知识----对象机制/","content":"\n>本文介绍Redis对象机制相关知识，只是对底层做一些了解，并不深入底层的数据结构。\n\n\nRedis的5种基础数据类型，在底层是采用对象机制实现的。\n\nRedis的每种对象其实都由对象结构(redisObject) 与 对应编码的数据结构组合而成，而每种对象类型对应若干编码方式，不同的编码方式所对应的底层数据结构是不同的。\n![Redis对象机制](https://img-blog.csdnimg.cn/20210421170649889.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n**redisObject**:\nredisObject 是 Redis 类型系统的核心, 数据库中的每个键、值, 以及 Redis 本身处理的参数, 都表示为这种数据类型。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210421171948867.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n其中type、encoding和ptr是最重要的三个属性。\n\n - type记录了对象所保存的值的类型，它的值可能是以下常量中的一个：\n```c\n/*\n - 对象类型\n*/\n#define OBJ_STRING 0 // 字符串\n#define OBJ_LIST 1 // 列表\n#define OBJ_SET 2 // 集合\n#define OBJ_ZSET 3 // 有序集\n#define OBJ_HASH 4 // 哈希表\n```\n - encoding记录了对象所保存的值的编码，它的值可能是以下常量中的一个：\n\n```c\n/*\n* 对象编码\n*/\n#define OBJ_ENCODING_RAW 0     /* Raw representation */\n#define OBJ_ENCODING_INT 1     /* Encoded as integer */\n#define OBJ_ENCODING_HT 2      /* Encoded as hash table */\n#define OBJ_ENCODING_ZIPMAP 3  /* 注意：版本2.6后不再使用. */\n#define OBJ_ENCODING_LINKEDLIST 4 /* 注意：不再使用了，旧版本2.x中String的底层之一. */\n#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */\n#define OBJ_ENCODING_INTSET 6  /* Encoded as intset */\n#define OBJ_ENCODING_SKIPLIST 7  /* Encoded as skiplist */\n#define OBJ_ENCODING_EMBSTR 8  /* Embedded sds string encoding */\n#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */\n#define OBJ_ENCODING_STREAM 10 /* Encoded as a radix tree of listpacks */\n\n```\n\n - ptr是一个指针，指向实际保存值的数据结构，这个数据结构由type和encoding属性决定。如果一个redisObject 的type 属性为OBJ_LIST ， encoding 属性为OBJ_ENCODING_QUICKLIST ，那么这个对象就是一个Redis 列表（List)，它的值保存在一个QuickList的数据结构内，而ptr 指针就指向quicklist的对象；\n\n**当执行一个处理数据类型命令的时候，redis执行以下步骤**：\n\n - 根据给定的key，在数据库字典中查找和他相对应的redisObject，如果没找到，就返回NULL；\n - 检查redisObject的type属性和执行命令所需的类型是否相符，如果不相符，返回类型错误；\n - 根据redisObject的encoding属性所指定的编码，选择合适的操作函数来处理底层的数据结构；\n - 返回数据结构的操作结果作为命令的返回值。\n\n比如现在执行LPOP命令：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210421173348258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n**字符串对象**：\n从第一张图可以看出字符串对象的编码类型：\n\n - int 编码：保存的是可以用 long 类型表示的整数值。 \n - embstr 编码：保存长度小于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。 \n - raw 编码：保存长度大于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210421184642144.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n\n**列表对象**：\n\n列表对象的编码是quicklist。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210421184628366.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**哈希对象**：\n哈希对象的编码可以是 ziplist 或者 hashtable；对应的底层实现有两种, 一种是ziplist, 一种是dict。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2021042118473249.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n\n**集合对象**：\n集合对象的编码可以是 intset 或者 hashtable; 底层实现有两种, 分别是intset和dict。 显然当使用intset作为底层实现的数据结构时, 集合中存储的只能是数值数据, 且必须是整数; 而当使用dict作为集合对象的底层实现时, 是将数据全部存储于dict的键中, 值字段闲置不用。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210421185640615.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**有序集合对象**：\n有序集合的底层实现依然有两种, 一种是使用ziplist作为底层实现, 另外一种比较特殊, 底层使用了两种数据结构: dict与skiplis。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2021042119004922.png)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210421190111616.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n其实有序集合单独使用字典或跳跃表其中一种数据结构都可以实现，但是这里使用两种数据结构组合起来，原因是假如我们单独使用 字典，虽然能以 O(1) 的时间复杂度查找成员的分值，但是因为字典是以无序的方式来保存集合元素，所以每次进行范围操作的时候都要进行排序；假如我们单独使用跳跃表来实现，虽然能执行范围操作，但是查找操作有 O(1)的复杂度变为了O(logN)。因此Redis使用了两种数据结构来共同实现有序集合。\n\n**参考**：\n\n 1. [redis对象与编码(底层结构)对应关系详解](https://www.pdai.tech/md/db/nosql-redis/db-redis-data-type-enc.html#%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AF%B9%E8%B1%A1)\n","tags":["Redis"]},{"title":"Redis相关知识----数据类型","url":"/2021/04/19/Redis/Redis相关知识----数据类型/","content":"\n>本文介绍Redis的数据类型相关知识\n\n### Redis数据结构简介\n对于Redis，所有的Key都是字符串。我们在谈Redis基础数据结构时，讨论的是存储值的数据类型，主要包括常见的5种数据类型，分别是：String、List、Set、Zset、Hash。\n\n![Redis数据结构](https://img-blog.csdnimg.cn/202104192159585.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n### String字符串\nString是redis中最基本的数据类型，一个key对应一个value。String类型是二进制安全的，意思是 redis 的 string 可以包含任何数据。如数字，字符串，jpg图片或者序列化的对象。\n\n**命令**：\n\n|命令| 简述 | 使用 |\n|----|----|----|\n| GET | 获取存储在给定键中的值 | GET value |\n| SET | 设置存储在给定键中的值\t | SET value |\n| DEL | 删除存储在给定键中的值\t | DEL value |\n| INCR| 将键存储的值加1 | INCR key |\n| DECR| 将键存储的值减1 | DECR key |\n| INCRBY| 将键存储的值加上整数 | INCRBY key amount |\n| DECRBY| 将键存储的值减去整数 | DECRBY key amount |\n\n**使用场景**：\n\n - 缓存： 经典使用场景，把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力。\n - 计数器：redis是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。\n - session：常见方案spring session + redis实现session共享。\n\n### List列表\nRedis中的List其实就是链表（Redis用双端链表实现List）。\n\n**命令**：\n\n|命令| 简述 | 使用 |\n|----|----|----|\n| RPUSH |将给定值推入到列表右端 | RPUSH key value |\n| LPUSH | 将给定值推入到列表左端\t |LPUSH  key value |\n| RPOP| 从列表的右端取出一个值 | RPOP key value |\n| LPOP| 从列表的左端取出一个值 | LPOP key value |\n| LRANGE| 获取列表在给定范围上的所有值 | LRANGE key 0 -1 |\n| LINDEX| 通过索引获取列表中的元素 | LINDEX key index |\n\n**使用Redis List的技巧**：\n\n - LPUSH + RPOP 相当于队列\n - LPUSH + LPOP 相当于栈\n - LPUSH + BRPOP 相当于消息队列\n\n**使用场景**：\n\n - 微博TimeLine: 有人发布微博，用lpush加入时间轴，展示新的列表信息。\n - 消息队列：可以利用List的 PUSH 操作，将任务存放在List中，然后工作线程再用 POP 操作将任务取出进行执行，相当于生产者消费者模型。\n\n### Set集合\nRedis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。\n\n**命令**：\n\n|命令| 简述 | 使用 |\n|----|----|----|\n| SADD |向集合添加一个或多个成员 | SADD set-key value |\n| SREM |向集合删除一个或多个成员| SREM set-key value |\n| SCARD | 获取集合的成员数\t |SCARD set-key|\n| SMEMBERS| 返回集合中的所有成员 | SMEMBERS set-key|\n| SISMEMBER| 判断 member 元素是否是集合 key 的成员 | SISMEMBER set-key value |\n\n**使用场景**：\n\n - 标签（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。\n - 点赞，或点踩，收藏等，可以放到set中实现\n\n### Hash散列\nRedis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。\n\n**命令**：\n\n|命令| 简述 | 使用 |\n|----|----|----|\n| HSET|添加键值对 | HSET hash-key sub-key1 value1 |\n| HGET| 获取指定散列键的值\t |HGET hash-key sub-key1  |\n| HGETALL| 获取散列中包含的所有键值对 | HGETALL hash-key |\n| HDEL| 如果给定键存在于散列中，那么就移除这个键 | HDEL hash-key sub-key1|\n\n**使用场景**：\n\n - 缓存： 能直观，相比string更节省空间，的维护缓存信息，如用户信息，视频信息等。\n\n### Sorted Sets有序集合\nRedis 有序集合和集合一样也是 string 类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。\n\n有序集合的成员是唯一的,但分数(score)却可以重复。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。\n\n**命令**：\n\n|命令| 简述 | 使用 |\n|----|----|----|\n| ZADD|将所有指定成员添加到键为key有序集合（sorted set）里面 | ZADD zset-key score member1|\n| ZREM| 如果给定元素成员存在于有序集合中，那么就移除这个元素\t |ZREM zset-key member1 |\n| ZRANGE| 返回存储在有序集合key中的指定范围的元素。| ZRANGE zset-key start stop withccores |\n| ZCOUNT | 返回有序集key中，score值在min和max之间的成员数。  | ZCOUNT zset-key min max|\n\n**使用场景**：\n\n - 排行榜：有序集合经典使用场景。例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。\n\n\n### HyperLogLogs（基数统计）\n什么是基数？\n\n 举个例子，A = {1, 2, 3, 4, 5}， B = {3, 5, 6, 7, 9}；那么基数（不重复的元素）= 1, 2, 4, 6, 7, 9； （允许容错，即可以接受一定误差） \n\nHyperLogLogs 基数统计用来解决什么问题？ \n\n这个结构可以非常省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数、页面实时UV、在线用户数，共同好友数等。\n\n### Bitmap （位存储）\nBitmap 即位图数据结构，都是操作二进制位来进行记录，只有0 和 1 两个状态。\n\n用来解决什么问题？\n\n比如：统计用户信息，活跃，不活跃！ 登录，未登录！ 打卡，不打卡！ 两个状态的，都可以使用 Bitmaps！\n\n**命令**：\n\n|命令| 简述 | 使用 |\n|----|----|----|\n| SETBIT|对key所储存的字符串值，设置或清除指定偏移量上的位(bit)  | SETBIT bit-key offset value|\n| GETBIT| 对 key 所储存的字符串值，获取指定偏移量上的位(bit) |GETBIT bit-key offset |\n| BITCOUNT| 被设置为 1 的位的数量| BITCOUNT bit-key |\n\n### geospatial (地理位置)\nRedis 的 Geo 可以推算地理位置的信息: 两地之间的距离, 方圆几里的人。\n\n\n**参考**：\n\n 1. [Redis 5种基础数据类型详解](https://www.pdai.tech/md/db/nosql-redis/db-redis-data-types.html)\n 2. [Redis 3种特殊类型详解](https://www.pdai.tech/md/db/nosql-redis/db-redis-data-type-special.html)\n","tags":["Redis"]},{"title":"阻塞队列BlockingQueue","url":"/2021/04/18/Java 并发/阻塞队列BlockingQueue/","content":"\n>本文介绍BlockingQueue阻塞队列相关知识\n\n### 简介\nBlockingQueue是JUC包下的一个接口，通常用于一个线程生产对象，而另外一个线程消费这些对象的场景。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417171853751.png)\n\n**方法**：\nBlockingQueue继承Queue接口，因此，对数据元素的基本操作有：\n> 插入元素\n1. add(E e) ：往队列插入数据，当队列满时，插入元素时会抛出IllegalStateException异常；\n2. offer(E e)：当往队列插入数据时，插入成功返回`true`，否则则返回`false`。\n\n> 删除元素\n1. remove(Object o)：从队列中删除数据，成功则返回`true`，否则为`false`\n2. poll：删除数据，当队列为空时，返回null；\n\n> 查看元素\n1. element：获取队头元素，如果队列为空时则抛出NoSuchElementException异常；\n2. peek：获取队头元素，如果队列为空则抛出NoSuchElementException异常\n\nBlockingQueue具有的特殊操作：\n\n> 插入数据：\n1. put：当阻塞队列容量已经满时，往阻塞队列插入数据的线程会被阻塞，直至阻塞队列已经有空余的容量可供使用；\n2. offer(E e, long timeout, TimeUnit unit)：若阻塞队列已经满时，同样会阻塞插入数据的线程，直至阻塞队列已经有空余的地方，与put方法不同的是，该方法会有一个超时时间，若超过当前给定的超时时间，插入数据的线程会退出；\n\n> 删除数据\n1. take()：当阻塞队列为空时，获取队头数据的线程会被阻塞；\n2. poll(long timeout, TimeUnit unit)：当阻塞队列为空时，获取数据的线程会被阻塞，另外，如果被阻塞的线程超过了给定的时长，该线程会退出\n\n### 常用实现类\n**ArrayBlockingQueue**：\nArrayBlockingQueue是由数组实现的有界队列，ArrayBlockingQueue可作为“有界数据缓冲区”，生产者插入数据到队列容器中，并由消费者提取。ArrayBlockingQueue一旦创建，容量不能改变。\n\n从ArrayBlockingQueue的构造函数中可以看出，线程访问队列默认是非公平的，但是可以调用另一个构造函数进行设置。\n\n当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。\n\n```java\n    public ArrayBlockingQueue(int capacity) {\n        this(capacity, false);\n    }\n\n    public ArrayBlockingQueue(int capacity, boolean fair) {\n        if (capacity <= 0)\n            throw new IllegalArgumentException();\n        this.items = new Object[capacity];\n        lock = new ReentrantLock(fair);\n        notEmpty = lock.newCondition();\n        notFull =  lock.newCondition();\n    }\n```\n\n**LinkedBlockingQueue**:\nLinkedBlockingQueue是用链表实现的有界阻塞队列，同样满足FIFO的特性，与ArrayBlockingQueue相比起来具有更高的吞吐量，为了防止LinkedBlockingQueue容量迅速增，损耗大量内存。通常在创建LinkedBlockingQueue对象时，会指定其大小，如果未指定，容量等于Integer.MAX_VALUE。\n\n**LinkedBlockingDeque**:\nLinkedBlockingDeque是基于链表数据结构的有界阻塞双端队列，如果在创建对象时为指定大小时，其默认大小为Integer.MAX_VALUE。与LinkedBlockingQueue相比，主要的不同点在于LinkedBlockingDeque具有双端队列的特性。\n\n**LinkedTransferQueue**:\nLinkedTransferQueue是一个由链表数据结构构成的无界阻塞队列，由于该队列实现了TransferQueue接口，与其他阻塞队列相比主要有以下不同的方法：\n\ntransfer(E e): 如果当前有线程（消费者）正在调用take()方法或者可延时的poll()方法进行消费数据时，生产者线程可以调用transfer方法将数据传递给消费者线程。如果当前没有消费者线程的话，生产者线程就会将数据插入到队尾，直到有消费者能够进行消费才能退出；\n\ntryTransfer(E e): tryTransfer方法如果当前有消费者线程（调用take方法或者具有超时特性的poll方法）正在消费数据的话，该方法可以将数据立即传送给消费者线程，如果当前没有消费者线程消费数据的话，就立即返回false。因此，与transfer方法相比，transfer方法是必须等到有消费者线程消费数据时，生产者线程才能够返回。而tryTransfer方法能够立即返回结果退出。\n\ntryTransfer(E e,long timeout,imeUnit unit)\n与transfer基本功能一样，只是增加了超时特性，如果数据才规定的超时时间内没有消费者进行消费的话，就返回false。\n\n**PriorityBlockingQueue**:\n - PriorityBlockingQueue是一个支持优先级的无界阻塞队列（容量不够时会自动扩容,是二叉树最小堆的实现）。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现compareTo()方法来指定元素排序规则，或者初始化时通过构造器参数Comparator来指定排序规则。\n - 它的 take 方法在队列为空的时候会阻塞，但是正因为它是无界队列，而且会自动扩容，所以它的队列永远不会满，所以它的 put 方法永远不会阻塞，添加操作始终都会成功。\n\n**SynchronousQueue**：\n\n - synchronousQueue 是一个不存储任何元素的阻塞队列，每一个put操作必须等待take操作，否则不能添加元素。同时它也支持公平锁和非公平锁。\n - synchronousQueue 的容量并不是1，而是0。因为它本身不会持有任何元素，它是直接传递的，synchronousQueue 会把元素从生产者直接传递给消费者，在这个过程中能够是不需要存储的。\n - 线程池 CachedThreadPool 就是利用了该队列，Executors.newCachedThreadPool()，因为这个线程池它的最大线程数是Integer.MAX_VALUE，它是更具需求来创建线程，所有的线程都是临时线程，使用完后空闲60秒则被回收，\n\n**DelayQueue**：\n\n - DelayQueue 是一个使用PriorityBlockingQueue的延迟获取的无界队列。具有“延迟”的功能。\n - DelayQueue 应用场景：1. 缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。2. 定时任务调度。使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。\n - DelayQueue是一个存放实现Delayed接口的数据的无界阻塞队列，只有当数据对象的延时时间达到时才能插入到队列进行存储。如果当前所有的数据都还没有达到创建时所指定的延时期，则队列没有队头，并且线程通过poll等方法获取数据元素则返回null。所谓数据延时期满时，则是通过Delayed接口的getDelay(TimeUnit.NANOSECONDS)来进行判定，如果该方法返回的是小于等于0则说明该数据元素的延时期已满。\n\n**参考**：\n\n 1. [并发容器之BlockingQueue](https://github.com/CL0610/Java-concurrency/blob/master/19.%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E4%B9%8BBlockingQueue/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E4%B9%8BBlockingQueue.md)\n 2. [JAVA中常见的阻塞队列详解](https://segmentfault.com/a/1190000038178346)\n 3. [并发队列-无界阻塞优先级队列PriorityBlockingQueue原理探究](https://cloud.tencent.com/developer/article/1330391)\n 4. [Java-BlockingQueue 接口5大实现类的使用场景](https://cloud.tencent.com/developer/article/1636024)\n","tags":["Java并发"]},{"title":"Mysql相关知识（五）","url":"/2021/04/16/Mysql/Mysql相关知识(五)/","content":"\n>本文介绍Mysql ACID特性的实现原理\n\n**ACID**:\n\n - 原子性\n - 一致性\n - 隔离性\n - 持久性\n\n**原子性**：一个事务是一个不可切割的单位，要么全部执行成功，要么全部失败。\n\n是采用undo log日志实现的。undo log日志用来记录Mysql逻辑语句的执行。\n\n当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。\n\n当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。\n\n**一致性**：数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。\n\n\n从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。\n\n但是，如果你在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，你在转账的例子中，你的代码里故意不给B账户加钱，那一致性还是无法保证。因此，还必须从应用层角度考虑。\n\n从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！\n\n**隔离性**：事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰。\n\n隔离性主要解决并发环境下，事务之间互不干扰，因为并发情况下会出现并发一致性问题。\n - 丢失修改\n - 脏读\n - 不可重复读\n - 幻读\n\n这些并发一致性问题，从读写角度考虑，可以通过不同的方式解决\n\n - (一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性\n - (一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性\n\n按照锁的粒度，可以分位表锁和行锁。MyIsam只支持表锁，而InnoDB同时支持表锁和行锁。\n\nMVCC（Multi-Version Concurrency Control）：多版本并发控制，通过版本链、undo log、ReadView实现。\n\n - 隐藏列：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的事务id、指向undo log的指针等。\n - 基于undo log的版本链：前面说到每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链。\n - ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本；但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与trx_sys快照比较，从而判断数据对该ReadView是否可见，即对事务A是否可见。\n\nReadView中的重要id\n\n - trx_ids: 当前系统活跃(未提交)事务版本号集合。\n - low_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”。\n - up_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号”\n - creator_trx_id: 创建当前read view的事务版本号；\n\nSQL标准中定义了四种隔离级别，并规定了每种隔离级别下上述几个问题是否存在，mysql默认的隔离级别为RR（可重复读）。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210416225104783.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n上面说的MVCC用于支持RC和RR的实现，是一种非加锁的形式。\n\n - RR是在事务开始后第一次执行select前创建ReadView，直到事务提交都不会再创建。根据前面的介绍，RR可以避免脏读、不可重复读和幻读。\n - RC每次执行select前都会重新建立一个新的ReadView，因此如果事务A第一次select之后，事务B对数据进行了修改并提交，那么事务A第二次select时会重新建立新的ReadView，因此事务B的修改对事务A是可见的。因此RC隔离级别可以避免脏读，但是无法避免不可重复读和幻读。\n\n解决幻读：\n\n - 通过MVCC非加锁读，也称作快照读、一致性读\n - 加锁读：record lock(记录锁) + gap lock(间隙锁)\n\n**持久性**：事务一旦提交，它对数据库的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。\n\n使用redo log实现，保证数据库在宕机的情况下，数据也不会丢失。\n\nredo log 和 bin log的区别：\n\n - 作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。\n - 层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层(可以参考文章前面对MySQL逻辑架构的介绍)实现的，同时支持InnoDB和其他存储引擎。\n - redo log是物理日志，内容基于磁盘的Page；binlog的内容是二进制的，根据binlog_format参数的不同，可能基于sql语句、基于数据本身或者二者的混合。\n - 写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元：事务提交时、master thread每秒刷盘等。\n\n**参考**：\n\n 1. [深入学习Mysql事务](https://www.cnblogs.com/kismetv/p/10331633.html)\n 2. [数据库MVCC](https://www.cnblogs.com/kismetv/p/10331633.html)\n","tags":["Mysql"]},{"title":"Mysql相关知识（四）","url":"/2021/04/13/Mysql/Mysql相关知识(四)/","content":">本文介绍Mysql中explain相关知识\n\n**explain**:\n当mysql的查询语句执行较慢时，可以通过使用explain命令解释mysql语句，通过结果分析mysql语句执行慢的原因，来优化mysql语句。\n\nexpain出来的信息有10列：\n - id\n - select_type\n - table\n - type\n - possible_keys\n - key\n - key_len\n - ref\n - rows\n - Extra\n\n**id：SQL执行的顺序的标识,SQL根据id从大到小的执行**\n\nid列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的顺序增长的。MySQL将 select 查询分为简单查询和复杂查询。复杂查询分为三类：简单子查询、派生表（from语句中的子查询）、union 查询。\n\n 1. id相同时，执行顺序由上至下\n 2. 如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行\n 3. id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行\n\n**select_type：查询中每个select子句的类型**\n\n 1. simple：简单查询。查询不包含子查询和union\n 2. primary：复杂查询中最外层的 select\n 3. subquery：包含在 select 中的子查询（不在 from 子句中）\n 4. derived：包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表（derived的英文含义）\n\n```yaml\nmysql> explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der;\n+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------------+\n| id | select_type | table      | type   | possible_keys | key     | key_len | ref   | rows | Extra       |\n+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------------+\n|  1 | PRIMARY     | <derived3> | system | NULL          | NULL    | NULL    | NULL  |    1 | NULL        |\n|  3 | DERIVED     | film       | const  | PRIMARY       | PRIMARY | 4       | const |    1 | NULL        |\n|  2 | SUBQUERY    | actor      | const  | PRIMARY       | PRIMARY | 4       | const |    1 | Using index |\n+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------------+ \n```\n\n5. union：在 union 中的第二个和随后的 select\n6. union result：从 union 临时表检索结果的 select\n\n```yaml\nmysql> explain select 1 union all select 1;\n+----+--------------+------------+------+---------------+------+---------+------+------+-----------------+\n| id | select_type  | table      | type | possible_keys | key  | key_len | ref  | rows | Extra           |\n+----+--------------+------------+------+---------------+------+---------+------+------+-----------------+\n|  1 | PRIMARY      | NULL       | NULL | NULL          | NULL | NULL    | NULL | NULL | No tables used  |\n|  2 | UNION        | NULL       | NULL | NULL          | NULL | NULL    | NULL | NULL | No tables used  |\n| NULL | UNION RESULT | <union1,2> | ALL  | NULL          | NULL | NULL    | NULL | NULL | Using temporary |\n+----+--------------+------------+------+---------------+------+---------+------+------+-----------------+\n```\n**table：正在访问哪个表**\n\n**type：表示MySQL在表中找到所需行的方式，又称“访问类型”**\n常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）\n\n - ALL：即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了\n - index: 和ALL一样，不同就是mysql只需扫描索引树，这通常比ALL快一些。\n - range:范围扫描通常出现在 in(), between ,> ,<, >= 等操作中。使用一个索引来检索给定范围的行。\n - ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n - eq_ref: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件\n - const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用system\n - NULL: mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。例如：在索引列中选取最小值，可以单独查找索引来完成，不需要在执行时访问表。\n\n**possible_keys：查询可能使用哪些索引来查找**\n\n**key：实际采用哪个索引来优化对该表的访问**\n\n**key_len：mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列**\n![字节长度](https://img-blog.csdnimg.cn/2021041322293393.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**ref：显示了在key列记录的索引中，表查找值所用到的列或常量**\n\n**rows： 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数**\n\n**Extra：展示的是额外信息**\n\n - distinct: 一旦mysql找到了与行相联合匹配的行，就不再搜索了\n - Using index：这发生在对表的请求列都是同一索引的部分的时候，返回的列数据只使用了索引中的信息，而没有再去访问表中的行记录。是性能高的表现。\n - Using where：mysql服务器将在存储引擎检索行后再进行过滤。就是先读取整行数据，再按 where 条件进行检查，符合就留下，不符合就丢弃。\n - Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。\n - Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。\n\n**参考**：\n\n 1. [Mysql Explain详解](https://cloud.tencent.com/developer/article/1093229)\n","tags":["Mysql"]},{"title":"Mysql相关知识（三）索引","url":"/2021/04/10/Mysql/Mysql相关知识(三)索引/","content":"\n>本文介绍Mysql索引相关知识\n\n**索引是什么**\n\n<font color=red>索引是一种帮助数据库高效查询数据的数据结构</font>\n\n索引本身也很大，不可能全部存储在内存中，因此索引往往是存储在磁盘上的文件中。（可能是单独的索引文件，也可能是和数据一起存储在数据文件中）\n\n通常所说的索引，包括聚集索引、覆盖索引、组合索引、前缀索引、唯一索引等，没有特别说明，默认都是使用B+树结构组织（多路搜索树，并不一定是二叉的）的索引。\n\n**索引的类型**\n\n - 主键索引：索引列中的值必须是唯一的，且不允许有空值。\n - 唯一索引：索引列中的值必须是唯一的，但允许为空值。\n - 全文索引：只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。 \n - 组合索引： 可以是单列上创建的索引，也可以是在多列上创建的索引。\n - 普通索引： 最基本的索引类型，没有唯一性之类的限制。\n\n**索引相关操作**：\n\n**主键索引**：\n\n```yaml\n#建表的时候创建主键索引\ncreate table 表名 (字段1 数据类型，字段2 数据类型,primary key (列名));\n\n#修改表增加主键索引\nalter table 表名 add primary key (列名);\n\n#删除主键索引\nalter table 表名 drop primary key;\n```\n\n**唯一索引**：\n\n```yaml\n#创建\ncreate unique index 索引名 on 表名 (列名);\n或\nalter table 表名 add unique 索引名 (列名);\n或\ncreate table 表名 (字段1 数据类型，字段2 数据类型,unique 索引名 (列名));\n```\n**全文索引**:\n\n```yaml\ncreate fulltext index 索引名 on 表名 (列名);\n\nalter table 表名 add fulltext 索引名 (列名);\n\ncreate table 表名 (字段1 数据类型，字段2 数据类型,fulltext 索引名 (列名));\n```\n\n**组合索引**：\n\n```yaml\ncreate table 表名 (字段1 数据类型，字段2 数据类型,index 索引名 (列名1，列名2));\n#需要满足最左原则，因为select语句的 where 条件是依次从左往右执行的，所以在使用 select 语句查询时 where 条件使用的字段顺序必须和组合索引中的排序一致，否则索引将不会生效。\n#  select * from 表名 where 列名1='...' and(or) 列名2='...'\n```\n\n**普通索引**：\n\n```yaml\ncreate index 索引名 on 表名 (列名[(length)]);\n\n#(列名[(length)]：length 为可选项，如果忽略 length 的值，则使用整个列的值作为索引。如果指定使用列的前 length 个字符来创建索引，这样有利于减小索引文件的大小。\n\nalter table 表名 add index 索引名 (列名);\n```\n\n**查看索引**：\n\n```yaml\nshow index from T;\nshow keys form T;\n```\n\n**Mysql索引的数据结构**：<font color=red>B+Tree</font>\n不使用下列数据结构的原因：\n - 二叉树：极端情况下会成为类似链表的结构，而且树高会增大磁盘IO，影响查询效率\n - 平衡二叉树：树高会增大磁盘IO，影响查询效率\n - hash表：适合等值查询，不适合范围查询会查询整个表\n \n BTree：\n \n - 叶子节点和非叶子节点都存放数据，不支持范围查询的快速查询（会多词遍历根节点）。\n - 如果data存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中可存储的数据量就会变少，树相应就会变高，磁盘IO次数就会变大。\n\n\n B+Tree：\n \n - 只有叶子节点存储数据，非叶子节点存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。\n\n**InnoDB索引**：\n\n主键索引也叫聚簇索引，使用B+Tree构建，叶子节点存放的是数据表的整行记录。一般情况下，聚簇索引等同于主键索引，当一个表没有创建主键索引时，InnoDB会自动创建一个ROWID字段来构建聚簇索引。\n\n除聚簇索引之外的所有索引都称为辅助索引。辅助索引叶子节点存储的是该行的主键值，在检索时，InnoDB使用此主键值在聚簇索引中搜索行记录，这个过程也称回表。\n\n**哪些情况需要创建索引**：\n\n 1. 主键自动建立唯一索引\n 2. 频繁作为查询条件的字段应该创建索引\n 3. 查询中与其他表关联的字段，外键关系应该建立索引\n 4. 频繁更新的字段不适合创建索引\n 5. where条件里用不到的字段不创建索引\n 6. 查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度\n 7. 查询中统计或者分组的字段\n\n\n**哪些情况不需要创建索引**：\n\n 1. 表记录太少\n 2. 经常增删改的表\n 3. 数据列有许多重复的内容\n\n\n**索引优化**：\n\n - 覆盖索引\n - 最左前缀原则\n - 索引下推\n\n**参考**：\n\n 1. [Mysql索引相关知识](https://blog.csdn.net/Alen_xiaoxin/article/details/109258848)\n 2. [Mysql索引概念相关知识](https://blog.csdn.net/Lucien010230/article/details/115547721)\n 3. Mysql45讲\n","tags":["Mysql"]},{"title":"Mysql相关知识（二）","url":"/2021/04/09/Mysql/Mysql相关知识(二)/","content":"\n>本文介绍Mysql操作和语句相关知识，包括增删改查、建表、函数、过程等相关知识。\n\n### 1.操作\n**连接Mysql**：\n\n```yaml\nmysql -h 主机地址 -u 用户名 -p 密码\n\n本地连接：\nmysql -u root -p\n```\n**修改密码**：\n\n```yaml\nmysqladmin -u 用户名 -p 旧密码 password 新密码\n\n或者\n\nalter user `username`@`host` identified by 'password'\n```\n\n**增加权限**：\n\n```yaml\ngrant all privileges on databasename.tablename to 用户名@登录主机 identified by 密码\n\n增加一个用户 test1 密码为 abc，让他可以在任何主机上登录，并对所有数据库\n有查询、插入、修改、删除的权限：\n\ngrant select,insert,update,delete on . to `test1`@`localhost` identified by \"abc\"\n```\n\n**删除授权**：\n\n```yaml\nrevoke all privileges on  databasename.tablename from `username`@`host`\n```\n**创建用户**：\n\n```yaml\ncreate user `username`@`host` identified by 'password'\n\n要求使用ssl登录\ncreate user `username`@`host` identified by 'password' require ssl;\n```\n\n**锁定用户**\n\n```yaml\nalter user `username`@`host` account lock;\n\n解锁\nalter user `username`@`host` account unlock;\n```\n**删除用户**：\n\n```yaml\ndrop user `username`@`host`\n```\n\n\n### 2.常用命令\n**数据库**：\n\n```yaml\nshow databases; #显示数据库\n\ncreate database [if not exists] t [character set='utf8']; #建数据库\n\nuse t; #使用数据库\n\ndrop database t; #删除数据库\n\nshow tables; #显示表\n\n#建表\nCREATE TABLE `T` (\n  `id` int NOT NULL AUTO_INCREMENT,\n  `a` varchar(30) DEFAULT NULL,\n  `b` int DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;\n\n#查看建表语句\nshow create table `T`;\n\n#显示表结构\ndesc T;\n\n#删除表\ndrop table [if exists] T;\n```\n\n**表复制、备份、清除**\n\n```yaml\n#会造成索引丢失，只有表结构，没有主键等信息。\ncreate table 新表名 select * from T;\n或\ncreate table 新表名 as(select * from T);\n\n#讲旧表中的数据移入新表\ninsert into 新表 select * from T;\n\n#清空表数据\ntruncate table T;\n```\n\n**表相关操作**：\n\n```yaml\n#修改列名\nalter table T change <原字段名称> <新字段名称 字段类型>\n\n#修改表名\nalter table T rename newT\n\n#修改字段类型及指定是否为空\nalter table T modify(or change) <字段名称> <字段类型> [not null]\n\n#增加一个字段\nalter table T add column 字段名称 字段类型 (after 某个字段) (first)\n\n#删除字段\nalter table <表名称> drop column <列名>;\n```\n\n**查表**：\n\n```yaml\nSELECT [DISTINCT] <字段名称,用逗号隔开/*>\n\nFROM <left_table> [<join_type> JOIN <right_table> ON <连接条件>]\n\nWHERE <where条件>\n\nGROUP BY <分组字段>\n\nHAVING <筛选条件>\n\nORDER BY <排序条件> [desc/asc]\n\nLIMIT n[, m]\n```\n\n**增改删**：\n\n```yaml\n#增加数据\ninsert into T values();\n\n#更改数据\nupdate T set *** where ** = **\n\n#删除数据\ndelete FROM T WHERE ** = **\n```\n\n**索引**：\n\n```yaml\n#创建索引\n-- 普通索引\nALTER TABLE 表名称 ADD INDEX index_name (column_list)\n-- 唯一索引\nALTER TABLE 表名称 ADD UNIQUE (column_list)\n-- 主键索引\nALTER TABLE 表名称 ADD PRIMARY KEY (column_list)\n\n或者\nCREATE INDEX index_name ON 表名称 (column_list)\n\n#删除索引\nDROP INDEX index_name ON 表名称;\nALTER TABLE 表名称 DROP INDEX index_name;\n#删除主键\nalter table T drop primary key;\n\n#查看索引\nshow index from T;\nshow keys from T;\n```\n**变量**：\n\n```yaml\n#查看满足条件的部分系统变量\nshow global | session variables like '%char%';\n查看指定的某个系统变量的值\nselect @@global|session.系统变量名;\n\n#为某个系统变量赋值\nset global|session 系统变量名 = 值;\n或\nset @@global|session.系统变量名 = 值;\n\n#用户变量声明并初始化\nset @用户变量名=值\n\n#使用\nselect @用户变量名\n\n#声明局部变量\ndeclare 变量名 类型;\ndeclare 变量名 类型 default 值;\n\n#赋值和使用同用户变量一样\n```\n**存储过程**：\n\n```yaml\n#创建存储过程\ncreate procedure 存储过程名(参数列表)\nbegin\n\t方法体(一组合法的sql语句)\nend\n\n#存储过程的结尾可以使用delimiter重新设置\ndelimiter 结束标志\n例：\ndelimiter $\n\n#创建过程\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i, i, i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\n\n#调用\ncall idata();\n\n#查看存储过程\nshow create procedure 存储过程名;\n#删除存储过程\ndrop procedure 存储过程名;\n```\n\n**函数**：\n\n```yaml\n#创建函数\ncreate function 函数名（参数列表）returns 返回类型\nbegin\n函数体\nend\n\n注意事项：\n1.参数列表包含两部分：参数名 参数类型\n2.函数体：必须要有return语句，没有回报错。如果return语句没有放在函数体的最后也不报错，但不建议\n3.begin end用法与存储过程相同，\n\n#调用语法\nselect 函数名（参数列表）\n\n#例\ncreate function myfunc() returns int\nbegin\n\tdeclare c int default 0;\n\tselect count(*) into c\n\tfrom T;\n\treturn c;\nend;\n\nselect myfunc();\n\n#查看函数\nshow create function 函数名;\n#删除函数\ndrop function 函数名;\n```\n\n**参考**：\n\n 1. [Mysql-视图、变量、存储过程以及函数](https://blog.csdn.net/zSoaring/article/details/115370995)\n 2. [Mysql语句大全](https://www.ucloud.cn/yun/49368.html)\n","tags":["Mysql"]},{"title":"Mysql相关知识（一）","url":"/2021/04/07/Mysql/Mysql相关知识(一)/","content":"\n>本文介绍Mysql相关知识，主要包括Mysql的基础架构、事务、索引和日志等知识。\n\n### 基础架构\n**基础架构示意图**：\n\n - 连接器：管理连接，权限验证\n - 查询缓存：命中则直接返回结果\n - 分析器：词法分析，语法分析\n - 优化器：执行计划生成，索引选择\n - 执行器：操作引擎，返回结果\n - 存储引擎：存储数据，提供读写接口\n\nMysql可以分为Server层和存储引擎层，不同的存储引擎公用一个Server层，常见的存储引擎有InnoDB、MyISAM、Memory等，现在Mysql主要使用InnoDB做存储引擎。\n\n大多数情况下不要使用查询缓存，因为查询缓存失效非常频繁，只要对一个表有更新，这个表上的所有存储查询缓存都会被清空。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210407093017389.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n### 日志\n**redo log**：当有一条记录需要更新时，InnoDB引擎会先把记录写到redo log，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候。\n\nredo log这种机制可以保证即使数据库发生异常重启，之前提交的记录也不会丢失，这个称为crash-safe。\n\nredo log是InnoDB存储引擎特有的日志，而Server层也有自己的日志，称为bin log。\n\n**bin log**：MySQL的Server层实现的，所有引擎都可以使用。binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\n\n**两种日志的不同**：\n\n 1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。\n 2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。\n 3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n**两阶段提交**：\n![两阶段提交](https://img-blog.csdnimg.cn/20210407161757189.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。\n\n### 索引\n索引是为了提高查询效率，实现索引的方式有很多种：\n\n - 哈希表\n - 有序数组\n - 搜索树\n\n**哈希表**：适用于只有等值查询的场景，区间查询会搜索整个哈希表\n\n**有序数组**：等值查询和区间查询场景中的性能都很优秀，但插入和删除数据需要移动后面的记录，代价太大。只适用于静态存储引擎。\n\n**搜索树**：使用N叉树，减小树高，提高查询效率。\n\n**InnoDB中，表是根据主键顺序以索引形式存放的，这种存储方式称为索引组织表，使用了B+树索引模型。**\n\n主键索引的叶子节点存的是整行的数据(聚簇索引)，非主键索引的叶子节点内容是主键的值(二级索引)\n\n使用非主键索引的查询需要多扫描一颗索引树，称为回表，因此尽量使用主键查询。\n\n一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据页合并，合并的过程是分裂过程的逆过程。\n\n**索引覆盖**：可以直接提供查询结果，不需要回表，索引已经“覆盖了”查询需求。\n索引覆盖可以减少树的搜索次数，提升查询性能。\n\n**最左前缀**：B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n\n**索引下推**：可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n\n","tags":["Mysql"]},{"title":"Java线程池相关知识","url":"/2021/04/01/Java 并发/Java线程池/","content":">本文介绍Java线程池相关知识\n\n### 前言\n**线程池**：线程池是一种基于池化思想管理线程的工具，经常出现再多线程服务器中。\n\n**线程池解决的问题是什么**：\n线程池解决的核心问题就是资源管理问题。在并发环境下，系统不能确定任意时刻，有多少任务需要执行，有多少资源需要投入。会存在下列问题：\n\n 1. 频繁申请/销毁资源和调度资源，将带来额外的消耗，可能会非常巨大。\n 2. 对资源无限申请缺乏抑制手段，可能会引发系统资源耗尽的风险。\n 3. 系统无法合理管理内部的资源分布，会降低系统的稳定性。\n\n为解决资源分配这个问题，线程池采用了“池化”（Pooling）思想。池化，顾名思义，是为了最大化收益并最小化风险，而将资源统一在一起管理的一种思想。\n\n**线程池的优点**：\n\n - 降低资源消耗：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。\n - 提高响应速度：任务到达时，无需等待线程创建即可立即执行。\n - 提高线程的可管理性：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。\n - 提供更多更强大的功能：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。\n\n### TheadPoolExecutor源码设计\nJava中线程池核心实现类是ThreadPoolExecutor,它的继承关系：\n![ ThreadPoolExecutor 继承关系](https://img-blog.csdnimg.cn/2021040116000948.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n\n**运行机制**：\nThreadPoolExecutor内部实际上构建了一个生产者消费者模型，将线程和任务两者解耦，并不直接关联。线程池的运行主要分为两部分：任务管理、线程管理。任务管理部分充当生产者的角色，当任务提交后，线程池会判断该任务后续的流转：\n\n 1. 直接申请线程执行任务\n 2. 缓存到队列中等待线程执行\n 3. 拒绝该任务\n\n线程管理部分是消费者，它们被统一维护在线程池内，根据任务请求进行线程的分配，当线程执行完任务后会继续获取新的任务去执行，最终当线程获取不到任务时，线程就会被回收。\n\n![ThreadPoolExecutor运行流程](https://img-blog.csdnimg.cn/img_convert/3d9113e3961a68dc85fe6e15fd52ea70.png#pic_center)\n\n**运行状态**：\nThreadPoolExecutor的运行状态有5种，分别为：\n\n| 运行状态 | 状态描述 |\n|---|---|\n| RUNNING | 能接受新提交的任务，且也能处理阻塞队列中的任务 |\n| SHUTDOWN | 不再接受新提交的任务，但是能处理阻塞队列中的任务 |\n| STOP | 不能接受新提交的任务，也不能处理阻塞队列中的任务，会中断正在处理任务的线程 |\n| TIDYING | 所有任务都已经终止了，workerCount（有效线程数）为0 |\n| TERMINATED | 在terminated()方法执行完后进入该状态 |\n\n其生命周期转换如下入所示：\n![线程池生命周期](https://img-blog.csdnimg.cn/img_convert/432693a9f531da06274114af24421f9b.png#pic_center)\n**任务调度**：\n当使用execute方法提交一个任务到ThreadPoolExecutor时，会检查现在的线程池运行状态、运行线程数、运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。其执行过程如下：\n\n 1. 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。\n 2. 如果workerCount < corePoolSize，则创建并启动一个线程来执行新提交的任务。\n 3. 如果workerCount >= corePoolSize，则判断任务阻塞队列是否已满，若未蛮则将任务添加到该阻塞队列，若已满则判断工作线程数是否大于最大线程数，如果小于，则创建并启动一个线程来执行新提交的任务，如果大于则根据拒绝策略来处理该任务，默认的处理方式是直接抛异常。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/c56abc7d2dec4791faccebd708452fd6.png#pic_center)\n**任务申请**：\n由上文的任务分配部分可知，任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。\n![任务流程图](https://img-blog.csdnimg.cn/img_convert/11553b961689e8854be6c5745e657ff1.png#pic_center)\n**任务拒绝**：\n拒绝策略是一个接口：\n```java\n\tpublic interface RejectedExecutionHandler {\n\t    void rejectedExecution(Runnable r, ThreadPoolExecutor executor);\n\t}\n```\n用户可以通过实现这个接口去定制拒绝策略，也可以选择JDK提供的四种已有拒绝策略，其特点如下：\n![拒绝策略](https://img-blog.csdnimg.cn/img_convert/f7f391628940c6cfe8ba7e568ef6a03d.png#pic_center)\n\n**Worker线程**：\nWorker这个工作线程，实现了Runnable接口，并持有一个线程Thread，一个初始化的任务firstTask。thread是在调用构造方法时通过ThreadFactory来创建的线程，firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。\n\n线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。\n\nWorker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。\n\n**addWorker增加工作线程**：\n\n```java\nprivate boolean addWorker(Runnable firstTask, boolean core) {\n}\n```\naddWorker方法有两个参数：firstTask、core。firstTask参数用于指定新增的线程执行的第一个任务，该参数可以为空；core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize\n\n**执行流程**：\n![执行流程](https://img-blog.csdnimg.cn/img_convert/e21ae15778df5b8028bb9088424d196a.png#pic_center)\n**参考**：\n\n 1. [Java线程池实现原理](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)\n","tags":["Java并发"]},{"title":"二叉树相关知识","url":"/2021/03/31/算法/树/二叉树/","content":"\n\n>本文介绍二叉树相关知识\n\n**定义**：树的任意节点至多包含两棵子树。\n\n**数据存储**：\n\n - 链表\n - 数组\n\n**链表方式定义**\n\n```java\npublic class TreeNode {\n    public int val;\n    public TreeNode left;\n    public TreeNode right;\n    \n    public TreeNode(int val) {\n        this.val = val;\n    }\n    \n    public TreeNode(int val, TreeNode left, TreeNode right) {\n        this.val = val;\n        this.left = left;\n        this.right = right;\n    }\n}\n```\n\n**二叉树的遍历**\n\n**递归：**\n\n```java\n    //前序遍历\n    public void preOrder(TreeNode root){\n        if (root == null){\n            return;\n        }\n\n        System.out.println(root.val);\n        preOrder(root.left);\n        preOrder(root.right);\n    }\n\t//中序遍历\n    public void inOrder(TreeNode root){\n        if (root == null){\n            return;\n        }\n        inOrder(root.left);\n        System.out.println(root.val);\n        inOrder(root.right);\n    }\n\t//后序遍历\n    public void postOrder(TreeNode root){\n        if (root == null){\n            return;\n        }\n        inOrder(root.left);\n        inOrder(root.right);\n        System.out.println(root.val);\n    }\n\t\n\t//层序遍历\n    public void BFSOrder(TreeNode root){\n        if (root == null){\n            return;\n        }\n\n        Queue<TreeNode> queue = new LinkedList<TreeNode>();\n        TreeNode temp = null;\n        queue.offer(root);\n        while (!queue.isEmpty()){\n            temp = queue.poll();\n            System.out.println(temp.val);\n            if (temp.left != null){\n                queue.offer(temp.left);\n            }\n            if (temp.right != null){\n                queue.offer(temp.right);\n            }\n        }\n    }\n```\n\n**迭代**：\n\n```java\n    //前序\n    public List<Integer> preorderTraversal(TreeNode root) {\n        List<Integer> list = new ArrayList<>();\n        if (root == null) {\n            return list;\n        }\n        Deque<TreeNode> deque = new LinkedList<>();\n        while (!deque.isEmpty() || root != null){\n            if (root != null){\n                list.add(root.val);\n                deque.push(root);\n                root =root.left;\n            }else {\n                TreeNode tmp = deque.pop();\n                root = tmp.right;\n            }\n        }\n        return list;\n    }\n\n\t//中序\n    public List<Integer> preorderTraversal(TreeNode root) {\n        List<Integer> list = new ArrayList<>();\n        if (root == null) {\n            return list;\n        }\n        Deque<TreeNode> deque = new LinkedList<>();\n        while (!deque.isEmpty() || root != null){\n            if (root != null){\n                deque.push(root);\n                root =root.left;\n            }else {\n                TreeNode tmp = deque.pop();\n                list.add(tmp.val);\n                root = tmp.right;\n            }\n        }\n        return list;\n    }\n\n\t//后序  反转前序操作 先添加队首添加节点  先循环右子树  再循环左子树\n    public List<Integer> postorderTraversal(TreeNode root) {\n        List<Integer> list = new ArrayList<>();\n        if (root == null) {\n            return list;\n        }\n        Deque<TreeNode> deque = new LinkedList<>();\n        while (!deque.isEmpty() || root != null){\n            if (root != null){\n                deque.push(root);\n                list.add(0,root.val);\n                root =root.right;\n            }else {\n                TreeNode tmp = deque.pop();\n                root = tmp.left;\n            }\n        }\n        return list;\n    }\n```\n\n**二叉搜索树 （BST）**\n\n**定义**：\n\n - 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n - 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n - 任意节点的左、右子树也分别为二叉查找树。\n - 没有键值相等的节点。\n\n**链表方式实现**：\n\n```java\npublic class BSTree<T extends Comparable<T>> {\n\n    private BSTNode<T> mRoot;    // 根结点\n\n    public class BSTNode<T extends Comparable<T>> {\n        public T key;                // 关键字(键值)\n        public BSTNode<T> left;      // 左孩子\n        public BSTNode<T> right;     // 右孩子\n        public BSTNode<T> parent;    // 父结点\n\n        public BSTNode(T key, BSTNode<T> parent, BSTNode<T> left, BSTNode<T> right) {\n            this.key = key;\n            this.parent = parent;\n            this.left = left;\n            this.right = right;\n        }\n    }\n}\n```\n","tags":["算法","树"]},{"title":"Spring bean的生命周期相关知识","url":"/2021/03/30/Spring/Spring bean生命周期/","content":"\n>本文简单介绍Spring bean的生命周期相关知识\n\n### Spring IOC 简介\n**IOC**：Inversion of Control,即控制反转。传统Java程序中，我们是自己创建对象，而Spring IoC 是有一个容器来保管我们创建的对象，即将对象交给Spring 容器进行管理。\n\n**bean**：在 Spring 中，构成应用程序主干并由 Spring IoC 容器管理的对象称为 bean。 bean 是一个由 Spring IoC 容器实例化，组装和管理的对象。\n\n**BeanDefinition**：bean的定义类，用来存储bean的所有属性和方法。\n\n**BeanFactory**：BeanFactory接口是Spring IoC的基础。\n\n**ApplicationContext**：是BeanFactory的子接口，同时还继承了其他的接口，是相对比较高级的 IoC 容器实现。\n\n**bean生命周期核心流程**：\n\n 1. 实例化\tInstantiation\n 2. 注入属性\t\tPopulate\n 3. 初始化\tInitialization\n 4. 销毁\tDestruction\n\n**bean生命周期经历了各种方法的调用，可以分为几类**：\n\n 1. Bean自身的方法：这个包括了Bean本身调用的方法和通过配置文件中<bean>的init-method和destroy-method指定的方法\n 2. Bean级生命周期接口方法：这个包括了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这些接口的方法\n 3. 容器级生命周期接口方法：这个包括了InstantiationAwareBeanPostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“后置处理器”。\n\n\n### Spring Bean生命周期\n![Spring bean生命周期](https://img-blog.csdnimg.cn/20210330191031791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n\n**测试代码**：[bean生命周期](https://github.com/ZouShuYou/sping-boot-demos/tree/master/spring-bean-lifecycle)\n\n\n### 扩展点\n**4个后置处理器**：\n\n 1. InstantiationAwareBeanPostProcessor\n 2. SmartInstantiationAwareBeanPostProcessor\n 3. MergedBeanDefinitionPostProcessor\n 4. SmartInitializingSingleton\n\n**影响多个Bean**：\n\n- BeanPostProcessor ：\n\t1. postProcessBeforeInitialization\n\t2. postProcessAfterInitialization\n- InstantiationAwareBeanPostProcessor\n\t1. postProcessBeforeInstantiation\n\t2. postProcessAfterInstantiation\n\t3. postProcessProperties\n- MergedBeanDefinitionPostProcessor\n\t1. postProcessMergedBeanDefinition\n- SmartInstantiationAwareBeanPostProcessor\n\t1. determineCandidateConstructors\n\t2. getEarlyBeanReference\n\n**影响单个Bean**：\n\n - BeanNameAware\n - BeanClassLoaderAware\n - BeanFactoryAware\n - EnvironmentAware\n - EmbeddedValueResolverAware\n - ApplicationContextAware\n - InitializingBean\n - DisposableBean\n\n\t\n**参考**：\n\n 1. [spring bean生命周期](https://blog.csdn.net/qq_23473123/article/details/76610052?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.baidujs&dist_request_id=1328740.50450.16170841210074475&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.baidujs)\n","tags":["Spring"]},{"title":"Java垃圾回收","url":"/2021/03/25/JVM/Java垃圾回收/","content":">本文介绍Java垃圾回收相关知识\n\n### 判断一个对象是否可以被回收\n回收对象首先需要判断这个对象是否可以被回收，Java虚拟机采用可达性分析算法判断。\n\n**引用计数算法**\n\n给对象添加一个引用计数器，当对象增加一个引用时计数器加一，减少一个引用时计数器减一。引用计数为 0 的对象可被回收。\n\n两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。\n\n正因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。\n\n\n**可达性分析算法**\n通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210325111314120.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\nJava 虚拟机使用该算法来判断对象是否可被回收，在 Java 中 GC Roots 一般包含以下内容:\n\n - 虚拟机栈中引用的对象\n - 本地方法栈中引用的对象\n - 方法区中类静态属性引用的对象\n - 方法区中常量引用的对象\n\n**方法区的回收**\n\n方法区的垃圾回收主要包括两部分：废弃的变量和不再使用的类型。\n\n判断一个常量是否废弃：当没有其他对象引用这个常量时，Java虚拟机会对这个常量进行回收。\n\n判断一个类型是否属于不再使用的类：\n\n - 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 \n - 加载该类的 ClassLoader 已经被回收。\n -  该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。\n\n### 引用类型\n**强引用**\n被强引用关联的对象不会被回收。\n\n使用 new 一个新对象的方式来创建强引用。\n\n```java\n\tObject obj = new Object();\n```\n\n**软引用**\n被软引用关联的对象，只有在虚拟机内存不足时才会被回收\n\n使用 SoftReference 类来创建软引用。\n```java\n\tObject obj = new Object();\n\tSoftReference<Object> sf = new SoftReference<Object>(obj);\n\tobj = null;  // 使对象只被软引用关联\n```\n\n**弱引用**\n被弱引用关联的对象，在虚拟机下一次GC时会被回收\n\n使用 WeakReference 类来实现弱引用。\n```java\n\tObject obj = new Object();\n\tWeakReference<Object> sf = new WeakReference<Object>(obj);\n\tobj = null;  // 使对象只被软引用关联\n```\n\n**虚引用**\n又称为幽灵引用或者幻影引用。\n\n一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。 \n\n为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。 \n\n使用 PhantomReference 来实现虚引用。\n\n```java\n\tObject obj = new Object();\n\tPhantomReference<Object> pf = new PhantomReference<Object>(obj);\n\tobj = null;\n```\n### 垃圾回收算法\n**标记-清除**\n![](https://img-blog.csdnimg.cn/20210325132146534.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n首先标记所有需要回收的对象，标记完成后进行统一的回收，也可以反过来标记存活的对象，统一回收所有未被标记的对象。\n\n缺点：\n\n 1. 执行效率不稳定，标记和清除过程效率都不高；\n 2. 内存空间的碎片化\n\n**标记-整理**\n![](https://img-blog.csdnimg.cn/20210325132518976.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n在标记-清楚算法的基础上，让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n\n**标记-复制**\n![](https://img-blog.csdnimg.cn/2021032513285885.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。\n\n主要不足是只使用了内存的一半。\n\n现在的商业虚拟机都采用标记-复制算法来回收新生代，但是并不是将新生代分为大小相等的两块，而是分为一块较大的Eden空间和两块较小的Survivor空间。\n\n每次使用Eden空间和其中一块Survivor，在回收时，在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。\n\nHotSpot 虚拟机的 Eden 和 Survivor 的大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象\n\n**分代收集器**\n\n现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存分为几块，不同块采用适当的收集算法。\n\n一般将堆分为新生代和老年代：\n\n - 新生代使用 标记-复制 算法\n - 老年代使用 标记-整理 或者 标记-清除 算法\n\n### 内存分配与回收策略\n\n**Minor GC 和 Full GC**\n\n - Minor GC发生在新生代上，因为新生代上对象存活时间很短，所以Minor GC会频繁执行，执行的速度一般也很快。\n - Full GC发生在老年代，老年代对象存活时间长，因此Full GC很少执行，执行速度也比Minor GC慢很多\n\n**内存分配策略**\n\n - 对象优先在Eden上分配\n - 大对象直接进入老年代\n - 长期存活的对象进入老年代\n - 动态对象年龄判定\n - 空间分配担保\n\n**回收条件**\n\n对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件:\n\n - 调用 System.gc()\n - 老年代空间不足\n - 空间分配担保失败\n - JDK 1.7 及以前的永久代空间不足\n - Concurrent Mode Failure\n\n**参考**\n\n 1. 深入理解Java虚拟机\n 2. [Java 垃圾回收基础](https://www.pdai.tech/md/java/jvm/java-jvm-gc.html)\n","tags":["JVM"]},{"title":"深入了解JVM内存结构","url":"/2021/03/24/JVM/Java虚拟机内存结构/","content":"\n>本文主要介绍JVM内存结构相关知识，需要注意JVM内存结构和Java内存模型是两个概念。\n\n### 运行时数据区\nJava虚拟机在执行程序时会把它所管理的内存划分为若干个不同的数据区域。这些区域有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而一直存在，有些区域则依赖用户线程的启动和结束而建立和销毁。\n\n下图是 JVM 整体架构，中间部分就是 Java 虚拟机定义的各种运行时数据区域。\n在这里插入图片描述\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210324150056997.jpg?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n>下面介绍下这些内存结构\n\n### 程序计数器\n程序计数器（program counter  register）是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指令器。\n\n - 在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致。\n - 在任何一个时刻，一个处理器都只会处理一条线程中的指令，因此为了线程切换后能恢复到正确的执行位置，每条线程都要有一个独立的程序计数器，各条线程之间的计数器互不影响，我们称这类区域为“线程私有”区域。\n - 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成\n - 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令\n - 它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域\n\n### 虚拟机栈\n与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。\n\n**Java虚拟机栈描述的是Java方法执行的线程内存模型：每个方法被执行时，Java虚拟机都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。**\n\n**栈不存在垃圾回收的问题**：进栈和出栈，出栈相当于释放内存。\n\n栈中可能出现的异常：\n\n - 如果采用固定大小的 Java 虚拟机栈，那每个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常\n - 如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个OutOfMemoryError异常\n\n可以通过参数-Xss来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。\n\n**栈帧是虚拟机栈的最小单位**：在用idea进行debug时，看到的就是一个个栈帧。\n\n**栈帧的内部结构**：\n\n- 局部变量表：主要用于存储方法参数和定义在方法体内的局部变量\n- 操作数栈：主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间\n- 动态链接：指向运行时常量池的方法引用\n- 方法返回地址：方法正常退出或异常退出的地址\n- 一些附加信息\n\n### 本地方法栈\n本地方法栈与虚拟机栈所发挥的作用是非常相似的，其区别是虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则是为虚拟机使用到的本地方法服务。\n\n本地方法栈也是线程私有的。\n\n>**栈是运行时的单位，而堆是存储的单位。**\n>\n>栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。\n\n### 堆\n对Java程序来说，Java堆是虚拟机所管理的内存中最大的一块。Java堆是被所有线程所共享的一块内存区域，在虚拟机启动时创建。\n\n**此内存区域的唯一目的就是存放对象实例**\n\n为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）：\n\n - 新生代（年轻代）：新对象和没达到一定年龄的对象都在新生代\n - 老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大\n - 元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存\n![内存区域](https://img-blog.csdnimg.cn/20210324161121304.jpg#pic_center)\nJava 虚拟机规范规定，Java 堆可以是处于物理上不连续的内存空间中，只要逻辑上是连续的即可，像磁盘空间一样。实现时，既可以是固定大小，也可以是可扩展的，主流虚拟机都是可扩展的（通过 -Xmx 和 -Xms 控制），如果堆中没有完成实例分配，并且堆无法再扩展时，就会抛出 OutOfMemoryError 异常。\n\n**年轻代 (Young Generation)**\n\n年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为 Minor GC。年轻一代被分为三个部分——伊甸园（Eden Memory）和两个幸存区（Survivor Memory，被称为from/to或s0/s1），默认比例是8:1:1\n\n - 大多数新创建的对象都位于 Eden 内存空间中\n - 当 Eden 空间被对象填充时，执行Minor GC，并将所有幸存者对象移动到一个幸存者空间中\n - Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，总有一个幸存者空间是空的\n - 经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代\n\n**老年代(Old Generation)**\n\n旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major GC），通常需要更长的时间。\n\n大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝 \n\n### 方法区\n方法区与堆一样是被各个线程所共享的区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。\n\n虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。\n\n运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本/字段/方法/接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将类在加载后进入方法区的运行时常量池中存放。运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的是 String.intern()方法。受方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。\n\n除了和Java堆一样不需要连续的内存和可以选择内存大小或者可扩展外，方法区还可以选择不进行垃圾收集。这区域内存的回收目标主要是常量池的回收和对类型的卸载。\n\n**方法区（method area）只是 JVM 规范中定义的一个概念，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，并没有规定如何去实现它，不同的厂商有不同的实现。而永久代（PermGen）是 Hotspot 虚拟机特有的概念， Java8 的时候又被元空间取代了，永久代和元空间都可以理解为方法区的落地实现。**\n\n永久代物理是堆的一部分，和新生代，老年代地址是连续的（受垃圾回收器管理），而元空间存在于本地内存（我们常说的堆外内存，不受垃圾回收器管理），这样就不受 JVM 限制了，也比较难发生OOM（都会有溢出异常）\n\n所以对于方法区，Java8 之后的变化：\n\n - 移除了永久代（PermGen），替换为元空间（Metaspace）；\n - 永久代中的 class metadata 转移到了 native memory（本地内存，而不是虚拟机）；\n - 永久代参数 （PermSize MaxPermSize） -> 元空间参数（MetaspaceSize MaxMetaspaceSize）\n\n**栈、堆、方法区的交互关系**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210324165854810.png?x-oss-process=image,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n\n**参考**\n\n 1. 深入理解Java虚拟机\n 2. [JVM 基础 - JVM 内存结构](https://www.pdai.tech/md/java/jvm/java-jvm-struct.html)\n","tags":["JVM"]},{"title":"Spring 事务相关知识","url":"/2021/03/23/Spring/Spring事务/","content":"\n>本文介绍Spring事务相关的知识，包括事务隔离级别和事务传播特性。\n\n### 事务\n事务是逻辑上的一组操作，要么都执行，要么都不执行。我自己的理解是，数据库操作的最小单位，要么成功，要么失败。\n\n**特性：ACID**\n\n - 原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么全部失败回滚。\n - 一致性（Consistency）：数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。\n - 隔离性（Isolation）：一个事务所做的修改在最终提交以前，对其他事务是不可见的。\n - 持久性（Durability）：一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。\n\n### 事务隔离级别\n在并发环境下，事务的隔离性很难得到保证，因此会出现很多并发一致性的问题。\n\n**丢失修改**\nT1和T2 两个事务同时对一个数据进行修改，T1修改之后，T2又修改，T2的修改覆盖了T1的修改。\n\n**读脏数据**\nT1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。\n\n**不可重复读**\nT2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。\n\n**幻读**\nT1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。\n\n**不可重复读的重点是修改，幻读的重点在于新增或者删除。**\n\n在Spring中，TransactionDefinition 接口中定义了五个表示隔离级别的常量：\n\n 1. **TransactionDefinition.ISOLATION_DEFAULT**：使用数据库默认的事务隔离级别\n 2. **TransactionDefinition.ISOLATION_READ_UNCOMMITTED（未提交读）**：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读\n 3. **TransactionDefinition.ISOLATION_READ_COMMITTED（读已提交）**：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生\n 4. **TransactionDefinition.ISOLATION_REPEATABLE_READ（可重复读）**：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。\n 5. **TransactionDefinition.ISOLATION_SERIALIZABLE（串行化）**：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。\n\n### 事务的传播机制\n当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。在TransactionDefinition定义中包括了如下几个表示传播行为的常量：\n\n**支持当前事务**：\n\n - **TransactionDefinition.PROPAGATION_REQUIRED**：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。\n - **TransactionDefinition.PROPAGATION_SUPPORTS**： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。\n - **TransactionDefinition.PROPAGATION_MANDATORY**： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）\n\n**不支持当前事务**：\n\n - **TransactionDefinition.PROPAGATION_REQUIRES_NEW**： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。\n - **TransactionDefinition.PROPAGATION_NOT_SUPPORTED**： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。\n - **TransactionDefinition.PROPAGATION_NEVER**： 以非事务方式运行，如果当前存在事务，则抛出异常。\n\n**其他情况**：\n\n - **TransactionDefinition.PROPAGATION_NESTED**： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则创建一个新的事务。\n\n\n**参考**\n\n 1. [SQL DB - 数据库系统核心知识点](https://www.pdai.tech/md/db/sql/sql-db-theory.html)\n 2. [Spring事务管理详解](https://juejin.cn/post/6844903608224333838)\n 3. [Spring事务传播机制详解](https://blog.csdn.net/qq_26323323/article/details/81908955?utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control&dist_request_id=1328679.64251.16164914922937405&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.control)\n","tags":["Spring"]},{"title":"Java类加载机制","url":"/2021/03/22/JVM/Java虚拟机类加载过程/","content":"\n>本文简单介绍Java类加载相关知识\n\n### Java类的生命周期\n一个类从被加载到虚拟机内存到卸载出虚拟机内存，它的生命周期会经历：加载、验证、准备、解析、初始化、使用、卸载这七个阶段。其中验证、准备、解析三个部分统称为连接。\n![类的生命周期](https://img-blog.csdnimg.cn/20210322133225873.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n其中加载、验证、准备、初始化、卸载这五个阶段的顺序是确定的，类型的加载过程必须按这种顺序，而解析阶段却不一定，它在某些情况下可以在初始化之后再开始，这是为了支持Java语言运行时绑定特性（也称动态绑定）。\n\n另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。\n\n### 加载\n加载是整个类加载的过程中的一个阶段，在加载阶段，Java虚拟机需要完成三件事：\n\n 1. 通过一个类的全限定名来获取定义此类的二进制字节流\n 2. 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构\n 3. 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n\n相对于类加载的其他阶段而言，加载阶段(准确地说，是加载阶段获取类的二进制字节流的动作)是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。\n\n 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。\n\n类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误(LinkageError错误)如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。\n\n### 验证\n验证是连接的第一步，这一阶段的目的是确保Class文件的字节流信息符合规范，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作:\n\n 1. 文件格式验证： 验证字节流是否符合Class文件格式的规范；例如: 是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。\n 2. 元数据验证： 对字节码描述的信息进行语义分析(注意: 对比javac编译阶段的语义分析)，以保证其描述的信息符合Java语言规范的要求；例如: 这个类是否有父类，除了java.lang.Object之外。\n 3. 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。\n 4. 符号引用验证：确保解析动作能正确执行。\n\n### 准备\n准备阶段是正式为类中定义的变量（即静态变量， 被static修饰的变量） 分配内存并设置类变量初始值的阶段， **这些内存都将在方法区中分配。**\n\n这时候进行内存分配的仅包括类变量(static)，而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。\n\n这里所设置的初始值通常情况下是数据类型默认的零值(如0、0L、null、false等)，而不是被在Java代码中被显式地赋予的值。\n\n假设一个类变量的定义为: public static int value = 3；那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的put static指令是在程序编译后，存放于类构造器<clinit>()方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。\n\n### 解析\n解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。\n\n符号引用就是一组符号来描述目标，可以是任何字面量。 \n\n直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。\n\n### 初始化\n初始化为类的静态变量赋予正确的初始值，在Java中对类变量进行初始值设定有两种方式:\n\n - 声明类变量时指定初始化值\n - 使用静态代码块为类变量指定初始值\n\n### 使用\n类访问方法区内的数据结构， 对象是Heap区的数据。\n\n### 卸载\nJava虚拟机将结束生命周期的几种情况：\n\n - 执行了System.exit()方法\n - 程序正常执行结束\n - 程序在执行过程中遇到了异常或错误而异常终止\n - 由于操作系统出现错误而导致Java虚拟机进程终止\n\n### Java类加载机制\n**类加载器**\n**站在Java开发人员的角度来看，类加载器可以大致划分为以下三类 :**\n\n 1. 启动类加载器： Bootstrap ClassLoader，负责加载存放在JDK\\jre\\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库(如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载)。启动类加载器是无法被Java程序直接引用的。\n 2. 扩展类加载器：Extension ClassLoader，该加载器 sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库(如javax.*开头的类)，开发者可以直接使用扩展类加载器。\n 3. 应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径(ClassPath)所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210322180011328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**寻找类加载器**\n\n```java\npackage classloader;\n\npublic class ClassLoaderTest {\n    public static void main(String[] args) {\n        ClassLoader classLoader = ClassLoaderTest.class.getClassLoader();\n        System.out.println(classLoader.toString());\n        System.out.println(classLoader.getParent());\n        System.out.println(classLoader.getParent().getParent());\n\n    }\n}\n```\n结果如下:\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210322182737715.png)\n从上面的结果可以看出，当前类的加载器为AppClassLoader，它的父Loader是ExtClassLoader，并没有获取到ExtClassLoader的父Loader，原因是BootstrapLoader(引导类加载器)是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。\n\n**接着介绍下JVM的类加载机制：**\n - **全盘负责**：当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入。\n - **缓存机制**：缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效。\n - **双亲委派机制**： 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。\n\t1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。\n\t2、当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。\n\t3、如果BootStrapClassLoader加载失败(例如在$JAVA_HOME/jre/lib里未查找到该class)，会使用ExtClassLoader来尝试加载；\n\t4、若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。\n\n>这里的父类并不是继承关系，而是一种组合关系。\n\n**类加载器的默认加载路径**\n\n|类加载器|加载路径 |\n|-----|-----|\n| Bootstrap ClassLoader   | 由系统属性sun.boot.class.path指定，通常是$JAVA_HOME/jre/lib |\n| Extension ClassLoader   | 通常是$JAVA_HOMEx/jre/lib/ext，可通过系统属性java.ext.dirs查看路径  |\n| Application ClassLoader | 通常是当前路径下的Class文件，可通过系统属性java.class.path查看 |\n\n**双亲委托加载方向**\n\n<font color=#00f >类加载器在加载类时，只能向上递归委托其双亲进行类加载，而不可能从双亲再反向委派当前类加载器来进行类加载。</font>\n\n**双亲委派优势**\n\n - 系统类防止内存中出现多份同样的字节码\n - 保证Java程序安全稳定运行\n\n\n**参考**\n\n 1. 深入理解Java虚拟机\n 2. [JVM 基础 - Java 类加载机制](https://www.pdai.tech/md/java/jvm/java-jvm-classload.html#%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8-jvm%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6)\n","tags":["JVM"]},{"title":"深入了解LinkedHashMap","url":"/2021/03/16/Java Base/LinkedHashMap/","content":"\n>本文介绍LinkedHashMap的相关知识\n\n### 简介\n之前了解过HashMap，HashMap是无序的，当我们希望有顺序地去存储key-value时，就需要使用LinkedHashMap了。\n\nLinkedHashMap由哈希表+双向链表组成，它继承自HashMap，重写了HashMap的一些方法，可以用于LRU算法，它和HashMap一样不是线程安全的。\n```java\npublic class TestLinkedHashMap {\n    public static void main(String[] args) {\n        LinkedHashMap<String, String> linkedHashMap = new LinkedHashMap<String, String>(16,0.75f,true);\n        linkedHashMap.put(\"name1\", \"josan1\");\n        linkedHashMap.put(\"name2\", \"josan2\");\n        linkedHashMap.put(\"name3\", \"josan3\");\n        System.out.println(\"LinkedHashMap遍历时顺序：\");\n\n        for (Entry<String, String> entry : linkedHashMap.entrySet()){\n            String key = (String) entry.getKey();\n            String value = (String) entry.getValue();\n            System.out.println(\"key:\" + key + \",value:\" + value);\n        }\n\n        HashMap<String, String> hashMap = new HashMap<String, String>(16);\n        hashMap.put(\"name1\", \"josan1\");\n        hashMap.put(\"name2\", \"josan2\");\n        hashMap.put(\"name3\", \"josan3\");\n        System.out.println(\"HashMap遍历时顺序：\");\n\n        for (Entry<String, String> entry : hashMap.entrySet()){\n            String key = (String) entry.getKey();\n            String value = (String) entry.getValue();\n            System.out.println(\"key:\" + key + \",value:\" + value);\n        }\n\n    }\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210316102945365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n结果可知，LinkedHashMap是有序的，且默认为插入顺序。\n\n### 构造函数\n\n```java\npublic class LinkedHashMap<K,V>\n    extends HashMap<K,V>\n    implements Map<K,V>\n{\n\n    public LinkedHashMap() {\n        super();\n        //accessOrder默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。\n        accessOrder = false;\n    }\n\n    public LinkedHashMap(int initialCapacity) {\n        super(initialCapacity);\n        accessOrder = false;\n    }\n \t//指定初始化时的容量，和扩容的加载因子\n    public LinkedHashMap(int initialCapacity, float loadFactor) {\n        super(initialCapacity, loadFactor);\n        accessOrder = false;\n    }\n\n    public LinkedHashMap(int initialCapacity,\n                         float loadFactor,\n                         boolean accessOrder) {\n        super(initialCapacity, loadFactor);\n        this.accessOrder = accessOrder;\n    }\n\n    public LinkedHashMap(Map<? extends K, ? extends V> m) {\n        super();\n        accessOrder = false;\n        putMapEntries(m, false);\n    }\n}\n```\n**LinkedHashMap 继承了HashMap，实现了Map接口。**\n\nLinkedHashMap的accessOrder变量默认为false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。\n\n### 数据结构\n**Entry的next是用于维护HashMap指定table位置上连接的Entry的顺序的，before、After是用于维护Entry插入的先后顺序的。**\n\n```java\n\t//LinkedHashMap内部类 Entry继承HashMap的Node内部类，是一个双向链表\n    static class Entry<K,V> extends HashMap.Node<K,V> {\n        Entry<K,V> before, after;\n        Entry(int hash, K key, V value, Node<K,V> next) {\n            super(hash, key, value, next);\n        }\n    }\n```\n![结构图](https://img-blog.csdnimg.cn/20210316104728801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210316105558286.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n**该循环双向链表的头部存放的是最久访问的节点或最先插入的节点，尾部为最近访问的或最近插入的节点，迭代器遍历方向是从链表的头部开始到链表尾部结束。**\n\n### 增\nLinkedHashMap并没有重写任何put方法。但是其重写了构建新节点的newNode()方法.\nnewNode()会在HashMap的putVal()方法里被调用，putVal()方法会在批量插入数据putMapEntries()或者插入单个数据public V put(K key, V value)时被调用。\n\nLinkedHashMap重写了newNode()，在每次构建新节点时，通过linkNodeLast，将新节点链接在内部双向链表的尾部。\n\n```java\n    Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {\n        LinkedHashMap.Entry<K,V> p =\n            new LinkedHashMap.Entry<K,V>(hash, key, value, e);\n        linkNodeLast(p);\n        return p;\n    }\n\n    private void linkNodeLast(LinkedHashMap.Entry<K,V> p) {\n        LinkedHashMap.Entry<K,V> last = tail;\n        //tail 指向尾节点即插入的节点\n        tail = p;\n        if (last == null)\n            head = p;\n        else {\n            p.before = last;\n            last.after = p;\n        }\n    }\n```\n**HashMap专门预留给LinkedHashMap的afterNodeAccess() afterNodeInsertion() afterNodeRemoval() 方法。**\n\n```java\n    // Callbacks to allow LinkedHashMap post-actions\n    void afterNodeAccess(Node<K,V> p) { }\n    void afterNodeInsertion(boolean evict) { }\n    void afterNodeRemoval(Node<K,V> p) { }\n```\n\n```java\n    //回调函数，新节点插入之后回调 ， 根据evict 和   判断是否需要删除最老插入的节点。如果实现LruCache会用到这个方法。\n    void afterNodeInsertion(boolean evict) { // possibly remove eldest\n        LinkedHashMap.Entry<K,V> first;\n        //LinkedHashMap 默认返回false 则不删除节点\n        if (evict && (first = head) != null && removeEldestEntry(first)) {\n            K key = first.key;\n            removeNode(hash(key), key, null, false, true);\n        }\n    }\n    //LinkedHashMap 默认返回false 则不删除节点。 返回true 代表要删除最早的节点。通常构建一个LruCache会在达到Cache的上限是返回true\n    protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {\n        return false;\n    }\n```\n\n### 删\nLinkedHashMap也没有重写remove()方法，因为它的删除逻辑和HashMap并无区别。\n但它重写了afterNodeRemoval()这个回调方法。该方法会在Node<K,V> removeNode()方法中回调，removeNode()会在所有涉及到删除节点的方法中被调用。\n\n```java\n\t//双向链表删除节点\n    void afterNodeRemoval(Node<K,V> e) { // unlink\n        LinkedHashMap.Entry<K,V> p =\n            (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;\n        //要删除的节点p before和after 置空\n        p.before = p.after = null;\n        //p的前置节点为null，则p是头节点，head指向p的后置节点\n        if (b == null)\n            head = a;\n        else//b不为null，b的后置节点为p的后置节点\n            b.after = a;\n        //p的后置节点为null，则p是尾节点，tail指向p的前置节点\n        if (a == null)\n            tail = b;\n        else//a不为null，a的前置节点为p的前置节点\n            a.before = b;\n    }\n```\n\n### 改\n更改value时，发生hash冲突，逻辑和HashMap的put逻辑一样。\n\n### 查\n重写了HashMap的get方法，调用getNode方法，LinkedHashMap只是增加了在成员变量(构造函数时赋值)accessOrder为true的情况下，要去回调void afterNodeAccess()函数，在afterNodeAccess()函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。\n```java\n    public V get(Object key) {\n        Node<K,V> e;\n        if ((e = getNode(hash(key), key)) == null)\n            return null;\n        if (accessOrder)\n            afterNodeAccess(e);\n        return e.value;\n    }\n\n    void afterNodeAccess(Node<K,V> e) { // move node to last\n        LinkedHashMap.Entry<K,V> last;//原尾节点\n        //如果accessOrder 是true ，且原尾节点不等于e\n        if (accessOrder && (last = tail) != e) {\n            //节点e强转成双向链表节点p\n            LinkedHashMap.Entry<K,V> p =\n                (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;\n            //p现在是尾节点， 后置节点一定是null\n            p.after = null;\n            //如果p的前置节点是null，则p以前是头结点，所以更新现在的头结点是p的后置节点a\n            if (b == null)\n                head = a;\n            else//否则更新p的前直接点b的后置节点为 a\n                b.after = a;\n            //如果p的后置节点不是null，则更新后置节点a的前置节点为b\n            if (a != null)\n                a.before = b;\n            else//如果原本p的后置节点是null，则p就是尾节点。 此时 更新last的引用为 p的前置节点b\n                last = b;\n            if (last == null) //原本尾节点是null  则，链表中就一个节点\n                head = p;\n            else {//否则 更新 当前节点p的前置节点为 原尾节点last， last的后置节点是p\n                p.before = last;\n                last.after = p;\n            }\n            //尾节点的引用赋值成p\n            tail = p;\n            //修改modCount。\n            ++modCount;\n        }\n    }\n```\n### containsValue\nLinkedHashMap重写了该方法，相比HashMap的实现，遍历双向链表更为高效。\n```java\n    public boolean containsValue(Object value) {\n        for (LinkedHashMap.Entry<K,V> e = head; e != null; e = e.after) {\n            V v = e.value;\n            if (v == value || (value != null && value.equals(v)))\n                return true;\n        }\n        return false;\n    }\n```\n对比HashMap，是用两个for循环遍历，相对低效。\n\n```java\n    public boolean containsValue(Object value) {\n        Node<K,V>[] tab; V v;\n        if ((tab = table) != null && size > 0) {\n            for (int i = 0; i < tab.length; ++i) {\n                for (Node<K,V> e = tab[i]; e != null; e = e.next) {\n                    if ((v = e.value) == value ||\n                        (value != null && value.equals(v)))\n                        return true;\n                }\n            }\n        }\n        return false;\n    }\n```\n\n**总结**\n\n 1. LinkedHashMap通过继承HashMap重写了它的一些方法，实现了有序性。\n 2. accessOrder ,默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。为true时，可以在这基础之上构建一个LRUCache。\n 3. LinkedHashMap不是线程安全的，内部结构是哈希表+双向链表。\n 4. LinkedHashMap和HashMap一样，允许一对键值为null，key不能重复，但value可以重复。\n\n**参考**\n\n 1. [LinkedHashMap源码解析（JDK8）](https://blog.csdn.net/zxt0601/article/details/77429150)\n 2. [图解LinkedHashMap原理](https://www.jianshu.com/p/8f4f58b4b8ab)\n 3. [Java集合之LinkedHashMap](https://www.cnblogs.com/xiaoxi/p/6170590.html)\n","tags":["Java集合"]},{"title":"FIFO、LRU、LFU三种缓存淘汰算法","url":"/2021/03/16/算法/缓存淘汰算法/","content":"\n>本文介绍三种常用缓存淘汰算法，即它们的简单实现。\n\n### 简介\n**缓存，就是将程序或系统经常要调用的对象存在内存中，再次调用时可以快速从内存中获取对象，不必再去创建新的重复的实例。**\n当缓存中的数据太多超过一定值时，通常会采取一些缓存淘汰算法进行处理。\n\n### FIFO（先进先出）\nFIFO即先进先出算法，队列也具有先进先出的性质，所以可以考虑采用LinkedList实现FIFO算法。但是只用LinkedList的话，查找时时间复杂度为O(n)，所以可以考虑采用HashMap+LinkedList实现。\n\n```java\npublic class FIFOCache<K,V>{\n    private Map<K,V> cache;\n    private LinkedList<K> list;\n    private volatile int maxCapacity;\n    private final Lock lock;\n\n    public FIFOCache(){\n        this(1000);\n    }\n\n    public FIFOCache(int maxCapacity){\n        this.maxCapacity = maxCapacity;\n        this.lock = new ReentrantLock();\n        this.cache = new HashMap<>();\n        this.list = new LinkedList<>();\n    }\n\n    public V get(K key){\n        this.lock.lock();\n\n        V var;\n        try {\n            var = this.cache.get(key);\n        }finally {\n            this.lock.unlock();\n        }\n        return var;\n    }\n\n    public void put(K key, V value){\n        this.lock.lock();\n\n        try {\n            this.list.addLast(key);\n            if (maxCapacity < this.list.size()){\n                K k = this.list.getFirst();\n                cache.remove(k);\n                this.list.removeFirst();\n            }\n            this.cache.put(key, value);\n        }finally {\n            this.lock.unlock();\n        }\n    }\n\n    @Override\n    public String toString() {\n        return \"FIFOCache{\" +\n                \"cache=\" + cache +\n                \", list=\" + list +\n                \", maxCapacity=\" + maxCapacity +\n                \", lock=\" + lock +\n                '}';\n    }\n}\n```\n**测试类**\n\n```java\npublic class TestFIFO {\n    public static void main(String[] args) {\n        FIFOCache<String,String> fifoCache = new FIFOCache<String,String>(3);\n\n        fifoCache.put(\"1\",\"a\");\n        fifoCache.put(\"2\",\"b\");\n        fifoCache.put(\"3\",\"c\");\n        fifoCache.put(\"4\",\"d\");\n\n        System.out.println(fifoCache.toString());\n\n        System.out.println(fifoCache.get(\"2\"));\n    }\n}\n```\n![FIFO算法](https://img-blog.csdnimg.cn/20210316143819142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n### LRU（最近最久未使用）\nLRU（The Least Recently Used，最近最久未使用算法）是一种常见的缓存算法，在很多分布式缓存系统（如Redis, Memcached）中都有广泛使用。\n\n**LRU算法的思想是：如果一个数据在最近一段时间没有被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最久没有访问的数据最先被置换（淘汰）。**\n\n**实现**\n\n 1. 数组+时间戳 （时间复杂度较高O(n)）\n 2. 链表 （查询时间复杂度还是O(n)）每次将访问到的节点移到链表尾部\n 3. 哈希表+双向链表（LinkedHashMap）\n\n**Dubbo中的LRU实现**\n```java\npackage cache;\n\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-03-16 14:46\n */\npublic class LRUCache<K, V> extends LinkedHashMap<K, V> {\n    \n    private static final float DEFAULT_LOAD_FACTOR = 0.75F;\n    private static final int DEFAULT_MAX_CAPACITY = 1000;\n    private final Lock lock;\n    private volatile int maxCapacity;\n\n    public LRUCache() {\n        this(1000);\n    }\n\n    public LRUCache(int maxCapacity) {\n        super(16, 0.75F, true);\n        this.lock = new ReentrantLock();\n        this.maxCapacity = maxCapacity;\n    }\n\n    @Override\n    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {\n        return this.size() > this.maxCapacity;\n    }\n\n    @Override\n    public boolean containsKey(Object key) {\n        this.lock.lock();\n\n        boolean var2;\n        try {\n            var2 = super.containsKey(key);\n        } finally {\n            this.lock.unlock();\n        }\n\n        return var2;\n    }\n\n    @Override\n    public V get(Object key) {\n        this.lock.lock();\n\n        Object var2;\n        try {\n            var2 = super.get(key);\n        } finally {\n            this.lock.unlock();\n        }\n\n        return (V) var2;\n    }\n\n    @Override\n    public V put(K key, V value) {\n        this.lock.lock();\n\n        Object var3;\n        try {\n            var3 = super.put(key, value);\n        } finally {\n            this.lock.unlock();\n        }\n\n        return (V) var3;\n    }\n\n    @Override\n    public V remove(Object key) {\n        this.lock.lock();\n\n        Object var2;\n        try {\n            var2 = super.remove(key);\n        } finally {\n            this.lock.unlock();\n        }\n\n        return (V) var2;\n    }\n\n    @Override\n    public int size() {\n        this.lock.lock();\n\n        int var1;\n        try {\n            var1 = super.size();\n        } finally {\n            this.lock.unlock();\n        }\n\n        return var1;\n    }\n\n    @Override\n    public void clear() {\n        this.lock.lock();\n\n        try {\n            super.clear();\n        } finally {\n            this.lock.unlock();\n        }\n\n    }\n\n    public int getMaxCapacity() {\n        return this.maxCapacity;\n    }\n\n    public void setMaxCapacity(int maxCapacity) {\n        this.maxCapacity = maxCapacity;\n    }\n}\n```\n**测试类**\n\n```java\npublic class TestLRUCache {\n    private static LRUCache<String, Integer> cache = new LRUCache<>(10);\n\n    public static void main(String[] args) {\n        for (int i = 0; i < 10; i++) {\n            cache.put(\"k\" + i, i);\n        }\n        System.out.println(\"all cache :'{\"+cache+\"}'\");\n        cache.get(\"k3\");\n        System.out.println(\"get k3 :'{\"+cache+\"}'\");\n        cache.get(\"k4\");\n        System.out.println(\"get k4 :'{\"+cache+\"}'\");\n        cache.get(\"k4\");\n        System.out.println(\"get k4 :'{\"+cache+\"}'\");\n        cache.put(\"k\" + 10, 10);\n        System.out.println(\"After running the LRU algorithm cache :'{\"+cache+\"}'\");\n    }\n}\n```\n![结果](https://img-blog.csdnimg.cn/20210316145118364.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n### LFU（最近最少使用）\nLFU（Least Frequently Used ，最近最少使用算法）也是一种常见的缓存算法。\n\n**LFU算法的思想是：如果一个数据在最近一段时间很少被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最小频率访问的数据最先被淘汰。**\n\n算法实现策略：考虑到 LFU 会淘汰访问频率最小的数据，我们需要一种合适的方法按大小顺序维护数据访问的频率。\n\n**实现**\n\n 1. 计算器+链表+哈希表\n 2. LIFO的Deque数组+哈希表+链表\n\n这里看下Dubbo中的LFU算法的实现。\n\n```java\npublic class LFUCache<K, V> {\n    private Map<K, LFUCache.CacheNode<K, V>> map;\n    private LFUCache.CacheDeque<K, V>[] freqTable; \n    private final int capacity;\n    private int evictionCount;\n    private int curSize;\n    private final ReentrantLock lock;\n    private static final int DEFAULT_LOAD_FACTOR = 1000;\n    private static final float DEFAULT_EVICTION_CAPACITY = 0.75F;//默认淘汰因子\n\n    public LFUCache() {\n        this(1000, 0.75F);\n    }\n\n    public LFUCache(final int maxCapacity, final float evictionFactor) {\n        this.curSize = 0;\n        this.lock = new ReentrantLock();\n        if (maxCapacity <= 0) {\n            throw new IllegalArgumentException(\"Illegal initial capacity: \" + maxCapacity);\n        } else {\n            boolean factorInRange = evictionFactor <= 1.0F || evictionFactor < 0.0F;\n            if (factorInRange && !Float.isNaN(evictionFactor)) {\n                this.capacity = maxCapacity;\n                this.evictionCount = (int)((float)this.capacity * evictionFactor);\n                this.map = new HashMap();\n                this.freqTable = new LFUCache.CacheDeque[this.capacity + 1];\n\n                int i;\n                for(i = 0; i <= this.capacity; ++i) {\n                    this.freqTable[i] = new LFUCache.CacheDeque();\n                }\n\n                for(i = 0; i < this.capacity; ++i) {\n                    this.freqTable[i].nextDeque = this.freqTable[i + 1];\n                }\n\n                this.freqTable[this.capacity].nextDeque = this.freqTable[this.capacity];\n            } else {\n                throw new IllegalArgumentException(\"Illegal eviction factor value:\" + evictionFactor);\n            }\n        }\n    }\n\n    public int getCapacity() {\n        return this.capacity;\n    }\n\n    public V put(final K key, final V value) {\n        this.lock.lock();\n\n        LFUCache.CacheNode node;\n        try {\n            if (this.map.containsKey(key)) {\n                node = (LFUCache.CacheNode)this.map.get(key);\n                if (node != null) {\n                    LFUCache.CacheNode.withdrawNode(node);\n                }\n\n                node.value = value;\n                this.freqTable[0].addLastNode(node);\n                this.map.put(key, node);\n            } else {\n                node = this.freqTable[0].addLast(key, value);\n                this.map.put(key, node);\n                ++this.curSize;\n                if (this.curSize > this.capacity) {\n                    this.proceedEviction();\n                }\n            }\n        } finally {\n            this.lock.unlock();\n        }\n\n        return node.value;\n    }\n\n    public V remove(final K key) {\n        LFUCache.CacheNode<K, V> node = null;\n        this.lock.lock();\n\n        try {\n            if (this.map.containsKey(key)) {\n                node = (LFUCache.CacheNode)this.map.remove(key);\n                if (node != null) {\n                    LFUCache.CacheNode.withdrawNode(node);\n                }\n\n                --this.curSize;\n            }\n        } finally {\n            this.lock.unlock();\n        }\n\n        return node != null ? node.value : null;\n    }\n\n    public V get(final K key) {\n        LFUCache.CacheNode<K, V> node = null;\n        this.lock.lock();\n\n        try {\n            if (this.map.containsKey(key)) {\n                node = (LFUCache.CacheNode)this.map.get(key);\n                LFUCache.CacheNode.withdrawNode(node);\n                //数组下一个位置存放访问过的值,相当于访问过n次。淘汰时，根据对应位置链表长度进行淘汰。\n                node.owner.nextDeque.addLastNode(node);\n            }\n        } finally {\n            this.lock.unlock();\n        }\n\n        return node != null ? node.value : null;\n    }\n\n    private int proceedEviction() {\n        int targetSize = this.capacity - this.evictionCount;//允许缓存的大小 = 容量-容量*淘汰因子\n        int evictedElements = 0;\n\n        for(int i = 0; i <= this.capacity; ++i) {\n            while(!this.freqTable[i].isEmpty()) {\n                LFUCache.CacheNode<K, V> node = this.freqTable[i].pollFirst();\n                this.remove(node.key);\n                if (targetSize >= this.curSize) {\n                    return evictedElements;\n                }\n\n                ++evictedElements;\n            }\n        }\n\n        return evictedElements;\n    }\n\n    public int getSize() {\n        return this.curSize;\n    }\n\t\n    static class CacheDeque<K, V> {\n        LFUCache.CacheNode<K, V> last = new LFUCache.CacheNode();\n        LFUCache.CacheNode<K, V> first = new LFUCache.CacheNode();\n        LFUCache.CacheDeque<K, V> nextDeque;\n\n        CacheDeque() {\n            this.last.next = this.first;\n            this.first.prev = this.last;\n        }\n\n        LFUCache.CacheNode<K, V> addLast(final K key, final V value) {\n            LFUCache.CacheNode<K, V> node = new LFUCache.CacheNode(key, value);\n            node.owner = this;\n            node.next = this.last.next;\n            node.prev = this.last;\n            node.next.prev = node;\n            this.last.next = node;\n            return node;\n        }\n\n        LFUCache.CacheNode<K, V> addLastNode(final LFUCache.CacheNode<K, V> node) {\n            node.owner = this;\n            node.next = this.last.next;\n            node.prev = this.last;\n            node.next.prev = node;\n            this.last.next = node;\n            return node;\n        }\n\n        LFUCache.CacheNode<K, V> pollFirst() {\n            LFUCache.CacheNode<K, V> node = null;\n            if (this.first.prev != this.last) {\n                node = this.first.prev;\n                this.first.prev = node.prev;\n                this.first.prev.next = this.first;\n                node.prev = null;\n                node.next = null;\n            }\n\n            return node;\n        }\n\n        boolean isEmpty() {\n            return this.last.next == this.first;\n        }\n    }\n\n    static class CacheNode<K, V> {\n        LFUCache.CacheNode<K, V> prev;\n        LFUCache.CacheNode<K, V> next;\n        K key;\n        V value;\n        LFUCache.CacheDeque owner;\n\n        CacheNode() {\n        }\n\n        CacheNode(final K key, final V value) {\n            this.key = key;\n            this.value = value;\n        }\n\n        static <K, V> LFUCache.CacheNode<K, V> withdrawNode(final LFUCache.CacheNode<K, V> node) {\n            if (node != null && node.prev != null) {\n                node.prev.next = node.next;\n                if (node.next != null) {\n                    node.next.prev = node.prev;\n                }\n            }\n\n            return node;\n        }\n    }\n}\n```\n**数据结构**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210316180715262.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**测试**\n\n```java\npublic class TestLFUCache {\n\n    private static LFUCache<String, Integer> cache = new LFUCache<String, Integer>(3,0);\n\n    public static void main(String[] args) {\n        cache.put(\"k1\",1);\n        cache.get(\"k1\");\n        cache.put(\"k2\",2);\n        cache.get(\"k2\");\n        cache.put(\"k3\",3);\n        cache.put(\"k4\",4);\n        cache.put(\"k5\",5);\n        cache.put(\"k6\",6);\n\n        System.out.println(cache.get(\"k1\"));\n        System.out.println(cache.get(\"k2\"));\n        System.out.println(cache.get(\"k3\"));\n        System.out.println(cache.get(\"k4\"));\n        System.out.println(cache.get(\"k5\"));\n        System.out.println(cache.get(\"k6\"));\n    }\n}\n```\n\n**结果**\n![结果](https://img-blog.csdnimg.cn/20210316181520133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**CacheDeque链表数组相当于给访问过的值计数，每访问过一次就移动到下一个下标处。**\n","tags":["算法"]},{"title":"Java线程通信工具类的使用","url":"/2021/03/12/Java 并发/Java线程通信工具类的使用/","content":"\n>本文介绍一些Java线程常用通信工具类，主要介绍怎么使用。\n\n### 简介\n常见的线程间通信方法有：\n\n - wait()和notify() +加锁机制synchronized和lock\n - 还有线程的join()方法\n - Condition接口的awiat() 和 signAll()方法 + 加锁机制synchronized和lock\n - 生产者消费者模式\n\n这里介绍一些JDK中java.util.concurrent包下的一些通信工具类。\n\n\n|  类| 作用 |\n|--|--|\n| Semaphore | 限制线程的数量 |\n| Exchanger | 两个线程交换数据 |\n| CountDownLatch | 线程等待直到计数器减为0时开始工作 |\n| CyclicBarrier | 作用跟CountDownLatch类似，但是可以重复使用 |\n\n### 1.Semaphore\nSemaphore即信号，以前学操作系统时，学过信号量机制。Semaphore往往用于资源有限的场景中，去限制线程的数量，这里介绍下这个类的使用。举个例子，我想限制同时只能有3个线程在工作：\n\n```java\npackage threadcon;\n\nimport java.util.Random;\nimport java.util.concurrent.Semaphore;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-03-11 17:47\n */\npublic class SemaphoreDemo {\n    static class MyThread implements Runnable {\n\n        private int value;\n        private Semaphore semaphore;\n\n        public MyThread(int value, Semaphore semaphore) {\n            this.value = value;\n            this.semaphore = semaphore;\n        }\n\n        @Override\n        public void run() {\n            try {\n                semaphore.acquire(); // 获取permit\n                System.out.println(String.format(\"当前线程是%d, 还剩%d个资源，还有%d个线程在等待\",\n                        value, semaphore.availablePermits(), semaphore.getQueueLength()));\n                // 睡眠随机时间，打乱释放顺序\n                Random random =new Random();\n                Thread.sleep(random.nextInt(1000));\n                System.out.println(String.format(\"线程%d释放了资源\", value));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } finally{\n                semaphore.release(); // 释放permit\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        Semaphore semaphore = new Semaphore(3);\n        for (int i = 0; i < 10; i++) {\n            new Thread(new MyThread(i, semaphore)).start();\n        }\n    }\n}\n\n```\n![运行结果](https://img-blog.csdnimg.cn/20210311182547119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**原理：**\n\nSemaphore(int)型构造函数\n```java\npublic Semaphore(int permits) {\n    sync = new NonfairSync(permits);\n}\n```\n该构造函数会创建具有给定的许可数和非公平机制的Semaphore。\n\n这里即设置AQS中的state为3，调用acquire会将state-1，调用release会将state+1。\n\n与AQS的队列操作大同小异，这里不再详细介绍。\n\n### 2.Exchanger\nExchanger类用于两个线程交换数据。它支持泛型，也就是说你可以在两个线程之间传送任何数据。\n\n```java\npackage threadcon;\n\nimport java.util.concurrent.Exchanger;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-03-11 18:38\n */\npublic class ExchangerDemo {\n    public static void main(String[] args) {\n        Exchanger<String> exchanger =new Exchanger<>();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    String a = \"这是来自线程A的数据\";\n                    System.out.println(\"这是线程A，得到了另一个线程的数据：\"\n                            + exchanger.exchange(a) + \" hashcode  \" + exchanger.exchange(a).hashCode());\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"A\").start();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    String b = \"这是来自线程B的数据\";\n                    System.out.println(\"这是线程B，得到了另一个线程的数据：\"\n                            + exchanger.exchange(b) + \" hashcode  \" + exchanger.exchange(b).hashCode());\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"A\").start();\n    }\n}\n\n```\n![结果](https://img-blog.csdnimg.cn/20210311184215782.png)\nExchanger只能是两个线程交换数据吗？那三个调用同一个实例的exchange方法会发生什么呢？答案是只有前两个线程会交换数据，第三个线程会进入阻塞状态。\n\n需要注意的是，exchange是可以重复使用的。也就是说。两个线程可以使用Exchanger在内存中不断地再交换数据。\n\n### 3.CountDownLatch\n先来解读一下CountDownLatch这个类名字的意义。CountDown代表计数递减，Latch是“门闩”的意思。也有人把它称为“屏障”。而CountDownLatch这个类的作用也很贴合这个名字的意义，假设某个线程在执行任务之前，需要等待其它线程完成一些前置任务，必须等所有的前置任务都完成，才能开始执行本线程的任务。\n\n```java\npackage threadcon;\n\nimport java.util.concurrent.CountDownLatch;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-03-11 18:48\n */\npublic class CountDownLatchDemo {\n    public static void main(String[] args) {\n        CountDownLatch countDownLatch = new CountDownLatch(3);\n\n        for (int i = 0; i < 3; i++) {\n            new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    try {\n                        Thread.sleep(1000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    System.out.println(Thread.currentThread().getName() + \" is running \");\n                    countDownLatch.countDown();\n\n                }\n            },\"ThreadA \"+ i + \" \").start();\n        }\n\n        try {\n            countDownLatch.await();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(\"ThreadAs run over\");\n        \n        for (int i = 0; i < 5; i++) {\n            new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    try {\n                        Thread.sleep(1000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    System.out.println(Thread.currentThread().getName() + \" is running \");\n                    countDownLatch.countDown();\n\n                }\n            },\"ThreadB \"+ i + \" \").start();\n        }\n\n\n    }\n}\n\n```\n![运行结果](https://img-blog.csdnimg.cn/20210311190548176.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\nCountDownLatch类的内部同样是一个基层了AQS的实现类Sync，且实现起来还很简单，可能是JDK里面AQS的子类中最简单的实现了。\n\n需要注意的是构造器中的计数值（count）实际上就是闭锁需要等待的线程数量。这个值只能被设置一次，而且CountDownLatch没有提供任何机制去重新设置这个计数值。\n### 4.CyclicBarrier\nCyclicBarrirer从名字上来理解是“循环的屏障”的意思。前面提到了CountDownLatch一旦计数值count被降为0后，就不能再重新设置了，它只能起一次“屏障”的作用。而CyclicBarrier拥有CountDownLatch的所有功能，还可以使用reset()方法重置屏障。\n\n```java\npackage thread;\n\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-03-12 9:37\n */\npublic class CyclicBarrierTest2 {\n\n    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(2, new Runnable() {\n        @Override\n        public void run() {\n            System.out.println(Thread.currentThread().getName() + \" step done\");\n        }\n    });\n\n    public static void main(String[] args) {\n        ExecutorService executorService = Executors.newFixedThreadPool(2);\n\n\n        executorService.submit(new Runnable() {\n            @Override\n            public void run() {\n\n                for (int i = 0; i < 2; i++) {\n                    System.out.println(Thread.currentThread().getName() +\"  \"+ i+ \"  step  doing \");\n                    try {\n                        cyclicBarrier.await();\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    } catch (BrokenBarrierException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n        });\n\n        executorService.submit(new Runnable() {\n            @Override\n            public void run() {\n                for (int i = 0; i < 2; i++) {\n                    System.out.println(Thread.currentThread().getName() +\"  \"+ i+ \"  step  doing \");\n                    try {\n                        cyclicBarrier.await();\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    } catch (BrokenBarrierException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n        });\n\n        executorService.shutdown();\n    }\n}\n\n```\n![运行结果](https://img-blog.csdnimg.cn/20210312094814110.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\nCyclicBarrier没有分为await()和countDown()，而是只有单独的一个await()方法。\n一旦调用await()方法的线程数量等于构造方法中传入的任务总量（这里是2），就代表达到屏障了。CyclicBarrier允许我们在达到屏障的时候可以执行一个任务，可以在构造方法传入一个Runnable类型的对象。\n\n\n**和CountDonwLatch再对比** \n\n - CountDownLatch减计数，CyclicBarrier加计数。\n - CountDownLatch是一次性的，CyclicBarrier可以重用。\n - CountDownLatch和CyclicBarrier都有让多个线程等待同步然后再开始下一步动作的意思，但是CountDownLatch的下一步的动作实施者是主线程，具有不可重复性；而CyclicBarrier的下一步动作实施者还是“其他线程”本身，具有往复多次实施动作的特点。 \n\n**参考**\n\n 1. [JAVA线程通信工具类](http://concurrent.redspider.group/article/03/17.html)\n 2. [JUC工具类: CyclicBarrier详解](https://www.pdai.tech/md/java/thread/java-thread-x-juc-tool-cyclicbarrier.html)\n 3. JAVA并发编程之美\n\n  ","tags":["Java并发"]},{"title":"深入了解ReentrantReadWriteLock","url":"/2021/03/10/Java 并发/ReentrantReadWriteLock/","content":"\n>本文分析JDK1.8中的ReentrantReadWriteLock类\n\n### 简介\n由于ReentrantLock是独占锁，某时只有一个线程可以获取该锁，而实际中会有写少读多的场景，所以ReentrantReadWriteLock应运而生，采用读写分离的策略，允许多个线程同时获取该锁。\n\nReentrantReadWriteLock即可重入读写锁，内部维护一个ReadLock和一个WriteLock，他们依赖Sync来实现，而Sync继承AbstractQueuedSynchronizer，并且也提供了公平和非公平的实现。\n\n### 内部类\n![内部类](https://img-blog.csdnimg.cn/20210309140028298.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n**Sync**\n\n抽象类Sync继承自AQS\n```java\nabstract static class Sync extends AbstractQueuedSynchronizer {}\n```\n\n一些属性\n```java\n\t\t//高16位为读锁，低16位为写锁\n        static final int SHARED_SHIFT   = 16;\n        //共享锁读锁 状态单位值65536\n        static final int SHARED_UNIT    = (1 << SHARED_SHIFT);\n        //共享锁读锁 最大个数65535\n        static final int MAX_COUNT      = (1 << SHARED_SHIFT) - 1;\n        //排它锁写锁掩码 15个1\n        static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;\n\n        // 返回读锁线程数   c右移 16位\n        static int sharedCount(int c)    { return c >>> SHARED_SHIFT; }\n        //返回写锁可重入个数   c & 15个1\n        static int exclusiveCount(int c) { return c & EXCLUSIVE_MASK; }\n\t    //本地线程计数器\n\t    private transient ThreadLocalHoldCounter readHolds;\n\t    //缓存计数器\n\t    private transient HoldCounter cachedHoldCounter;\n\t    //第一个读线程\n\t    private transient Thread firstReader = null;\n\t    //第一个读线程的计数\n\t    private transient int firstReaderHoldCount;\n```\n\nSync内部类\n\n```java\n\t\t\n        static final class HoldCounter {\n        \t//重入的次数\n            int count = 0;\n            //线程id\n            final long tid = getThreadId(Thread.currentThread());\n        }\n\n        \n        static final class ThreadLocalHoldCounter\n            extends ThreadLocal<HoldCounter> {\n            // 重写初始化方法，在没有进行set的情况下，获取的都是该HoldCounter值\n            public HoldCounter initialValue() {\n                return new HoldCounter();\n            }\n        }\n```\n### 锁的获取与释放\n**WriteLock   写锁的获取与释放**\n\n**lock**\n\n```java\n\tpublic void lock() {\n\t    sync.acquire(1);\n\t}\n    public final void acquire(int arg) {\n    \t//获取锁失败则插入AQS阻塞队列尾部\n        if (!tryAcquire(arg) &&\n            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n            selfInterrupt();\n    }\n    protected final boolean tryAcquire(int acquires) {\n\t\t//当前线程\n        Thread current = Thread.currentThread();\n        //获取状态值\n        int c = getState();\n        //获取写线程数量\n        int w = exclusiveCount(c);\n        //c!=0 说明写锁或者读锁已经被某线程获取\n        if (c != 0) {\n            //w=0说明已经有线程获取了读锁返回false，w!=0并且当前线程不是写锁的拥有者，则返回false\n            if (w == 0 || current != getExclusiveOwnerThread())\n                return false;\n            //超过最高写线程数量\n            if (w + exclusiveCount(acquires) > MAX_COUNT)\n                throw new Error(\"Maximum lock count exceeded\");\n            // 设置AQS状态\n            setState(c + acquires);\n            return true;\n        }\n        //c == 0 说明目前没有线程获取到读锁和写锁，非公平锁则线程抢占式执行CAS尝试获取写锁\n        if (writerShouldBlock() ||\n            !compareAndSetState(c, c + acquires))\n            return false;\n        // 设置独占线程\n        setExclusiveOwnerThread(current);\n        return true;\n    }\n\n```\n首先会获取state，判断是否为0，若为0，表示此时没有读锁线程，再判断写线程是否应该被阻塞，而在非公平策略下线程抢占式执行CAS尝试获取写锁，在公平策略下会进行判断(判断同步队列中是否有等待时间更长的线程，若存在，则需要被阻塞，否则，无需阻塞)，之后在设置状态state，然后返回true。若state不为0，则表示此时存在读锁或写锁线程，若写锁线程数量为0或者当前线程为独占锁线程，则返回false，表示不成功，否则，判断写锁线程的重入次数是否大于了最大值，若是，则抛出异常，否则，设置状态state，返回true，表示成功。\n![流程图](https://img-blog.csdnimg.cn/2021030914442224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n**lockInterruptibly**\n会对中断进行响应，也就是当其他线程调用了该线程的interrupt()方法中断了当前线程，当前线程会抛出异常InterruptedException。\n\n**unlock**\n\n```java\n\t//释放写锁\n    public void unlock() {\n        sync.release(1);\n    }\n\t\n    public final boolean release(int arg) {\n    \t//释放锁成功，取AQS阻塞队列的头节点，并激活\n\t\tif (tryRelease(arg)) {\n\t\t   \tNode h = head;\n\t\t   \tif (h != null && h.waitStatus != 0)\n\t\t       \tunparkSuccessor(h);\n\t\t   \treturn true;\n\t\t}\n\t\treturn false;\n    }\n\tprotected final boolean tryRelease(int releases) {\n\t\t//是否是写锁拥有者调用的unlock\n\t     if (!isHeldExclusively())\n\t         throw new IllegalMonitorStateException();\n\t     //释放写锁后的 写锁的数量\n\t     int nextc = getState() - releases;\n\t     boolean free = exclusiveCount(nextc) == 0;\n\t     //写锁数量为0 则释放锁\n\t     if (free)\n\t         setExclusiveOwnerThread(null);\n\t     //更新状态值\n\t     setState(nextc);\n\t     return free;\n\t }\n```\n首先会判断该线程是否为独占线程，若不为独占线程，则抛出异常，否则，计算释放资源后的写锁的数量，若为0，表示成功释放，资源不将被占用，否则，表示资源还被占用。其函数流程图如下。\n\n**ReadLock   读锁的获取与释放**\n**lock**\n\n```java\n    public void lock() {\n        sync.acquireShared(1);\n    }\n    \n    public final void acquireShared(int arg) {\n    \t//获取锁，如果返回值<0说明失败了\n        if (tryAcquireShared(arg) < 0)\n        \t//加入队列 自旋去获取锁\n            doAcquireShared(arg);\n    }\n    \n    protected final int tryAcquireShared(int unused) {\n\t\t//获取当前线程\n        Thread current = Thread.currentThread();\n        //获取状态\n        int c = getState();\n        //有写锁占用并且不是当前线程，则直接返回获取失败\n        if (exclusiveCount(c) != 0 &&\n            getExclusiveOwnerThread() != current)\n            return -1;\n        //获取读锁的线程数\n        int r = sharedCount(c);\n        // 读线程是否应该被阻塞、并且小于最大值、并且比较设置成功\n        if (!readerShouldBlock() &&\n            r < MAX_COUNT &&\n            compareAndSetState(c, c + SHARED_UNIT)) {\n            // 如果读锁持有数为0，则说明当前线程是第一个reader，分别给firstReader和firstReaderHoldCount初始化\n            if (r == 0) {\n                firstReader = current;\n                firstReaderHoldCount = 1;\n            } else if (firstReader == current) {// 如果读锁持有数不为0且当前线程就是firstReader，那么直接给firstReaderHoldCount+1，表示读锁重入\n                firstReaderHoldCount++;\n            } else {// 读锁数量不为0并且不为当前线程\n                HoldCounter rh = cachedHoldCounter;\n                if (rh == null || rh.tid != getThreadId(current))\n                    cachedHoldCounter = rh = readHolds.get();\n                else if (rh.count == 0)\n                    readHolds.set(rh);\n                rh.count++;\n            }\n            return 1;\n        }\n        // 应该阻塞或者CAS失败则进入此方法获取锁\n        return fullTryAcquireShared(current);\n    }\n\n    private void doAcquireShared(int arg) {\n    \t//将节点挂在到队列 并设置其为尾结点\n        final Node node = addWaiter(Node.SHARED);\n        boolean failed = true;\n        try {\n            boolean interrupted = false;\n            for (;;) {\n            \t//p是node的前节点\n                final Node p = node.predecessor();\n                if (p == head) {\n                \t// 如果前一个节点是头节点，则尝试获取锁\n                    int r = tryAcquireShared(arg);\n                    if (r >= 0) {//获取锁成功\n                        setHeadAndPropagate(node, r);//设置头节点\n                        p.next = null; // help GC\n                        if (interrupted)\n                            selfInterrupt();\n                        failed = false;\n                        return;\n                    }\n                }\n                if (shouldParkAfterFailedAcquire(p, node) &&\n                    parkAndCheckInterrupt())\n                    interrupted = true;\n            }\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210310152508189.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n**unlock**\n\n```java\n    public void unlock() {\n        sync.releaseShared(1);\n    }\n\n    public final boolean releaseShared(int arg) {\n        if (tryReleaseShared(arg)) {\n            doReleaseShared();\n            return true;\n        }\n        return false;\n    }\n\n    protected final boolean tryReleaseShared(int unused) {\n    \t//当前线程\n        Thread current = Thread.currentThread();\n        //当前线程是否为第一个读线程\n        if (firstReader == current) {\n            // assert firstReaderHoldCount > 0;\n            //重入数为1 则置空\n            if (firstReaderHoldCount == 1)\n                firstReader = null;\n            //可重入数-1\n            else\n                firstReaderHoldCount--;\n        } else {\n        \t//得到缓存的计算\n            HoldCounter rh = cachedHoldCounter;\n            if (rh == null || rh.tid != getThreadId(current))\n\t            // 获取当前线程对应的计数器\n                rh = readHolds.get();\n            // 获取计数\n            int count = rh.count;\n            if (count <= 1) {\n                readHolds.remove();\n                if (count <= 0)\n                    throw unmatchedUnlockException();\n            }\n            //计数-1\n            --rh.count;\n        }\n        for (;;) {\n            int c = getState();\n            // 获取释放后状态\n            int nextc = c - SHARED_UNIT;\n            if (compareAndSetState(c, nextc)) //CAS自旋设置\n                return nextc == 0;\n        }\n    }\n    \n    private void doReleaseShared() {\n        for (;;) { //自旋激活等待节点\n            Node h = head;\n            if (h != null && h != tail) {\n                int ws = h.waitStatus;\n                if (ws == Node.SIGNAL) {\n                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                        continue;            // loop to recheck cases\n                    unparkSuccessor(h);\n                }\n                else if (ws == 0 &&\n                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                    continue;                // loop on failed CAS\n            }\n            if (h == head)                   // loop if head changed\n                break;\n        }\n    }\n```\n### ReentrantReadWriteLock的使用\n\n```java\npackage thread3;\n\nimport java.util.ArrayList;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-03-09 14:55\n */\npublic class ReentrantReadWriteLockList {\n    private ArrayList<String> array = new ArrayList<>();\n\n    private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\n\n    private final Lock readLock = lock.readLock();\n\n    private final Lock writeLock = lock.writeLock();\n\n    public void add(String e){\n        System.out.println(Thread.currentThread().getName() + \"  try writeLock  lock    value   \"+e);\n        writeLock.lock();\n        try {\n            array.add(e);\n        } catch (Exception exception) {\n            exception.printStackTrace();\n        }finally {\n            writeLock.unlock();\n            System.out.println(Thread.currentThread().getName() + \"  try writeLock  unlock\");\n        }\n    }\n\n    public String get(int index){\n        System.out.println(Thread.currentThread().getName() + \"  try readLock lock\");\n        readLock.lock();\n        try {\n            return array.get(index);\n        }catch (Exception e){\n            return new String(\"越界访问\");\n        }\n        finally {\n            readLock.unlock();\n        }\n    }\n\n    public static void main(String[] args) {\n        ReentrantReadWriteLockList reentrantLockList = new ReentrantReadWriteLockList();\n\n        for (int i = 0; i < 3; i++) {\n            new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    String s = String.valueOf(ThreadLocalRandom.current().nextInt(100));\n                    reentrantLockList.add(s);\n                }\n            }).start();\n\n\n            final int j = i;\n\n            new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    System.out.println(Thread.currentThread().getName()+ \"  try readLock  unlock value   \" + reentrantLockList.get(j));\n                }\n            }).start();\n\n            new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    System.out.println(Thread.currentThread().getName()+ \"  try readLock  unlock value   \" + reentrantLockList.get(j));\n                }\n            }).start();\n\n        }\n    }\n}\n\n\n```\n**运行结果：**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210310181617979.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n**小结**\n\n - ReentrantReadWriteLock 有公平和非公平两种机制，默认使用非公平锁。\n - 在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。\n - 在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。\n - 读锁能同时被多个线程持有，而写锁是独占锁同一时刻只能有一个线程持有。\n - 锁降级：线程获取写入锁后可以获取读取锁，然后释放写入锁，这样就从写入锁变成了读取锁，从而实现锁降级特性。\n - ReentrantReadWriteLock 使用int 类型的变量  高16为表示拥有读锁线程数，低16为表示写锁可重入数。\n\n**参考**\n\n 1. **Java并发编程之美**\n 2. [JDK1.8源码分析之ReentrantReadWriteLock](https://www.cnblogs.com/leesf456/p/5419132.html)\n 3. [读写锁——ReentrantReadWriteLock原理详解](https://cloud.tencent.com/developer/article/1469555)\n","tags":["Java并发"]},{"title":"Java并发基础","url":"/2021/03/08/Java 并发/Java并发基础/","content":">本篇介绍Java并发的基础知识，主要包括线程安全，共享变量的内存可见性，synchronized和volatile关键字，指令重排序，伪共享等相关知识。\n\n### 并发与并行\n\n - 并发是指同一时间段内多个任务执行。\n - 并行是指同一时刻，多个任务同时执行。\n   \n\n**并发是单位时间内，一个CPU切换时间片对多个任务进行处理**\n\n**并行是同一时刻，多个CPU对多个任务同时进行处理**\n\n### 线程安全\n**共享资源**：该资源被多个线程所持有。\n\n**线程安全问题是指当多线程同时读写一个共享资源并且没有任何同步措施时，导致出现脏数据或者其他不可预见的结果的问题**\n\n### Java中共享变量的内存可见性\nJava内存模型规定，将所有变量存放在主内存中，当线程使用变量时，会把主内存里面的变量复制到自己的工作内存，线程读写变量时操作的是自己工作内存中的变量。\n![内存模型](https://img-blog.csdnimg.cn/20210305182228132.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n当线程A和线程B同时处理一个共享变量X。\n\n - 线程A首先获取共享变量X的值，由于两级Cache都没有命中，所以加载主内存中X的值，假如是0，然后把X=0缓存到二级缓存，并刷新到主内存。此时二级缓存和主内存中X的值都是1。\n - 线程B获取X的值，一级缓存未命中，二级缓存命中，返回X=1。然后线程B将X的值改为2，并缓存到二级缓存，刷新到主内存。此时二级缓存和主内存中X的值都是1\n - 线程A再次获取X的值，一级缓存命中，此时线程A工作内存中的X=1。这样就出现了问题，二级缓存和主内存中X的值已经被线程B修改为2了。这就是共享变量的内存不可见问题，也就是线程B写入的值对线程A不可见。\n\n### Java中的原子性操作和指令重排序\n**所谓原子性操作，是指在执行一系列操作时，要么全部执行，要么全部不执行，不存在只执行其中一部分的情况。**\n\n**指令重排序**：Java内存模型运行编译器和处理器对指令重排序以提高运行效率，只会对不存在数据依赖的指令重排序。重排序在单线程下可以保证最终的执行结果，在多线程下不能保证。\n\n\n### synchronized和volatile关键字\n**synchronized**：\n\n - synchronized块是Java提供的一种原子性内置锁，内置锁是排它锁，也就是当一个线程获取该锁时，其他线程必须等待该线程释放锁后才能获取该锁。\n - 进入synchronized块的内存语义是把synchronized块内使用到的变量从线程工作内存中清除，这样线程使用到的变量会从主内存中获取。退出synchronized块的内存语义是把synchronized块内对共享变量的修改刷新到主内存。\n - synchronized关键字保证了原子性、共享变量的内存可见性、有序性。这里注意的是，synchronized没有禁止指令重排序，但是却保证了有序性，这是因为synchronized块中只能有一个线程运行，所以保证了最终执行的结果。\n\n**volatile**：\n\n - 对于解决内存可见性问题，使用锁太笨重，因为它会带来线程上下文切换开销。volatile关键字确保对一个变量的更新对其他线程可见。\n - 写入volatile的内存语义是将写入线程工作内存的变量刷新到主内存，读取volatile的内存语义是先清空线程的工作内存再从主内存中读取。\n - volatile关键字只保证共享变量的内存可见性，并且禁止指令重排序，但不保证原子性。\n \n \n### 伪共享\n**缓存行（Cache line）**：在高速缓存Cache内部，是按行存储的，每一行被称为一个缓存行。缓存行是Cache与主内存进行数据交换的单位。Cache行的大小一般为2的幂次方字节。\n\n**伪共享**：当多个线程，修改一个缓存行中的多个变量时，由于同时只能有一个线程操作缓存行（这就没有做到多个线程同时操作多个变量），所以相比将每个变量放到不同的缓存行，性能会下降，这就是伪共享。\n\n### Java中的CAS操作\n\n**CAS**：compare and swap，是JDK提供的非阻塞原子性操作，它通过硬件保证了比较--更新操作的原子性。\n\n -     public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);\n -     public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n -     public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);\n\nJDK中的Unsafe类提供了这三种CAS方法，有四个操作数，分别为：对象的内存位置，对象的变量的偏移量，变量预期值，变量新的值。\n\n**ABA问题**：ABA问题是指，线程1获取变量X的值A后在使用CAS修改X的值之前，线程2使用CAS修改X的值为B，然后又使用CAS修改X的值为A，此时线程1获取的X的值A已经不是之前获取的A了。\n给每个变量的状态值，配备时间戳可避免ABA问题。\n\n","tags":["Java并发"]},{"title":"深入了解ThreadLocal","url":"/2021/03/05/Java 并发/ThreadLocal/","content":"\n>本文分析ThreadLocal的原理和使用\n### 1.ThreadLocal简介\n多线程访问共享变量时容易出现并发问题，为了保证线程安全，一般会给共享变量进行适当的加锁同步。如果不想加锁呢？\nThreadLocal可以做到线程隔离，多个线程访问共享变量时，访问的是自己线程的变量。\nThreadLocal提供了线程本地变量，如果创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地副本，当多线程操作这个变量时，实际操作的是自己本地内存的变量，从而避免线程安全的问题。\n\n### 2.ThreadLocal使用\n\n```java\npublic class ThreadLocalDemo {\n\n    static ThreadLocal<String> stringThreadLocal = new ThreadLocal<String>();\n\n\n    public static void main(String[] args) {\n\n        CountDownLatch countDownLatch = new CountDownLatch(10);\n        for (int i = 0; i < 10; i++) {\n            Thread thread = new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    stringThreadLocal.set(Thread.currentThread().getName());\n                    System.out.println(stringThreadLocal.get());\n                    countDownLatch.countDown();\n                }\n            },\"i  am  thread  --\"+i);\n            thread.start();\n        }\n\n    }\n}\n```\n运行结果\n![结果](https://img-blog.csdnimg.cn/2021030411015322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n### 3.ThreadLocal的原理\nThread类中有两个包访问变量，一个是threadLocals ，一个是inheritableThreadLocals，它们都是ThreadLocalMap类型的变量。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210304111445418.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n而ThreadLocalMap又是ThreadLocal的内部类。\n默认情况下，每个线程的这两个变量都为null，只有当线程第一次调用ThreadLocal 的set 或者get方法时才会创建他们。\n每个线程的本地变量是存在调用线程的threadLocals变量中的，ThreadLocal通过set方法把value放在调用线程的threadLocals变量中，通过get方法取出调用线程的threadLocals中的值。\nThread里面的threadLocals为何设计为map结构？因为每个线程可以关联多个ThreadLocal变量。\n\n**下面分析下 ThreadLocal 的set、get及remove方法**\n**1.set**\n\n```java\n    public void set(T value) {\n    \t//获取当前调用线程\n        Thread t = Thread.currentThread();\n        //将当前线程作为key  去查对应的线程变量threadLocals\n        ThreadLocalMap map = getMap(t);\n        //当前线程的threadLocals不为null\n        if (map != null)\n        \t//将当前ThreadLocal 对象作为key传入map\n            map.set(this, value);\n        else\n        \t//创建map\n            createMap(t, value);\n    }\n    \n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n    \n    void createMap(Thread t, T firstValue) {\n    \t//当前线程的threadLocals  赋值   以当前ThreadLocal 对象作为key 创建的ThreadLocalMap\n        t.threadLocals = new ThreadLocalMap(this, firstValue);\n    }\n\n\t//ThreadLocalMap的构造函数\n    ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\n    \t//Entry为ThreadLocalMap的内部类  INITIAL_CAPACITY = 16\n        table = new Entry[INITIAL_CAPACITY];\n        //计算应该存放的位置 i  因INITIAL_CAPACITY = 16 相当于对 16 取余\n        int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);\n        //存放到table[i]\n        table[i] = new Entry(firstKey, firstValue);\n        size = 1;\n        setThreshold(INITIAL_CAPACITY);\n    }\n```\n\n**2.get**\n\n```java\n    public T get() {\n    \t//获取当前调用线程\n        Thread t = Thread.currentThread();\n        //将当前线程作为key  去查对应的线程变量threadLocals\n        ThreadLocalMap map = getMap(t);\n        if (map != null) {\n        \t//以当前ThreadLocal对象作为key 去取 map中的 entry\n            ThreadLocalMap.Entry e = map.getEntry(this);\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                T result = (T)e.value;\n                return result;\n            }\n        }\n        return setInitialValue();\n    }\n\n\tprivate T setInitialValue() {\n        T value = initialValue();\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n        return value;\n    }\n```\n**remove**\n\n```java\n    public void remove() {\n        ThreadLocalMap m = getMap(Thread.currentThread());\n        if (m != null)\n            m.remove(this);\n    }\n    \n\tprivate void remove(ThreadLocal<?> key) {\n\t\t\t//拿到table数组\n            Entry[] tab = table;\n            int len = tab.length;\n            //找到在数组中存放的位置 i\n            int i = key.threadLocalHashCode & (len-1);\n            for (Entry e = tab[i];\n                 e != null;\n                 e = tab[i = nextIndex(i, len)]) {\n                //判断key是否相等\n                if (e.get() == key) {\n                \t//清除\n                    e.clear();\n                    expungeStaleEntry(i);\n                    return;\n                }\n            }\n   \t}\n```\n**ThreadLocalMap内部类 Enrtry**\n\n```java\n        static class Entry extends WeakReference<ThreadLocal<?>> {\n           \n            Object value;\n\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n            }\n        }\n```\nEnrtry 继承自软引用，当对应的ThreadLocal对象为null时，此Entry对象会被JVM回收，避免出现内存泄漏。\n\n### 4.ThreadLocal不支持继承性\n\n```java\npublic class TestThreadLocal {\n    public static ThreadLocal<String> threadLocal = new ThreadLocal<String>();\n\n    public static void main(String[] args) {\n        threadLocal.set(\"hello\");\n        \n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(\"sub thread:  \" + threadLocal.get());\n            }\n        }).start();\n\n        System.out.println(\"main:  \"+ threadLocal.get());\n    }\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210304135601647.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n也就是说，同一个ThreadLocal变量在父线程中被设置值后，在子线程中是获取不到的。\n\n### 5.InheritableThreadLocal类\n利用InheritableThreadLocal类，子线程可以访问父线程中的本地变量。\n\n```java\n//继承ThreadLocal类\npublic class InheritableThreadLocal<T> extends ThreadLocal<T> {\n\n    protected T childValue(T parentValue) {\n        return parentValue;\n    }\n\t//返回当前线程的inheritableThreadLocals变量\n    ThreadLocalMap getMap(Thread t) {\n       return t.inheritableThreadLocals;\n    }\n    //初始化当前线程的inheritableThreadLocals变量\n    void createMap(Thread t, T firstValue) {\n        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);\n    }\n}\n```\n当子线程初始化时会判断父线程的inheritableThreadLocals变量是否为null，不为null 则会赋值给子线程inheritableThreadLocals变量\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210304140844418.png)\n\n```java\n    static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {\n    \t//这个构造函数 仅此方法createInheritedMap调用\n        return new ThreadLocalMap(parentMap);\n    }\n    \n    private ThreadLocalMap(ThreadLocalMap parentMap) {\n        Entry[] parentTable = parentMap.table;\n        int len = parentTable.length;\n        setThreshold(len);\n        table = new Entry[len];\n\n        for (int j = 0; j < len; j++) {\n            Entry e = parentTable[j];\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();\n                if (key != null) {\n                \t//这里调用InheritableThreadLocal类覆盖的 childValue方法\n                    Object value = key.childValue(e.value);\n                    Entry c = new Entry(key, value);\n                    int h = key.threadLocalHashCode & (len - 1);\n                    while (table[h] != null)\n                        h = nextIndex(h, len);\n                    table[h] = c;\n                    size++;\n                }\n            }\n        }\n    }\n```\n**改为InheritableThreadLocal 运行**\n\n```java\npublic class TestInheritableThreadLocal {\n    public static ThreadLocal<String> threadLocal = new InheritableThreadLocal<>();\n\n    public static void main(String[] args) {\n        threadLocal.set(\"hello\");\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(\"sub thread:  \" + threadLocal.get());\n            }\n        }).start();\n\n        System.out.println(\"main:  \"+ threadLocal.get());\n    }\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210304141242249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n","tags":["Java并发"]},{"title":"深入了解ConcurrentHashMap","url":"/2021/03/03/Java Base/ConcurrentHashMap/","content":"\n>本文将深入源码分析ConcurrentHashMap的相关内容\n\n### 1.ConcurrentHashMap简介\n由于HashMap是非线程安全的，所以如果想在多线程下安全的操作Map，有下面几个解决方案：\n\n 1. 使用HashTable\n 2. 使用Collections.synchronizedMap\n 3. 使用ConcurrentHashMap\n\n**HashTable**\nHashTable类是一个线程安全的类，它的底层给几乎所有的多线程操作方法都加上了synchronized关键字，相当于锁住整个HashTable，多线程访问时，只要有一个线程访问或操作该对象，其他线程只能阻塞等待锁的释放，性能非常差，所以HashTable不推荐使用。\n\n**Collections.synchronizedMap**\n底层也是使用对象锁来保证线程安全，本质上也相当于是全表锁。\n\n**CocurrentHashMap**\n**JDK1.7:**\n在JDK1.7中，采用分段锁。所谓分段锁，是将HashMap中的Entry数组进行切割，分成许多小数组即Segment,Segment继承ReetrantLock（可重入锁）。\n**JDK1.8**\n在JDK1.8中，取消了Segment分段锁，采用CAS+synchronized来保证并发安全，synchronized只锁住table数组中链表或者红黑树的头节点，只要插入节点的hash不冲突,就不会产生线程竞争。\n\n**jdk1.8中的ConcurrentHashMap相比于jdk1.7  锁的粒度更小，性能更好。**\n\n### 2.底层数据结构\n同jdk1.8中的HashMap一样，底层也采用了数组+链表/红黑树的数据结构，这样当hash冲突较多时，查询效率会更好。\n\nNode和TreeNode同HashMap中的差不多，不过Node中的Value 和 next 用 volatile修饰\n```java\n\tstatic class Node<K,V> implements Map.Entry<K,V> {\n        final int hash;\n        final K key;\n        //val和next都会在扩容时发生变化，所以加上volatile来保持可见性和禁止重排序\n        volatile V val;\n        volatile Node<K,V> next;\n\n        Node(int hash, K key, V val, Node<K,V> next) {\n            this.hash = hash;\n            this.key = key;\n            this.val = val;\n            this.next = next;\n        }\n\n        public final K getKey()       { return key; }\n        public final V getValue()     { return val; }\n        public final int hashCode()   { return key.hashCode() ^ val.hashCode(); }\n        public final String toString(){ return key + \"=\" + val; }\n        public final V setValue(V value) {\n            throw new UnsupportedOperationException();\n        }\n\n        public final boolean equals(Object o) {\n            Object k, v, u; Map.Entry<?,?> e;\n            return ((o instanceof Map.Entry) &&\n                    (k = (e = (Map.Entry<?,?>)o).getKey()) != null &&\n                    (v = e.getValue()) != null &&\n                    (k == key || k.equals(key)) &&\n                    (v == (u = val) || v.equals(u)));\n        }\n\n        /**\n         * Virtualized support for map.get(); overridden in subclasses.\n         */\n        Node<K,V> find(int h, Object k) {\n            Node<K,V> e = this;\n            if (k != null) {\n                do {\n                    K ek;\n                    if (e.hash == h &&\n                        ((ek = e.key) == k || (ek != null && k.equals(ek))))\n                        return e;\n                } while ((e = e.next) != null);\n            }\n            return null;\n        }\n    }\n```\n**TreeBin**\nTreeBin并不是红黑树的存储节点，TreeBin通过root属性维护红黑树的根结点，因为红黑树在旋转的时候，根结点可能会被它原来的子节点替换掉，在这个时间点，如果有其他线程要写这棵红黑树就会发生线程不安全问题，所以在ConcurrentHashMap中TreeBin通过waiter属性维护当前使用这棵红黑树的线程，来防止其他线程的进入。\n\n```java\n \tstatic final class TreeBin<K,V> extends Node<K,V> {\n \t\t//指向TreeNode链表的根节点\n        TreeNode<K,V> root;\n        volatile TreeNode<K,V> first;\n        volatile Thread waiter;\n        volatile int lockState;\n        // 锁的状态\n        static final int WRITER = 1; // 持有写锁时的状态\n        static final int WAITER = 2; // 等待写锁时的状态\n        static final int READER = 4; // 增加数据时读锁的状态\n\t\t\t\n\t\t//构造函数 hash未 TREEBIN = -2，以b节点为头节点， 代表红黑树头节点hash<0\n        TreeBin(TreeNode<K,V> b) {\n            super(TREEBIN, null, null, null);\n            this.first = b;\n            TreeNode<K,V> r = null;\n            for (TreeNode<K,V> x = b, next; x != null; x = next) {\n                next = (TreeNode<K,V>)x.next;\n                x.left = x.right = null;\n                if (r == null) {\n                    x.parent = null;\n                    x.red = false;\n                    r = x;\n                }\n                else {\n                    K k = x.key;\n                    int h = x.hash;\n                    Class<?> kc = null;\n                    for (TreeNode<K,V> p = r;;) {\n                        int dir, ph;\n                        K pk = p.key;\n                        if ((ph = p.hash) > h)\n                            dir = -1;\n                        else if (ph < h)\n                            dir = 1;\n                        else if ((kc == null &&\n                                  (kc = comparableClassFor(k)) == null) ||\n                                 (dir = compareComparables(kc, k, pk)) == 0)\n                            dir = tieBreakOrder(k, pk);\n                            TreeNode<K,V> xp = p;\n                        if ((p = (dir <= 0) ? p.left : p.right) == null) {\n                            x.parent = xp;\n                            if (dir <= 0)\n                                xp.left = x;\n                            else\n                                xp.right = x;\n                            r = balanceInsertion(r, x);\n                            break;\n                        }\n                    }\n                }\n            }\n            this.root = r;\n            assert checkInvariants(root);\n        }\n\t}\n\n```\n**ForwardingNode**\n扩容用到的数据结构，代表正在进行扩容\n```java\n    static final class ForwardingNode<K,V> extends Node<K,V> {\n        final Node<K,V>[] nextTable;\n        //hash 为 MOVED = -1 代变正在进行扩容\n        ForwardingNode(Node<K,V>[] tab) {\n            super(MOVED, null, null, null);\n            this.nextTable = tab;\n        }\n\t}\n```\n\n### 3.常用方法\n**put方法**\n\n```java\n    public V put(K key, V value) {\n        return putVal(key, value, false);\n    }\n\n    final V putVal(K key, V value, boolean onlyIfAbsent) {\n    \t//key和value 都不能为null\n        if (key == null || value == null) throw new NullPointerException();\n        //获取key 的  hash\n        int hash = spread(key.hashCode());\n        int binCount = 0;\n        for (Node<K,V>[] tab = table;;) {\n            Node<K,V> f; int n, i, fh;\n            if (tab == null || (n = tab.length) == 0)\n            \t//table 为 null 或者长度为 0  初始化table\n                tab = initTable();\n            // f 代表数组 hash&（n-1）位置的元素，如果f为null 则调用casTabAt方法利用Unsafe.compareAndSwapObject插入Node节点\n            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {\n                if (casTabAt(tab, i, null,\n                             new Node<K,V>(hash, key, value, null)))\n                    break;                   // no lock when adding to empty bin\n            }\n            //MOVED = -1 如果f.hash等于 -1 意味着有其它线程正在扩容，则当前线程一起进行扩容\n            else if ((fh = f.hash) == MOVED)\n            \t//如果在进行扩容，则先进行扩容操作\n                tab = helpTransfer(tab, f);\n            else {\n                V oldVal = null;\n                //锁住链表或红黑树的头节点\n                synchronized (f) {\n                \t//再次确认，防止其他线程修改\n                    if (tabAt(tab, i) == f) {\n                    \t//hash >=0 说明时链表的节点，如果有相等的key，则修改它的value，否则在链表尾部插入 \n                        if (fh >= 0) {\n                            binCount = 1;\n                            for (Node<K,V> e = f;; ++binCount) {\n                                K ek;\n                                if (e.hash == hash &&\n                                    ((ek = e.key) == key ||\n                                     (ek != null && key.equals(ek)))) {\n                                    oldVal = e.val;\n                                    if (!onlyIfAbsent)\n                                        e.val = value;\n                                    break;\n                                }\n                                Node<K,V> pred = e;\n                                if ((e = e.next) == null) {\n                                    pred.next = new Node<K,V>(hash, key,\n                                                              value, null);\n                                    break;\n                                }\n                            }\n                        }\n                        // f 是 TreeBin类型，则f为红黑树根节点\n                        else if (f instanceof TreeBin) {\n                            Node<K,V> p;\n                            binCount = 2;\n                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,\n                                                           value)) != null) {\n                                oldVal = p.val;\n                                if (!onlyIfAbsent)\n                                    p.val = value;\n                            }\n                        }\n                    }\n                }\n                if (binCount != 0) {\n                \t//binCount >= TREEIFY_THRESHOLD(默认是8) 则进行链表转红黑树操作\n                    if (binCount >= TREEIFY_THRESHOLD)\n                        treeifyBin(tab, i);\n                    if (oldVal != null)\n                        return oldVal;\n                    break;\n                }\n            }\n        }\n        //扩容判断\n        addCount(1L, binCount);\n        return null;\n    }\n```\n\n 1. 对要存放的元素，利用spread方法对key的hashcode进行一次hash运算，由运算后的 hash&（n-1）来确定这个元素应该存放在数组中的位置\n 2. 如果当前table没有初始化，则先初始化数组table\n 3. 如果数组当前位置为null，则使用CAS操作直接放入\n 4. 如果这个位置存在节点，说明发生hash碰撞，首先根据此位置元素的hash判断数组是否正在进行扩容（(fh = f.hash) == MOVED），如果正在进行扩容，则一起进行扩容\n 5. 如果没正在扩容，则判断当前节点是否为链表节点，依次向后遍历确定这个新加入的值所在位置。如果遇到hash值与key值都与新加入节点是一致的情况，则只需要更新value值即可。否则依次向后遍历，直到链表尾插入这个结点；\n 6. 如果这个节点的类型是TreeBin的话，直接调用红黑树的插入方法进行插入新的节点；\n 7. 插入完节点之后再次检查链表长度，如果长度大于8，就把这个链表转换成红黑树；\n 8. 对当前容器存放的元素容量进行检查，如果超过临界值（实际大小 * 加载因子）就需要进行扩容\n\n\n\n**initTable方法**\n初始化table数组\n```java\n    private final Node<K,V>[] initTable() {\n        Node<K,V>[] tab; int sc;\n        //table为初始化才进行初始化\n        while ((tab = table) == null || tab.length == 0) {\n        \t//sizeCtl默认为0 ，使用volatile修饰，当sizeCtl《0时，代表其他线程正在初始化，当前线程只需让出CPU时间片\n            if ((sc = sizeCtl) < 0)\n                Thread.yield();\n            // 利用UnSafe.compareAndSwapInt,更改SIZECTL值为 -1 代表此时有线程在进行扩容\n            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n                try {\n                \t//再次确认table未初始化\n                    if ((tab = table) == null || tab.length == 0) {\n                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;\n                        @SuppressWarnings(\"unchecked\")\n                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];\n                        table = tab = nt;\n                        sc = n - (n >>> 2);\n                    }\n                } finally {\n                    sizeCtl = sc;\n                }\n                break;\n            }\n        }\n        return tab;\n    }\n```\n**helpTransfer方法**\n帮助扩容\n\n```java\n    final Node<K,V>[] helpTransfer(Node<K,V>[] tab, Node<K,V> f) {\n        Node<K,V>[] nextTab; int sc;\n        // f 是 ForWardingNode 类型 且 f的nextTable 不为 null \n        if (tab != null && (f instanceof ForwardingNode) &&\n            (nextTab = ((ForwardingNode<K,V>)f).nextTable) != null) {\n            //帮忙扩容，得到一个标识\n            int rs = resizeStamp(tab.length);\n            // 如果 nextTab 没有被并发修改 且 tab 也没有被并发修改\n        \t// 且 sizeCtl  < 0 （说明还在扩容） 自旋\n            while (nextTab == nextTable && table == tab &&\n                   (sc = sizeCtl) < 0) {\n                 // 如果 sizeCtl 无符号右移  16 不等于 rs （ sc前 16 位如果不等于标识符，则标识符变化了）\n            \t// 或者 sizeCtl == rs + 1  （扩容结束了，不再有线程进行扩容）（默认第一个线程设置 sc ==rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1）\n            \t// 或者 sizeCtl == rs + 65535  （如果达到最大帮助线程的数量，即 65535）\n            \t// 或者转移下标正在调整 （扩容结束）\n            \t// 结束循环，返回 table\n                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                    sc == rs + MAX_RESIZERS || transferIndex <= 0)\n                    break;\n                // 如果以上都不是, 将 sizeCtl + 1, （表示增加了一个线程帮助其扩容）    \n                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {\n                    transfer(tab, nextTab);\n                    break;\n                }\n            }\n            return nextTab;\n        }\n        return table;\n    }\n\n\tstatic final int resizeStamp(int n) {\n        return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));\n    }\n```\n关于 sizeCtl 变量：\n\n| 高RESIZE_STAMP_BITS位 |  低RESIZE_STAMP_SHIFT位|\n|--|--|\n| 扩容标记\t |并行扩容线程数 + 1 |\n\n\n\nresizeStamp 方法返回一个与table容量n大小有关的扩容标记\n\n 1. Integer.numberOfLeadingZeros(n)用于获取当前int从高位到低位第一个1前面0的个数。\n 2. RESIZE_STAMP_BITS = 16  ，  1 << (RESIZE_STAMP_BITS - 1)  后的结果是 1左移15位 也就是  0000 0000 0000 0000 1000 0000 0000 0000\n\n**addCount()方法**\nput完元素的最后，对当前元素容量大小进行检查，判断是否需要扩容\n```java\n    private final void addCount(long x, int check) {\n        CounterCell[] as; long b, s;\n        // s = sumCount() 统计容器中元素的个数，并将 BASECOUNT +1 \n        if ((as = counterCells) != null ||\n            !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {\n            CounterCell a; long v; int m;\n            boolean uncontended = true;\n            if (as == null || (m = as.length - 1) < 0 ||\n                (a = as[ThreadLocalRandom.getProbe() & m]) == null ||\n                !(uncontended =\n                  U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {\n                fullAddCount(x, uncontended);\n                return;\n            }\n            if (check <= 1)\n                return;\n            s = sumCount();\n        }\n        //check就是binCount，该值在`putVal()`里面一定是>=0的，所以这个条件一定会为true\n        if (check >= 0) {\n            Node<K,V>[] tab, nt; int n, sc;\n            //自旋\n            while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&\n                   (n = tab.length) < MAXIMUM_CAPACITY) {\n                int rs = resizeStamp(n);\n                //已经有线程进行扩容\n                if (sc < 0) {\n                    if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                        sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||\n                        transferIndex <= 0)\n                        break;\n                    //CAS  SIZECTL  增加一个线程帮助扩容\n                    if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))\n                        transfer(tab, nt);\n                }\n                // 它是第一个扩容的线程，  SIZECTL  低16位 置为 0000 0000 0000 0010 \n                else if (U.compareAndSwapInt(this, SIZECTL, sc,\n                                             (rs << RESIZE_STAMP_SHIFT) + 2))\n                    transfer(tab, null);\n                s = sumCount();\n            }\n        }\n    }\n```\n**transfer() 方法**\n扩容方法\n\n```java\nprivate final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {\n        int n = tab.length, stride;\n         // 将 n / 8 然后除以 CPU核心数。如果得到的结果小于 16，那么就使用 16。\n    \t// 这里的目的是让每个 CPU 处理的桶一样多，避免出现转移任务不均匀的现象，如果桶较少的话，默认一个 CPU（一个线程）处理 16 个桶\n        if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)\n            stride = MIN_TRANSFER_STRIDE; // subdivide range\n        // 新的 table 尚未初始化\n        if (nextTab == null) {            // initiating\n            try {\n                @SuppressWarnings(\"unchecked\")\n                //新tab大小 为原来的2倍\n                Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];\n                nextTab = nt;\n            } catch (Throwable ex) {      // try to cope with OOME\n                sizeCtl = Integer.MAX_VALUE;\n                return;\n            }\n            nextTable = nextTab;\n            transferIndex = n;\n        }\n        int nextn = nextTab.length;\n        ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);\n        boolean advance = true;\n        boolean finishing = false; // to ensure sweep before committing nextTab\n        // 死循环,i 表示下标，bound 表示当前线程可以处理的当前桶区间最小下标\n        for (int i = 0, bound = 0;;) {\n            Node<K,V> f; int fh;\n            while (advance) {\n                int nextIndex, nextBound;\n                // 对 i 减一，判断是否大于等于 bound （正常情况下，如果大于 bound 不成立，说明该线程上次领取的任务已经完成了。那么，需要在下面继续领取任务）\n            // 如果对 i 减一大于等于 bound（还需要继续做任务），或者完成了，修改推进状态为 false，不能推进了。任务成功后修改推进状态为 true。\n            // 通常，第一次进入循环，i-- 这个判断会无法通过，从而走下面的 nextIndex 赋值操作（获取最新的转移下标）。其余情况都是：如果可以推进，将 i 减一，然后修改成不可推进。如果 i 对应的桶处理成功了，改成可以推进。\n                if (--i >= bound || finishing)\n                    advance = false;\n                else if ((nextIndex = transferIndex) <= 0) {\n                    i = -1;\n                    advance = false;\n                }\n                else if (U.compareAndSwapInt\n                         (this, TRANSFERINDEX, nextIndex,\n                          nextBound = (nextIndex > stride ?\n                                       nextIndex - stride : 0))) {\n                    bound = nextBound;\n                    i = nextIndex - 1;\n                    advance = false;\n                }\n            }\n            if (i < 0 || i >= n || i + n >= nextn) {\n                int sc;\n                if (finishing) {\n                    nextTable = null;\n                    table = nextTab;\n                    sizeCtl = (n << 1) - (n >>> 1);\n                    return;\n                }\n                if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {\n                    if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)\n                        return;\n                    finishing = advance = true;\n                    i = n; // recheck before commit\n                }\n            }\n            else if ((f = tabAt(tab, i)) == null)\n                advance = casTabAt(tab, i, null, fwd);\n            else if ((fh = f.hash) == MOVED)\n                advance = true; // already processed\n            else {\n                synchronized (f) {\n                    if (tabAt(tab, i) == f) {\n                        Node<K,V> ln, hn;\n                        if (fh >= 0) {\n                        \t// hash & n 之后，因 n为 2^m 判断 m位 为0 还是1 \n                            int runBit = fh & n;\n                            Node<K,V> lastRun = f;\n                            for (Node<K,V> p = f.next; p != null; p = p.next) {\n                                int b = p.hash & n;\n                                if (b != runBit) {\n                                    runBit = b;\n                                    lastRun = p;\n                                }\n                            }\n                            //为0  则 低位是 lastRun\n                            if (runBit == 0) {\n                                ln = lastRun;\n                                hn = null;\n                            }\n                            //否则 高位是 lastRun\n                            else {\n                                hn = lastRun;\n                                ln = null;\n                            }\n                            //遍历链表 找到ln 或 hn\n                            for (Node<K,V> p = f; p != lastRun; p = p.next) {\n                                int ph = p.hash; K pk = p.key; V pv = p.val;\n                                if ((ph & n) == 0)\n                                    ln = new Node<K,V>(ph, pk, pv, ln);\n                                else\n                                    hn = new Node<K,V>(ph, pk, pv, hn);\n                            }\n                            //利用CAS  交换到nextTab 并 将tab[i]  标记为正在扩容\n                            setTabAt(nextTab, i, ln);\n                            setTabAt(nextTab, i + n, hn);\n                            setTabAt(tab, i, fwd);\n                            advance = true;\n                        }\n                        else if (f instanceof TreeBin) {\n                            TreeBin<K,V> t = (TreeBin<K,V>)f;\n                            TreeNode<K,V> lo = null, loTail = null;\n                            TreeNode<K,V> hi = null, hiTail = null;\n                            int lc = 0, hc = 0;\n                            for (Node<K,V> e = t.first; e != null; e = e.next) {\n                                int h = e.hash;\n                                TreeNode<K,V> p = new TreeNode<K,V>\n                                    (h, e.key, e.val, null, null);\n                                if ((h & n) == 0) {\n                                    if ((p.prev = loTail) == null)\n                                        lo = p;\n                                    else\n                                        loTail.next = p;\n                                    loTail = p;\n                                    ++lc;\n                                }\n                                else {\n                                    if ((p.prev = hiTail) == null)\n                                        hi = p;\n                                    else\n                                        hiTail.next = p;\n                                    hiTail = p;\n                                    ++hc;\n                                }\n                            }\n                            ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :\n                                (hc != 0) ? new TreeBin<K,V>(lo) : t;\n                            hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :\n                                (lc != 0) ? new TreeBin<K,V>(hi) : t;\n                            setTabAt(nextTab, i, ln);\n                            setTabAt(nextTab, i + n, hn);\n                            setTabAt(tab, i, fwd);\n                            advance = true;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n```\n\n 1. 通过计算 CPU 核心数和 Map 数组的长度得到每个线程（CPU）要帮助处理多少个桶，并且这里每个线程处理都是平均的。默认每个线程处理 16 个桶。因此，如果长度是 16 的时候，扩容的时候只会有一个线程扩容。\n 2. 初始化临时变量 nextTable。将其在原有基础上扩容两倍。\n 3. 死循环开始转移。多线程并发转移就是在这个死循环中，根据一个 finishing 变量来判断，该变量为 true 表示扩容结束，否则继续扩容。\n\n \t3.1 进入一个 while 循环，分配数组中一个桶的区间给线程，默认是 16. 从大到小进行分配。当拿到分配值后，进行 i-- 递减。这个 i 就是数组下标。（其中有一个 bound 参数，这个参数指的是该线程此次可以处理的区间的最小下标，超过这个下标，就需要重新领取区间或者结束扩容，还有一个 advance 参数，该参数指的是是否继续递减转移下一个桶，如果为 true，表示可以继续向后推进，反之，说明还没有处理好当前桶，不能推进)\n \t\n \t3.2 出 while 循环，进 if 判断，判断扩容是否结束，如果扩容结束，清空临死变量，更新 table 变量，更新库容阈值。如果没完成，但已经无法领取区间（没了），该线程退出该方法，并将 sizeCtl 减一，表示扩容的线程少一个了。如果减完这个数以后，sizeCtl 回归了初始状态，表示没有线程再扩容了，该方法所有的线程扩容结束了。（这里主要是判断扩容任务是否结束，如果结束了就让线程退出该方法，并更新相关变量）。然后检查所有的桶，防止遗漏。\n\n\t3.3 如果没有完成任务，且 i 对应的槽位是空，尝试 CAS 插入占位符，让 putVal 方法的线程感知。\n\n\t3.4 如果 i 对应的槽位不是空，且有了占位符，那么该线程跳过这个槽位，处理下一个槽位。\n\t\n\t3.5 如果以上都是不是，说明这个槽位有一个实际的值。开始同步处理这个桶。\n\n\t3.6 到这里，都还没有对桶内数据进行转移，只是计算了下标和处理区间，然后一些完成状态判断。同时，如果对应下标内没有数据或已经被占位了，就跳过了。\n\n 4. 锁住头结点，同步处理\n\t\n\t4.1 链表，那么就将这个链表根据 length 取于拆成两份，取于结果是 0 的放在新表的低位，取于结果是 1 放在新表的高位。\n\t\n\t4.2 红黑数，那么也拆成 2 份，方式和链表的方式一样，然后，判断拆分过的树的节点数量，如果数量小于等于 6，改造成链表。反之，继续使用红黑树结构。\n\n### 4.小结\n\n 1. 不采用Segment而采用内部类Node作为数组，锁住链表或红黑树的头结点来减小锁粒度\n 2. 不允许有 null Key 和 null Value\n 3. 扩容时，允许多线程帮助进行扩容，新数组长度为原来的2倍\n 4. 大量使用了CAS相关操作，定义了许多特殊的数据结构和变量，比如ForwardingNode和sizeCtl\n\n**参考链接**\n\n 1. [ConcurrentHashMap#transfer() 扩容逐行分析](https://www.jianshu.com/p/2829fe36a8dd)\n 2. [为并发而生的 ConcurrentHashMap（Java 8）](https://cnblogs.com/yangming1996/p/8031199.html)\n 3. [ConcurrentHashMap原理分析](https://www.cnblogs.com/study-everyday/p/6430462.html#autoid-2-2-6)\n","tags":["Java集合"]},{"title":"深入了解HashMap","url":"/2021/03/02/Java Base/HashMap/","content":">本篇分析HashMap的 hash()函数 和 底层数据结构 以及 常用方法 和 常见面试相关题目\n\n### 1. HashMap简介\nHashMap 是一个K，V键值对的常用集合类，它实现了Map接口。\njdk1.8 之前 HashMap 采用 数组 + 链表 的方式实现，链表存储key值冲突的数据。\njdk1.8 采用  数组 + 链表 / 红黑树 的方式实现，在满足下面两个条件之后，会执行链表转红黑树操作，以此来加快搜索速度。\n\n - 链表长度大于阈值（默认为 8）\n - HashMap 数组长度超过 64\n\n### 2. HashMap底层数据结构\n**类的属性**\n\n```java\npublic class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>, Cloneable, Serializable {\n\n    // 默认的初始容量是16\n    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;\n    // 最大容量\n    static final int MAXIMUM_CAPACITY = 1 << 30;\n    // 默认的填充因子\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n    // 当桶(bucket)上的结点数大于这个值时会转成红黑树\n    static final int TREEIFY_THRESHOLD = 8;\n    // 当桶(bucket)上的结点数小于这个值时树转链表\n    static final int UNTREEIFY_THRESHOLD = 6;\n    // 桶中结构转化为红黑树对应的table的最小大小\n    static final int MIN_TREEIFY_CAPACITY = 64;\n    // 存储元素的数组，大小总是2的幂次倍\n    transient Node<k,v>[] table;\n    // 存放具体元素的集\n    transient Set<map.entry<k,v>> entrySet;\n    // 存放元素的个数，注意这个不等于数组的长度。\n    transient int size;\n    // 每次扩容和更改map结构的计数器\n    transient int modCount;\n    // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容\n    int threshold;\n    // 加载因子\n    final float loadFactor;\n}\n```\n**一些内部类**\n\n - EntrySet、EntryIterator、EntrySpliterator\t\t\t键值Set 迭代器 分离器s\n - KeySet、KeyIterator、KeySpliterator\t\t\t\t\t键Set   迭代器 分离器\n - Values、ValueIterator、ValueSpliterator\t\t\t值Set   迭代器 分离器\n\n*使用*\n\n```java\npublic class TestMap {\n    public static void main(String[] args) {\n        \n        HashMap<String, String> test =  new HashMap<>();\n        System.out.println(test.size());\n        test.put(\"A\",\"AAA\");\n        test.put(\"B\",\"BBB\");\n        test.put(\"C\",\"CCC\");\n        test.put(\"D\",\"DDD\");\n        test.put(\"E\",\"EEE\");\n\n        Iterator<Map.Entry<String, String>> iterator = test.entrySet().iterator();\n        while (iterator.hasNext()){\n            System.out.println(iterator.next());\n        }\n\n        Iterator<String> iterator1 = test.keySet().iterator();\n        while (iterator1.hasNext()){\n            System.out.println(iterator1.next());\n        }\n\n        Spliterator<String> spliterator = test.values().spliterator();\n\n        System.out.println(spliterator.estimateSize());\n        spliterator.forEachRemaining(System.out::println);\n\n        System.out.println(test.size());\n    }\n}\n```\n![结果](https://img-blog.csdnimg.cn/20210301172916936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n\n**Node节点类**\n\n```java\n    static class Node<K, V> implements Entry<K, V> {\n        final int hash; //hash值，存放元素时用来与其他元素的hash值进行比较。\n        final K key; // 键  key 唯一  一个key 一个 value  允许有一个 key为 null \n        V value; // 值\n        HashMap.Node<K, V> next; //指向下一个Node\n\n        Node(int var1, K var2, V var3, HashMap.Node<K, V> var4) {\n            this.hash = var1;\n            this.key = var2;\n            this.value = var3;\n            this.next = var4;\n        }\n\n        public final K getKey() {\n            return this.key;\n        }\n\n        public final V getValue() {\n            return this.value;\n        }\n\n        public final String toString() {\n            return this.key + \"=\" + this.value;\n        }\n\t\t\n        public final int hashCode() {\n            return Objects.hashCode(this.key) ^ Objects.hashCode(this.value);\n        }\n\n        public final V setValue(V var1) {\n            Object var2 = this.value;\n            this.value = var1;\n            return var2;\n        }\n\n        public final boolean equals(Object var1) {\n            if (var1 == this) {\n                return true;\n            } else {\n                if (var1 instanceof Entry) {\n                    Entry var2 = (Entry)var1;\n                    if (Objects.equals(this.key, var2.getKey()) && Objects.equals(this.value, var2.getValue())) {\n                        return true;\n                    }\n                }\n\n                return false;\n            }\n        }\n    }\n```\n\n**TreeNode源码**\n\n```java\n    // 一些方法这里就不贴了\n    static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {\n        TreeNode<K,V> parent;  // 红黑树 父节点\n        TreeNode<K,V> left;\n        TreeNode<K,V> right;\n        TreeNode<K,V> prev;    // 删除后需要取消链接\n        boolean red;\n        TreeNode(int hash, K key, V val, Node<K,V> next) {\n            super(hash, key, val, next);\n        }\n    }\n```\n\n**数组+链表**\nNode<k,v>[] table  \n![拉链](https://img-blog.csdnimg.cn/20210301175245123.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**数组+红黑树**\n![\\[](https://img-blog.csdnimg.cn/2021030117571543.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n### 3.HashMap常用方法\n**构造函数**\n\n```java\n    /**\n     * 构造一个具有指定初始容量和负载因子的空HashMap 。\n     */\n    public HashMap(int initialCapacity, float loadFactor) {\n      //如果初始化大小小于0，抛出异常  \n        if (initialCapacity < 0)\n            throw new IllegalArgumentException(\"Illegal initial capacity: \" +\n                                               initialCapacity);\n      //HashMap 中table的最大值为2^30 如果初始化大小大于2^30，则为2^30\n        if (initialCapacity > MAXIMUM_CAPACITY)\n            initialCapacity = MAXIMUM_CAPACITY;\n            \n        if (loadFactor <= 0 || Float.isNaN(loadFactor))\n            throw new IllegalArgumentException(\"Illegal load factor: \" +\n                                               loadFactor);\n        this.loadFactor = loadFactor;\n        this.threshold = tableSizeFor(initialCapacity);\n    }\n\n    /**\n     * 自定义初始容量  使用默认加载因子（0.75）构造一个空的HashMap 。\n     */\n    public HashMap(int initialCapacity) {\n        this(initialCapacity, DEFAULT_LOAD_FACTOR);\n    }\n\n    /**\n     * 使用默认的初始容量（16）和默认的加载因子（0.75）构造一个空的HashMap 。\n     */\n    public HashMap() {\n        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted\n    }\n```\n\n - 填装因子:loadFactor 表示填装因子的大小，简单的介绍一下填装因子：假设数组大小为16，每个放到数组中的元素mod 9，所有元素取模后放的位置是（0–9） 此时填装因子的大小为 9/16 ,装填因子就为0.75啦。\n \n - HashMap初始化过程就是新建一个大小为capacity，类型为Node的数组，Node上面已经介绍过这个类，包含一个指针一个key，一个value，和一个hash。capacity是2的次幂，至于为什么是2的次幂后面会有介绍的。\n\n**hash函数**\n\n```java\n    static final int hash(Object key) {\n        int h;\n        //用 key 的 hashCode  高16位 与 低16位 进行 异或运算 结果放在低16位\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n    }\n```\n因为hashmap的 put 和 get 都要将 key 经过hash函数处理之后 与 数组大小 length -1 进行与运算，而数组的大小通常不会超过2^16，所以始终是低16位参与运算，所以将key的hashCode的高16位与低16位进行异或运算，得到的值会更具有散列的特性。\n\n**put 函数**\n\n```java\n    public V put(K key, V value) {\n        return putVal(hash(key), key, value, false, true);\n    }\n    \n    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) {\n        Node<K,V>[] tab; Node<K,V> p; int n, i;\n        //table未初始化 或者 长度为 0 进行扩容 \n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n        // 确定存放的下标，如果此时为null，则新生Node 放入当前数组下标的位置。\n        if ((p = tab[i = (n - 1) & hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n     \t//数组当前位置已存在元素\n        else {\n            Node<K,V> e; K k;\n            //数组当前位置p 的hash 与要插入元素的hash相等 且 key 相等\n            if (p.hash == hash &&\n                ((k = p.key) == key || (key != null && key.equals(k))))\n                //当前位置p 赋值给 e\n                e = p;\n            // hash值不等，即key不等，p为红黑树节点\n            else if (p instanceof TreeNode)\n            \t//插入红黑树\n                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            //为链表节点\n            else {\n            \t//在链表节点最末端插入\n                for (int binCount = 0; ; ++binCount) {\n                    if ((e = p.next) == null) {\n                    \t//插入最末端\n                        p.next = newNode(hash, key, value, null);\n                        //结点数量达到阈值(默认为 8 )，执行 treeifyBin 方法\n                        // 这个方法会根据 HashMap 数组来决定是否转换为红黑树。\n                    \t// 只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，否则就是只是对数组扩容。\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    //找到了key 值一样的节点 跳出循环 修改value\n                    if (e.hash == hash &&\n                        ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    p = e;\n                }\n            }\n            // 找到key值、hash值与插入元素相等的结点\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                \t//修改旧值\n                    e.value = value;\n                afterNodeAccess(e);\n                //返回旧值\n                return oldValue;\n            }\n        }\n        //结构性修改\n        ++modCount;\n        // 实际大小大于阈值则扩容\n        if (++size > threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210302131218700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n 1. 先判断数组 table 是否为null 或者 长度为0，如果是则 resize() 扩容，否则根据 hash 确定存放的下标，如果此时数组对应位置为null，则新生Node 放入当前数组下标的位置。\n 2. 对应位置有值，判断key是否一致，一致则直接修改value值 ，否则进行遍历在末端插入。\n 3. 判断此时链表长度是否大于默认阈值（8），不大于则直接返回旧值，否则将链表转换为红黑树。\n\n**get函数**\n\n```java\n    public V get(Object key) {\n        Node<K,V> e;\n        return (e = getNode(hash(key), key)) == null ? null : e.value;\n    }\n    \n    final Node<K,V> getNode(int hash, Object key) {\n        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;\n        if ((tab = table) != null && (n = tab.length) > 0 &&\n            (first = tab[(n - 1) & hash]) != null) { // hash计算出的 数组位置 第一个元素存在\n            if (first.hash == hash && // 数组当位置的第一个元素 hash 与要取的 hash相当 且 key相等\n                ((k = first.key) == key || (key != null && key.equals(k))))\n                return first;\n            if ((e = first.next) != null) { // 存在第二个元素\n                if (first instanceof TreeNode) // 第一个元素是一个树节点 调红黑树的取值方法\n                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);\n                do {// 链表节点  循环遍历  找到节点相等的key 和 hash\n                    if (e.hash == hash &&\n                        ((k = e.key) == key || (key != null && key.equals(k))))\n                        return e;\n                } while ((e = e.next) != null);\n            }\n        }\n        // 没有  返回null\n        return null;\n    }\n```\n**扩容**\n什么时候进行扩容操作？\n\n 1. 数组 table 为null 或者长度为 0\n 2. 数组中元素实际个数大于阈值 threshold 会扩容\n 3. 链表中的长度超过了TREEIFY_THRESHOLD（8），但表长度却小于MIN_TREEIFY_CAPACITY（64）\n\n```java\n    final Node<K,V>[] resize() {\n        Node<K,V>[] oldTab = table;\n        int oldCap = (oldTab == null) ? 0 : oldTab.length;\n        int oldThr = threshold;\n        int newCap, newThr = 0;\n        //旧容量大于 0 \n        if (oldCap > 0) {\n        \t//旧容量大于等于最大容量 阈值等于最大容量 并返回旧容量值\n            if (oldCap >= MAXIMUM_CAPACITY) {\n                threshold = Integer.MAX_VALUE;\n                return oldTab;\n            }\n            //新容量 为 旧容量的2倍 且 旧容量大于默认初始化容量且小于最大容量\n            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&\n                     oldCap >= DEFAULT_INITIAL_CAPACITY)\n                newThr = oldThr << 1; // 新阈值为 旧阈值的2倍\n        }\n        else if (oldThr > 0) //旧容量小于等于0时 新容量 等于 旧阈值\n            newCap = oldThr;\n        else {               // 阈值和容量 都初始化为默认值\n            newCap = DEFAULT_INITIAL_CAPACITY;\n            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n        }\n        if (newThr == 0) {\n            float ft = (float)newCap * loadFactor;\n            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n                      (int)ft : Integer.MAX_VALUE);\n        }\n        threshold = newThr;\n        @SuppressWarnings({\"rawtypes\",\"unchecked\"})\n        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];\n        table = newTab;\n        if (oldTab != null) {\n        \t//遍历旧数组 oldTab\n            for (int j = 0; j < oldCap; ++j) {\n                Node<K,V> e;\n                if ((e = oldTab[j]) != null) {\n                \t//旧数组 j 位置置空\n                    oldTab[j] = null;\n                    //只有一个值，根据hash放入新数组的对应位置\n                    if (e.next == null)\n                        newTab[e.hash & (newCap - 1)] = e;\n                    //为红黑树 \n                    else if (e instanceof TreeNode)\n                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n                    else { // 链表优化重hash的节点\n                        Node<K,V> loHead = null, loTail = null;\n                        Node<K,V> hiHead = null, hiTail = null;\n                        Node<K,V> next;\n                        do {\n                            next = e.next;\n                            //原索引\n                            if ((e.hash & oldCap) == 0) {\n                                if (loTail == null)\n                                    loHead = e;\n                                else\n                                    loTail.next = e;\n                                loTail = e;\n                            }\n                            //原索引 + oldCap\n                            else {\n                                if (hiTail == null)\n                                    hiHead = e;\n                                else\n                                    hiTail.next = e;\n                                hiTail = e;\n                            }\n                        } while ((e = next) != null);\n                         // 原索引放到新数组 j 上\n                        if (loTail != null) {\n                            loTail.next = null;\n                            newTab[j] = loHead;\n                        }\n                        // 原索引+oldCap放到新数组 j+oldCap 上\n                        if (hiTail != null) {\n                            hiTail.next = null;\n                            newTab[j + oldCap] = hiHead;\n                        }\n                    }\n                }\n            }\n        }\n        return newTab;\n    }\n```\n### 小结\n\n 1. 扩容是一个特别耗性能的操作，所以当使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。\n 2. 负载因子是可以修改的，也可以大于1，但是不建议轻易修改。\n 3. HashMap不是线程安全的，不要在并发环境下同时操作HashMap，建设使用ConcurrentHashMap。\n 4. JDK1.8之前 HashMap是数组+链表的实现，JDK1.8采用数组+链表/红黑树的方式实现。\n\n\n### 4.常见面试题\n**1.HashMap的底层数据结构**\nJDK1.8之前    \t数组+链表\nJDK1.8之后\t\t数组+链表/红黑树\n\n**2.HashMap的工作原理**\nHashMap底层是数组+链表，由Node内部类实现，通过put方法存放、get方法获取数据。\n\n存储数据时，将K，V键值传给put方法\n\n 1. 调用hash(K)方法，计算K的hash值，hash&(n-1)计算此时应放的数组下标。\n 2. 判断当前数组位置是否有值，没有则直接插入，有值则判断他们的key是否相等，相等则修改它的值。\n 3. 否则，判断当前节点是红黑树还是链表，若是链表则遍历，在末端插入元素，若存在key相等的节点，则修改它的值，若是红黑树则遍历红黑树并插入元素\n 4. 判断插入链表后，链表的长度是否大于8，如果大于且数组长度大于64，则链表转为红黑树，数组长度小于64，则数组扩容。\n 5. 判断插入之后，HashMap实际元素的个数是否大于 capacity * loadfactor，大于会进行扩容。\n\n获取数据时，将K值传给get方法。\n\n 1. 调用 hash(K) 方法（计算 K 的 hash 值）从而获取该键值所在链表的数组下标\n 2. 遍历链表或者红黑树，equals()方法查找相同 Node 链表中 K 值对应的 V 值。\n\n **3.HashMap 的底层数组长度为何总是2的n次方**\n\n1. 数据分布均匀，减少hash碰撞\n2. 当长度n总是2的n次方时  hash&（n-1）相当于 hash%n-1，即相当于取模运算，而且在速度、效率上比直接取模要快得多\n\n**4.HashMap允许空键空值么**\nHashMap允许Key有一个为null，允许多个Value为null\n\n**5.HashMap线程安全方面会出现什么问题**\nJDK1.7   扩容会出现循环链或数据丢失\nJDK1.8   put会出现数据覆盖\n\n\n**参考链接**\n\n 1. [美团技术团队 Java 8系列之重新认识HashMap](https://tech.meituan.com/2016/06/24/java-hashmap.html)\n 2. [JavaGuide HashMap(JDK1.8)源码+底层数据结构分析](https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/collection/HashMap%28JDK1.8%29%E6%BA%90%E7%A0%81+%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90.md)\n 3. [HashMap 常见面试题](https://www.cnblogs.com/java1024/p/13488714.html)\n\n","tags":["Java集合"]},{"title":"Java集合小结","url":"/2021/02/23/Java Base/Java集合小结/","content":">这篇文章对Java集合相关类进行介绍，包括Collection、List、Set、Map、Queue这些常见得集合相关接口和类。\n\n### 1.集合概述\n常用的集合有List、Set、Map、Queue等，他们之间的关系如下图。List、Queue、Set继承Collection接口。Iterable接口是迭代器，这里不进行过多介绍。Map接口是一个单独的接口，这里不进行介绍。\n![关系图](https://img-blog.csdnimg.cn/20210223141021909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**List、Set、Queue、Map的区别**\n- List存储可以重复、有序的元素\n- Set存储不可以重复、无序的元素\n- Queue存储有序的元素且先进先出，是一个队列\n- Map是键值对存储结构，Key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值，key和value都可以为null\n\n### 2.List\n\n**List：元素有序，元素可重复，添加的元素放在最后（按照插入顺序保存元素）**\n\n常用子类有：\n\n - ArrayList\n - LinkedList\n - Vector\n\n**2.1 ArrayList**\n![arraylist继承图](https://img-blog.csdnimg.cn/202102231429137.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\nArrayList继承AbstractList抽象类，实现List、Serializable、Cloneable、RandomAccess接口。\n**使用 Object[] 数组存储元素** 因此查询快，增删操作慢，没有实现线程同步。\n\n常用方法：\n - add(E e) 向数组末尾添加一个元素\n - clear() 清除所有元素，数组里的元素为null，size置为0\n - contains(Object o)  是否包含某个元素\n - get(int index) 获取第i个元素\n - remove(int index) 删除第i个元素\n - remove(Object o) 删除某个元素\n - size() 返回存储了多少个元素\n\n**2.2 LinkedList**\n![LinkedList继承图](https://img-blog.csdnimg.cn/20210223144522217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\nLinkedList继承AbstractSequentialList抽象类，实现List、Serializable、Cloneable、Deque接口。\n**使用双向链表存储元素（内有Node私有静态内部类）** 因此查询慢，增删操作快，没有实现线程同步。\n![双向链表](https://img-blog.csdnimg.cn/20210223144842742.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n因为实现了Deque接口，所以除了拥有列表相关的常用方法外，还有队列相关的方法。\n\n**实现List接口的方法（列表相关操作）常用方法和ArrayList类似**\n![列表相关操作](https://img-blog.csdnimg.cn/20210223145208747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**实现Deque接口的方法（队列相关操作）**\n![队列相关操作](https://img-blog.csdnimg.cn/20210223150655944.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n\n - addFirst(E e)  offerFirst(E e)  插入链表首位\n - addLast(E e)  offerLast(E e)  插入链表末尾\n - getFirst()  element()   获取链表首位元素\n - getLast()  获取链表末尾元素\n - offer(E e)  链表末尾添加元素\n - peek()  peekFirst()  获取链表首位元素 但不删除\n - poll()  pollFirst()  获取链表首位元素 且删除\n\n**2.3 Vector**\n![Vector继承](https://img-blog.csdnimg.cn/20210223151148644.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n**使用 Object[] 数组存储元素** 因此查询快，增删操作慢，实现线程同步。\nVector非常类似ArrayList，但是Vector是同步的。由Vector创建的Iterator，虽然和 ArrayList创建的Iterator是同一接口，但是，因为Vector是同步的，当一个Iterator被创建而且正在被使用，另一个线程改变了 Vector的状态（例如，添加或删除了一些元素），这时调用Iterator的方法时将抛出 ConcurrentModificationException。\n\n### 3.Set\n**Set：元素无序，元素不可重复。**\n - 无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。\n - 不可重复性是指添加的元素按照 equals()判断时 ，返回 false，需要同时重写 equals()方法和 HashCode()方法。\n\n常用子类：\n\n - HashSet\n - LinkedHashSet\n - TreeSet\n\n**3.1 HashSet**\n使用HashMap来保存所有元素，线程不安全的，集合元素可以是null,但只能放入一个null，不能保证迭代的顺序与插入的顺序一致。\n\n**当使用add方法添加元素时，底层是使用HashMap的put方法，会计算key的hash值，以hashcode值不同来去除重复的值，值得注意的是当添加对象作为键时，应该重写对象类的hashCode()和equals()方法**\n如果自定义的类中没有重写equals()，那么比较的还是地址，返回值不同，则判断为两个对象不相等，都被添加到了集合中，所以也要重写equals()。\n所以自定义对象添加到Set集合类中一定要重写hashCode()与equals()，缺一不可 。\n\n**3.2 LinkedHashSet**\n使用LinkedHashMap来保存所有元素，线程不安全的，集合元素不能重复，迭代输出的顺序与插入的顺序保持一致。\n**继承HashSet**\n\n**3.3 TreeSet**\nTreeSet 是 SortedSet 接口的实现类，TreeSet 可以确保集合元素处于排序状态。TreeSet底层使用红黑树结构存储数据(使用TreeMap存储元素)，默认情况下，TreeSet 采用自然排序。\n向TreeSet中添加的数据，要求是相同类的对象，需要实现使用至少一种排序方式，Comparable（自然排序）和Comparator（定制排序）。比较两个对象是否相同的标准是重写的方法是否返回0，不再equals()。\n\n### 4.Queue\n队列通常但不一定以FIFO（先进先出）的方式对元素进行排序。 例外情况包括优先级队列（根据提供的比较器对元素进行排序或元素的自然排序）和LIFO队列（或堆栈），对LIFO进行排序（后进先出）。\n\n很多常用queue子类都与线程有关，LinkedList已经介绍过了，这里只介绍ArrayDeque。\n\n**Deque**\nDeque扩展了Queue，有队列的所有方法，还可以看做栈，有栈的基本方法push/pop/peek，还有明确的操作两端的方法如addFirst/removeLast等。\n\n![方法](https://img-blog.csdnimg.cn/20210223172655847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n\n该接口定义了访问双端队列两端的元素的方法。 提供了用于插入，删除和检查元素的方法。 这些方法中的每一种都以两种形式存在：一种在操作失败时引发异常，另一种返回一个特殊值（取决于操作，为null或false ）。 插入操作的后一种形式是专门为容量受限的Deque实现而设计的。 在大多数实现中，插入操作不会失败。\n\n**4.1 ArrayDeque**\nArrayDeque实现了Deque接口，同LinkedList一样，它的队列长度也是没有限制的，底层使用 Object[] 数组存储元素\n![方法](https://img-blog.csdnimg.cn/20210223172604231.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n - ArrayDeque 是一个可扩容的数组，LinkedList 是链表结构；\n - ArrayDeque 里不可以存 null 值，但是 LinkedList 可以；\n - ArrayDeque 在操作头尾端的增删操作时更高效，但是 LinkedList 只有在当要移除中间某个元素且已经找到了这个元素后的移除才是 O(1) 的；因为ArrayDeque底层使用的是一个逻辑循环数组\n - ArrayDeque 在内存使用方面更高效。\n\n**推荐使用ArrayDeque**\n\n### 5.Map接口\nMap接口与List、Set接口不同，它并未继承Collection接口，是由一系列键值对组成的接口，是一个独立的接口。常用的实现Map的类有HashMap、ConcurrentHashMap、HashTable、TreeMap。\n\nMap接口有一个内部接口Entry，它是存储元素键值对的条目。\n\n\n##### 5.1HashMap和HashTable的区别\n\n - 线程安全：HashMap不是线程安全的，HashTable是线程安全的，它通过使用synchonrized修饰方法保证线程安全\n - 效率：HashMap比HashTable效率高，如果为了保证线程安全推荐使用ConcurrentHashMap，不推荐使用HashTable\n - 对 Null key 和 Null value 的支持： HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；HashTable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。\n - 初始容量大小和每次扩充容量大小的不同 ： ① 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的tableSizeFor()方法保证，下面给出了源代码）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。\n - 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。\n\n##### 5.2HashMap的底层实现\njdk1.8以前，HashMap底层使用数组加链表的方式实现，也称链表散列。HashMap通过key的hashCode经过hash()函数处理后得到hash值，然后通过（n - 1）& hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。\n\n[hash函数详解](https://www.hollischuang.com/archives/2091)\n\n为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上面也讲到了过了，Hash 值的范围值-2147483648 到 2147483647，前后加起来大概 40 亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个 40 亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是“ (n - 1) & hash”。（n 代表数组长度）。这也就解释了 HashMap 的长度为什么是 2 的幂次方。\n\n这个算法应该如何设计呢？\n\n我们首先可能会想到采用%取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是 2 的 n 次方；）。” 并且 采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。\n\n##### 5.3ConcurrentHashMap 和 Hashtable 的区别\n\n - 底层数据结构：ConcurrentHashMap在jdk1.7之前使用 分段数组+链表 实现，jdk1.8采用同HashMap一样的 数组 + 链表/红黑树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式。\n - 实现线程安全的方式：ConcurrentHashMap在jdk1.7之前使用分段数组segment 加锁实现，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。jdk1.8 采用了粒度更小的方式，直接对Node采用 volalite 关键字修饰，方法则用synchronized和CAS进行并发控制。","tags":["Java集合"]},{"title":"Aviator的初步了解和使用","url":"/2021/01/18/Aviator/aviator使用/","content":">\"初步了解和使用Aviator\"\n\n## 1.Aviator简介\nAviator 是一个高性能，轻量级的java语言实现的**表达式求值引擎**，主要用于各种表达式的动态求值。\n\n[官方文档](https://www.yuque.com/boyan-avfmj/aviatorscript/ra28g1#f67a50b4)\n\n[github地址](https://github.com/killme2008/aviatorscript)\n\n\n>支持数字、字符串、正则表达式、布尔值、正则表达式等基本类型，完整支持所有 Java 运算符及优先级等。\n函数是一等公民，支持闭包和函数式编程。\n内置 bigint/decmal 类型用于大整数和高精度运算，支持运算符重载得以让这些类型使用普通的算术运算符 +-*/ 参与运算。\n完整的脚本语法支持，包括多行数据、条件语句、循环语句、词法作用域和异常处理等。\n函数式编程结合 Sequence 抽象，便捷处理任何集合。\n轻量化的模块系统。\n多种方式，方便地调用 Java 方法，完整支持 Java 脚本 API（方便从 Java 调用脚本）。\n丰富的定制选项，可作为安全的语言沙箱和全功能语言使用。\n轻量化，高性能，通过直接将脚本翻译成 JVM 字节码，AviatorScript 的基础性能较好。\n\n使用场景包括：\n\n 1. 规则判断及规则引擎\n 2. 公式计算\n 3. 动态脚本控制\n 4. 集合数据 ELT 等 ……\n\n\n## 2.Aviator入门常用\n>**这里使用版本为4.2.5**\n\n#### 2.1数据类型\n\n - Number类型: 数字类型,支持四种类型,分别是long,double,java.math.BigInteger(简称 big int)和java.math.BigDecimal(简 称 decimal),规则如下:\n\t - 任何以大写字母 N 结尾的整数都被认为是 big int\n\t - \t任何以大写字母 M 结尾的数字都被认为是 decimal\n\t - 其他的任何整数都将被转换为 Long\n\t - 其他任何浮点数都将被转换为 Double\n\t - 超过 long 范围的整数字面量都将自动转换为 big int 类型\n - String类型: 字符串类型,单引号或者双引号括起来的文本串,如'hello world', 变量如果传入的是String或者Character也将转为String类型\n - Bool类型: 常量true和false,表示真值和假值,与 java 的Boolean.TRUE和Boolean.False对应\n -  Pattern类型: 正则表达式, 以//括起来的字符串,如/\\d+/,内部 实现为java.util.Pattern\n - 变量类型: 与 Java 的变量命名规则相同,变量的值由用户传入\n - nil类型: 常量nil,类似 java 中的null,但是nil比较特殊,nil不仅可以参与==、!=的比较, 也可以参与>、>=、<、<=的比较,Aviator 规定任何类型都大于nil除了nil本身,nil==nil返回true。 用户传入的变量值如果为null,那么也将作为nil处理,nil打印为null\n \n#### 2.2操作符\n##### 算术运算符\nAviator 支持常见的算术运算符,包括+ - * / %五个二元运算符,和一元运算符-(负)。其中- * / %和一元的-仅能作用于Number类型。\n+不仅能用于Number类型,还可以用于String的相加,或者字符串与其他对象的相加。\nAviator 规定,任何类型与String相加,结果为String。\n\n##### 逻辑运算符\nAvaitor 的支持的逻辑运算符包括,一元否定运算符!,以及逻辑与的&&,逻辑或的||。逻辑运算符的操作数只能为Boolean。\n&&和||都执行短路规则。\n##### 关系运算符\nAviator 支持的关系运算符包括<, <=, >, >=以及==和!= 。\n关系运算符可以作用于Number之间、String之间、Pattern之间、Boolean之间、变量之间以及其他类型与nil之间的关系比较, 不同类型除了nil之外不能相互比较。\n\n## 3.一些简单特性\n\n```java\npackage aviator;\n\nimport com.googlecode.aviator.AviatorEvaluator;\nimport com.googlecode.aviator.Expression;\nimport com.googlecode.aviator.runtime.function.AbstractFunction;\nimport com.googlecode.aviator.runtime.function.AbstractVariadicFunction;\nimport com.googlecode.aviator.runtime.function.FunctionUtils;\nimport com.googlecode.aviator.runtime.type.AviatorDouble;\nimport com.googlecode.aviator.runtime.type.AviatorObject;\nimport com.googlecode.aviator.runtime.type.AviatorString;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-16 15:39\n */\npublic class App {\n    public static void main(String[] args) {\n        //执行表达式 Aviator的数值类型仅支持Long和Double, 任何整数都将转换成Long,\n        // 任何浮点数都将转换为Double, 包括用户传入的变量数值\n        Object execute = AviatorEvaluator.execute(\"1+1+2\");\n        System.out.println(execute.toString() + execute.getClass().getSimpleName());\n        Object execute1 = AviatorEvaluator.execute(\"2.3+3.0\");\n        System.out.println(execute1.toString() + execute1.getClass().getSimpleName());\n\n        //内置函数和 多行表达式 使用; 隔开\n        Expression compile = AviatorEvaluator.getInstance().compile(\"println('Hello, AviatorScript!'); 1+2\");\n        Object res = compile.execute();\n        System.out.println(res.toString());\n\n        //使用变量\n        Map<String, Object> env = new HashMap<String, Object>();\n        env.put(\"name\",\"zsad\");\n        String execute2 = (String) AviatorEvaluator.execute(\" 'hello' + name\", env);\n        System.out.println(execute2);\n\n        //支持函数调用\n        Object execute3 = AviatorEvaluator.execute(\"string.length('hello')\");\n        System.out.println(execute3.toString());\n\n\n        //支持通过 lambda 关键字定义一个匿名函数，并且支持闭包捕获\n        //lambda (参数1,参数2...) -> 参数体表达式 end\n        env.put(\"x\",1);\n        env.put(\"y\",10);\n        Object execute4 = AviatorEvaluator.execute(\"(lambda (x,y) -> x + y end)(x,y)\", env);\n        System.out.println(execute4.toString());\n\n        //支持自定义函数\n        AviatorEvaluator.addFunction(new AddFunction());\n        AviatorEvaluator.addFunction(new GetFirstNonNullFunction());\n        env.put(\"a\",12);\n        env.put(\"v\",13);\n\n        //参数确定 自定义函数\n        System.out.println(AviatorEvaluator.execute(\"add(1,33)\").toString());\n        //参数不确定自定义函数\n        System.out.println(AviatorEvaluator.execute(\"getFirstNonNull(a,v,bas,asf)\",env));\n        //lambda表达式 自定义函数\n        AviatorEvaluator.defineFunction(\"sub\",\"lambda (a,b) -> a - b end\");\n        System.out.println(AviatorEvaluator.execute(\"sub(12,13)\").toString());\n        //lambda表达式支持闭包 自定义函数  ? 按照官方写 会报错  存疑\n        AviatorEvaluator.defineFunction(\"sub2\",\"lambda (a) -> lambda (b) -> a - b end end\");\n        System.out.println(AviatorEvaluator.execute(\"sub2(12)(14)\").toString());\n\n    }\n\n    //参数确定 继承 AbstractFunction\n    static class AddFunction extends AbstractFunction {\n\n        @Override\n        public AviatorObject call(Map<String, Object> env, AviatorObject arg1, AviatorObject arg2) {\n            Number left = FunctionUtils.getNumberValue(arg1, env);\n            Number right = FunctionUtils.getNumberValue(arg2, env);\n            return new AviatorDouble(left.doubleValue() + right.doubleValue());\n        }\n\n        //函数名 add\n        @Override\n        public String getName() {\n            return \"add\";\n        }\n    }\n\n    //参数不确定 继承 AbstractVariadicFunction\n    static class GetFirstNonNullFunction extends AbstractVariadicFunction {\n\n        @Override\n        public AviatorObject variadicCall(Map<String, Object> env, AviatorObject... args) {\n            if (args != null) {\n                for (AviatorObject arg : args) {\n                    if (arg.getValue(env) != null) {\n                        return arg;\n                    }\n                }\n            }\n            return new AviatorString(null);\n        }\n\n\n        @Override\n        public String getName() {\n            return \"getFirstNonNull\";\n        }\n\n    }\n}\n\n```\n\n**运行结果**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210118160419292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n## 4.官方函数例子(官方代码)\n\n```java\npackage aviator.example;\n\nimport com.googlecode.aviator.AviatorEvaluator;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.Map;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-18 15:59\n */\npublic class FunctionExample {\n    public static void main(String[] args) {\n        System.out.println(AviatorEvaluator.execute(\"sysdate()\"));\n        System.out.println(AviatorEvaluator.execute(\"rand()\"));\n        System.out.println(AviatorEvaluator.execute(\"now()\"));\n        System.out.println(AviatorEvaluator.execute(\"date_to_string(sysdate(),'yyyy-MM-dd')\"));\n        System.out.println(AviatorEvaluator\n                .execute(\"string_to_date(date_to_string(sysdate(),'yyyy-MM-dd'),'yyyy-MM-dd')\"));\n\n        // string function\n        System.out.println(\"test string function...\");\n        System.out.println(AviatorEvaluator.execute(\"string.length('hello')\"));\n        System.out.println(AviatorEvaluator.execute(\"string.contains('hello','h')\"));\n        System.out.println(AviatorEvaluator.execute(\"string.startsWith('hello','h')\"));\n        System.out.println(AviatorEvaluator.execute(\"string.endsWith('hello','llo')\"));\n        System.out.println(\n                AviatorEvaluator.execute(\"string.contains(\\\"test\\\",string.substring('hello',1,2))\"));\n        System.out.println(Arrays\n                .toString((String[]) AviatorEvaluator.execute(\"string.split('hello world,aviator',' ')\")));\n\n        // math function\n        System.out.println(\"test math function...\");\n        System.out.println(AviatorEvaluator.execute(\"math.abs(-3)\"));\n        System.out.println(AviatorEvaluator.execute(\"math.pow(-3,2)\"));\n        System.out.println(AviatorEvaluator.execute(\"math.sqrt(14.0)\"));\n        System.out.println(AviatorEvaluator.execute(\"math.log(100)\"));\n        System.out.println(AviatorEvaluator.execute(\"math.log10(1000)\"));\n        System.out.println(AviatorEvaluator.execute(\"math.sin(20)\"));\n        System.out.println(AviatorEvaluator.execute(\"math.cos(99.23)\"));\n        System.out.println(AviatorEvaluator.execute(\"math.tan(19.9)\"));\n\n        // seq lib\n        Map<String, Object> env = new HashMap<String, Object>();\n        ArrayList<Integer> list = new ArrayList<Integer>();\n        list.add(3);\n        list.add(100);\n        list.add(-100);\n        env.put(\"list\", list);\n        System.out.println(AviatorEvaluator.execute(\"reduce(list,+,0)\", env));\n        System.out.println(AviatorEvaluator.execute(\"filter(list,seq.exists())\", env));\n        System.out.println(AviatorEvaluator.execute(\"count(list)\", env));\n        System.out.println(AviatorEvaluator.execute(\"include(list,100)\", env));\n        System.out.println(AviatorEvaluator.execute(\"sort(list)\", env));\n        System.out.println(AviatorEvaluator.execute(\"map(list,println)\", env));\n        System.out.println(list);\n    }\n}\n\n```\n**运行结果**\n\n![运行结果](https://img-blog.csdnimg.cn/20210118160714133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n## 5.支持大数据操作\n\n```java\npackage aviator.example;\n\nimport com.googlecode.aviator.AviatorEvaluator;\nimport com.googlecode.aviator.Options;\n\nimport java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.math.MathContext;\nimport java.util.HashMap;\nimport java.util.Map;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-18 16:10\n */\npublic class BigNumberExample {\n    //以大写字母N为后缀的整数都被认为是big int,如1N,2N,9999999999999999999999N等, 都是big int类型。\n    //超过long范围的整数字面量都将自动转换为big int类型。\n    //以大写字母M为后缀的数字都被认为是decimal, 如1M,2.222M, 100000.9999M等, 都是decimal类型。\n    //big int和decimal的运算,跟其他数字类型long,double没有什么区别,操作符仍然是一样的。\n    // aviator重载了基本算术操作符来支持这两种新类型:\n    public static void main(String[] args) {\n        Object rt = AviatorEvaluator.execute(\"9223372036854775807100.356M * 2\");\n        System.out.println(rt + \"  \" + rt.getClass());\n\n        rt = AviatorEvaluator.execute(\"92233720368547758074+1000\");\n        System.out.println(rt + \"  \" + rt.getClass());\n\n        BigInteger a = new BigInteger(String.valueOf(Long.MAX_VALUE) + String.valueOf(Long.MAX_VALUE));\n        BigDecimal b = new BigDecimal(\"3.2\");\n        BigDecimal c = new BigDecimal(\"9999.99999\");\n\n        Map<String, Object> env = new HashMap<String, Object>();\n        env.put(\"a\", a);\n        env.put(\"b\", b);\n        env.put(\"c\", c);\n\n        rt = AviatorEvaluator.execute(\"a+10000000000000000000\", env);\n        System.out.println(rt + \"  \" + rt.getClass());\n\n        rt = AviatorEvaluator.execute(\"b+c*2\", env);\n        System.out.println(rt + \"  \" + rt.getClass());\n\n        rt = AviatorEvaluator.execute(\"a*b/c\", env);\n        System.out.println(rt + \"  \" + rt.getClass());\n\n        // set math context\n        AviatorEvaluator.setOption(Options.MATH_CONTEXT, MathContext.DECIMAL64);\n        rt = AviatorEvaluator.execute(\"a*b/c\", env);\n        System.out.println(rt + \"  \" + rt.getClass());\n    }\n}\n\n```\n**运行结果**\n![运行结果](https://img-blog.csdnimg.cn/20210118163700982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n## 6.正则表达式匹配\n\n```java\npackage aviator.example;\n\nimport com.googlecode.aviator.AviatorEvaluator;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-18 16:40\n */\npublic class RegularExpressionExample {\n    //email与正则表达式/([\\\\w0-8]+@\\\\w+[\\\\.\\\\w+]+)/通过=~操作符来匹配,结果为一个 Boolean 类 型,\n    // 因此可以用于三元表达式判断,匹配成功的时候返回$1,指代正则表达式的分组 1,也就是用户名,否则返回unknown。\n    //Aviator 在表达式级别支持正则表达式,通过//括起来的字符序列构成一个正则表达式,\n    // 正则表达式可以用于匹配(作为=~的右操作数)、比较大小。但是匹配仅能与字符串进行匹配。\n    // 匹配成功后, Aviator 会自动将匹配成功的捕获分组(capturing groups) 放入 env ${num}的变量中,\n    // 其中$0 指代整个匹配的字符串,而$1表示第一个分组，$2表示第二个分组以此类推。\n    //请注意，分组捕获放入 env 是默认开启的，因此如果传入的 env 不是线程安全并且被并发使用，可能存在线程安全的隐患。\n    // 关闭分组匹配，可以通过 AviatorEvaluator.setOption(Options.PUT_CAPTURING_GROUPS_INTO_ENV, false);来关闭，对性能有稍许好处。\n    //Aviator 的正则表达式规则跟 Java 完全一样,因为内部其实就是使用java.util.regex.Pattern做编译的。\n    public static void main(final String[] args) {\n        String email = \"killme2008@gmail.com\";\n        Map<String, Object> env = new HashMap<>();\n        env.put(\"email\", email);\n        String username =\n                (String) AviatorEvaluator.execute(\"email=~/([\\\\w0-8]+)@\\\\w+[\\\\.\\\\w+]+/ ? $1:'unknow'\", env);\n        System.out.println(username);\n    }\n}\n\n```\n**运行结果**\n![运行结果](https://img-blog.csdnimg.cn/20210118164657569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n","tags":["Aviator"]},{"title":"Spring AOP的初步使用","url":"/2021/01/11/Spring/Spring AOP/Spring AOP使用/","content":"\n>\"初步了解和使用SPRING AOP\"\n>\n## 一、JDK 动态代理的使用\n### 1.Food  目标接口\n\n```java\npackage proxy;\n\n/**\n * @author zsy\n * @version v1.0\n * @Description\n * @date 2020-09-23 15:50\n */\npublic interface Food {\n    /**\n     * @Author Zousy\n     * @Description 测试静态代理\n     * @Date 15:52 2020/9/23\n     * @Param []\n     * @return void\n     */\n    void priName();\n}\n```\n### 2.DynamicProxy 动态代理类 要实现 InvocationHandler接口\n\n```java\npackage proxy;\n\n\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\n\n/**\n * @author zsy\n * @version v1.0\n * @Description\n * @date 2020-09-23 15:57\n */\npublic class DynamicProxy implements InvocationHandler {\n    private Object target;\n\n    public DynamicProxy(Object target){\n        this.target = target;\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    \n            System.out.println(\"动态代理前------------\");\n            Object result = method.invoke(target,args);\n            System.out.println(\"动态代理后------------\");\n\n            return result;\n    }\n}\n\n```\n### 3.Test 测试类\n\n```java\npackage proxy;\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Proxy;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-09 16:32\n */\npublic class App {\n    public static void main(String[] args) {\n        Food food = new Food() {\n            @Override\n            public void priName() {\n                System.out.println(\"--------执行记录---------\");\n            }\n        };\n        InvocationHandler invocationHandler = new DynamicProxy(food);\n\n        Food proxy = (Food) Proxy.newProxyInstance(food.getClass().getClassLoader(),\n                food.getClass().getInterfaces(),invocationHandler);\n        proxy.priName();\n    }\n}\n```\n### 4.输出\n![执行结果](https://img-blog.csdnimg.cn/2021010916520088.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n\n\n## 二、CGLIB的使用\n### 1.Food 目标类\n\n```java\npackage com.proxy;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-09 17:14\n */\npublic class Food {\n    public void priName(){\n        System.out.println(\"----------执行-----------\");\n    }\n}\n\n```\n### 1.App 测试类\n\n```java\npackage com.proxy;\n\nimport org.springframework.cglib.proxy.Enhancer;\nimport org.springframework.cglib.proxy.MethodInterceptor;\nimport org.springframework.cglib.proxy.MethodProxy;\n\nimport java.lang.reflect.Method;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-09 17:15\n */\npublic class App {\n    public static void main(String[] args) {\n        Enhancer enhancer = new Enhancer();\n        Food food = new Food();\n\n        enhancer.setSuperclass(food.getClass());\n        enhancer.setCallback(new MethodInterceptor() {\n            @Override\n            public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {\n                System.out.println(\"记录执行日志\");\n                return methodProxy.invokeSuper(o,objects);\n            }\n        });\n\n        Food proxy = (Food) enhancer.create();\n        proxy.priName();\n    }\n}\n\n```\n### 3. 输出\n![输出结果](https://img-blog.csdnimg.cn/2021010917234980.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n## 3. Spring Aop的使用\n![spring aop通知类型](https://img-blog.csdnimg.cn/20210114142914482.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n### 1.LogAop 切面类\n\n```java\npackage com.page.aop;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.aspectj.lang.ProceedingJoinPoint;\nimport org.aspectj.lang.annotation.*;\nimport org.springframework.stereotype.Component;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description  切面必须配置到IOC容器中\n * @date 2021-01-11 14:06\n */\n@Aspect\n@Slf4j\n@Component\npublic class LogAop {\n\n    //切入点 需要写 切点表达式\n    @Pointcut(\"execution (* com.page.service.impl.UserServiceImpl.query(..))\")\n    public void pointcut(){\n    }\n\n    @Before(\"pointcut()\")\n    public void before(){\n        log.info(\"---------执行之前----------\");\n    }\n\n    @After(\"pointcut()\")\n    public void after(){\n        log.info(\"---------执行之后----------\");\n    }\n\n\n    @Around(\"pointcut()\")\n    public void around(ProceedingJoinPoint point) throws Throwable {\n        log.info(\"---------环绕执行之前----------\");\n        point.proceed();\n        System.out.println(point.getClass().getName());\n        System.out.println(point.getTarget().getClass().getSimpleName());\n        log.info(\"---------环绕执行之后----------\");\n    }\n\n    @AfterReturning(\"pointcut()\")\n    public void afterReturning(){\n        log.info(\"---------------方法返回之后执行--------------\");\n    }\n}\n\n```\n### 2.UserServiceImpl 测试类\n\n```java\npackage com.page.service.impl;\n\nimport com.page.service.UserService;\nimport org.springframework.stereotype.Service;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2021-01-09 18:02\n */\n@Service\npublic class UserServiceImpl implements UserService {\n\n    public void query(){\n        System.out.println(\"查询用户值\");\n    }\n}\n\n```\n### 3.主类\n\n```java\npackage com.page;\n\nimport com.page.service.impl.UserServiceImpl;\nimport org.mybatis.spring.annotation.MapperScan;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.ConfigurableApplicationContext;\nimport org.springframework.context.annotation.EnableAspectJAutoProxy;\nimport org.springframework.stereotype.Repository;\n\n/**\n * @author zousy\n * @version v1.0\n * @Description\n * @date 2020-12-09 17:27\n */\n@SpringBootApplication\n@MapperScan(\n        basePackages = \"com.zsy.page.*\",\n        annotationClass = Repository.class)\n//开启Spring AOP功能\n@EnableAspectJAutoProxy\npublic class AopPageApplication {\n    public static void main(String[] args) {\n        //SpringApplication.run(AopPageApplication.class,args);\n        ConfigurableApplicationContext context = SpringApplication.run(AopPageApplication.class, args);\n        UserServiceImpl bean = context.getBean(UserServiceImpl.class);\n        bean.query();\n    }\n}\n\n```\n### 4.结果\n![结果](https://img-blog.csdnimg.cn/20210114145820167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70)\n","tags":["Spring","Spring AOP"]},{"title":"Spring AOP的初步了解","url":"/2021/01/09/Spring/Spring AOP/Spring AOP介绍/","content":">\"初步了解和使用SPRING AOP\"\n\n##  一、AOP\n\n### 1.1 什么是AOP\n\nAOP(Aspect Orient Programming)，面向切面编程。AOP是一种编程思想，是对面向对象编程（OOP）的一种补充。\n\n\n### 1.2 AOP实现分类\nAOP的本质是由AOP框架修改业务组件的字节码，是代理模式的一种应用。按照修改的字节码的时机可以分为两类:\n* 静态AOP: AOP框架在编译阶段进行修改，生成了静态的AOP代理类(生成的.class文件已经被改动)，比如AspecJ框架。\n* 动态AOP: AOP框架在运行阶段动态生成代理对象(在内存中动态生成程序需要的.class文件)，比如SpringAop。\n\n**常用AOP实现比较**\n\n![aop.png](https://img-blog.csdnimg.cn/20210109151326747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NhcnJvdFpzeQ==,size_16,color_FFFFFF,t_70#pic_center)\n\n## 二、AOP术语\n* Aspect（切面）：通常是一个类，里面定义切入点和通知。\n* JointPoint（连接点）：程序执行过程中可以插入的点，可以是方法的调用、异常的抛出，在Spring AOP中通常是方法的调用。\n* Advice（通知）：AOP框架中的增强处理，有before,after,afterReturning,afterThrowing,around\n* PoinCut（切入点）：带有通知的连接点，\n* 引入（Introduction）：引入允许我们向现有的类添加新的方法或者属性。\n* 织入（Weaving）: 将增强处理添加到目标对象中，并创建一个被增强的对象，这个过程就是织入。\n\n## 三、初步认识Spring AOP\nSpring AOP 与ApectJ 的目的一致，都是为了统一处理横切业务，但与AspectJ不同的是，Spring AOP 并不尝试提供完整的AOP功能(即使它完全可以实现)，Spring AOP 更注重的是与Spring IOC容器的结合，并结合该优势来解决横切业务的问题，因此在AOP的功能完善方面，相对来说AspectJ具有更大的优势，同时,Spring注意到AspectJ在AOP的实现方式上依赖于特殊编译器(ajc编译器)，因此Spring很机智回避了这点，转向采用动态代理技术的实现原理来构建Spring AOP的内部机制（动态织入），这是与AspectJ（静态织入）最根本的区别。在AspectJ 1.5后，引入@Aspect形式的注解风格的开发，Spring也非常快地跟进了这种方式，因此Spring 2.0后便使用了与AspectJ一样的注解。请注意，Spring 只是使用了与 AspectJ 5 一样的注解，但仍然没有使用 AspectJ 的编译器，底层依是动态代理技术的实现，因此并不依赖于 AspectJ 的编译器。","tags":["Spring","Spring AOP"]},{"title":"Welcome to ShuYou Blog","url":"/2020/11/29/hello-world/","content":"> “Yeah It's on. ”\n\n## 前言\n这是使用Hexo搭建的博客，使用了Hux的主题。\n用腾讯云做的服务器，nginx静态资源访问，图片加载很慢，之后再优化下吧。\n刚开始是打算用来记录Java技术之类的学习，现在想了下这个博客还是用来记录自己平时的想法和生活吧。\n具体的技术什么的就发表在平台之类的网站上吧。\n\n## 计划\n2020年毕业的，今年也比较特殊，新冠嘛。\n年初谈了女朋友，当时已经签了三方，可是也没有去想毁三方，现在还是有点后悔的，早知道就留在武汉了。\n打算呆到2022年3月份回去吧，所以可能2022年1月份会辞职，回去过年，找工作。\n所以2021年要准备很多事情，学习很多东西。\n\n## 希望\n希望以后的自己会越来越好吧，生活和感情上都是。\n\n","tags":["记录"]}]